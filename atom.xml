<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>è‹¥æ³½å¤§æ•°æ® www.ruozedata.com</title>
  
  <subtitle>ruozedata</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-05-30T05:27:09.470Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>ruozedata</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ä¸Šæµ·æŸå…¬å¸çš„ç”Ÿäº§MySQLç¾éš¾æ€§æŒ½æ•‘</title>
    <link href="http://yoursite.com/2019/05/30/%E4%B8%8A%E6%B5%B7%E6%9F%90%E5%85%AC%E5%8F%B8%E7%9A%84%E7%94%9F%E4%BA%A7MySQL%E7%81%BE%E9%9A%BE%E6%80%A7%E6%8C%BD%E6%95%91/"/>
    <id>http://yoursite.com/2019/05/30/ä¸Šæµ·æŸå…¬å¸çš„ç”Ÿäº§MySQLç¾éš¾æ€§æŒ½æ•‘/</id>
    <published>2019-05-29T16:00:00.000Z</published>
    <updated>2019-05-30T05:27:09.470Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu May 30 2019 13:27:35 GMT+0800 (GMT+08:00) --><h3 id="1-èƒŒæ™¯"><a href="#1-èƒŒæ™¯" class="headerlink" title="1.èƒŒæ™¯"></a>1.èƒŒæ™¯</h3><p>æœ¬äºº(<a href="www.ruozedata.com">è‹¥æ³½æ•°æ®</a>Jå“¥)çš„åª³å¦‡ï¼Œæ˜¯ä¸ªæ¼‚äº®çš„å¦¹å­ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ä¸€æšçˆ¬è™«&amp;Sparkå¼€å‘å·¥ç¨‹å¸ˆã€‚</p><p>å‰å¤©ï¼Œå¥¹çš„å…¬å¸MySQL(é˜¿é‡Œäº‘ECSæœåŠ¡å™¨)ï¼Œç”±äºç£ç›˜çˆ†äº†åŠ ä¸Šäººä¸ºçš„ä¿®å¤ï¼Œå¯¼è‡´å„ç§é—®é¢˜ï¼Œç„¶åç»è¿‡2å¤©çš„æŠ˜è…¾ï¼Œç»ˆäºå…¬å¸çš„å¤§ç¥ä¿®å¤ä¸äº†äº†ã€‚äºæ˜¯å°±ä¸¢ç»™å¥¹äº†ï¼Œé¡ºç†æˆç« çš„å°±ä¸¢ç»™æˆ‘äº†ã€‚æˆ‘æƒ³è¯´ï¼Œéš¾é“Jå“¥è¿™ä¹ˆå‡ºåå—ï¼Ÿé‚£ä¸ºäº†åœ¨å¦¹å­é¢å‰ä¸èƒ½ä¸¢æˆ‘ä»¬çœŸæ­£å¤§ä½¬çš„ç¥æŠ€ï¼Œäºæ˜¯ä¹æˆ‘å°±å¾ˆçˆ½å¿«æ¥äº†è¿™ä¸ªMySQLæ•…éšœæ¢å¤ï¼Œæ­¤æ¬¡æ•…éšœçš„æ˜¯ä¸€ä¸ªæ•°æ®ç›˜ï¼Œ1Tã€‚<br>è¿™æ—¶çš„æˆ‘ï¼Œè¯´çœŸçš„å¹¶æ²¡æœ‰æ„è¯†åˆ°ï¼Œæ­¤äº‹æ˜¯å¦‚æ­¤çš„ç¹æ‚ï¼Œç‰¹æ­¤å†™æ­¤åšæ–‡è®°å½•ä¸€ä¸‹ï¼Œæ¯•ç«ŸJå“¥æˆ‘å¹´çºªä¹Ÿå¤§äº†ã€‚</p><p>PS:<br>è¿™é‡Œåæ§½ä¸€ä¸‹ï¼Œå¹¶æ²¡æœ‰å‘¨æ—¥å…¨å¤‡+å‘¨1~å‘¨6å¢é‡å¤‡ä»½æœºåˆ¶å“Ÿï¼Œä¸ç„¶æ¢å¤å°±çˆ½æ­ªæ­ªäº†ã€‚<br><a id="more"></a></p><h3 id="2-æ•…éšœç°è±¡"><a href="#2-æ•…éšœç°è±¡" class="headerlink" title="2.æ•…éšœç°è±¡"></a>2.æ•…éšœç°è±¡</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">æŸ¥çœ‹è¡¨ç»“æ„ã€æŸ¥è¯¢è¡¨æ•°æ®éƒ½å¦‚ä¸‹æŠ›é”™:</span><br><span class="line">ERROR 1030 (HY000): Got error 122 from storage engine</span><br></pre></td></tr></table></figure><p><img src="/assets/blogImg/1.png" alt="å›¾1"></p><h3 id="3-å°è¯•ä¿®å¤ç¬¬ä¸€æ¬¡ï¼Œå¤±è´¥"><a href="#3-å°è¯•ä¿®å¤ç¬¬ä¸€æ¬¡ï¼Œå¤±è´¥" class="headerlink" title="3.å°è¯•ä¿®å¤ç¬¬ä¸€æ¬¡ï¼Œå¤±è´¥"></a>3.å°è¯•ä¿®å¤ç¬¬ä¸€æ¬¡ï¼Œå¤±è´¥</h3><p>3.1 ä½¿ç”¨repairå‘½ä»¤ä¿®å¤è¡¨</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; repair table wenshu.wenshu2018;  </span><br><span class="line">é”™è¯¯ä¾æ—§:</span><br><span class="line">ERROR 1030 (HY000): Got error 122 from storage engine</span><br></pre></td></tr></table></figure><p>3.2 è°·æ­Œä¸€ç¯‡æœ‰æŒ‡å¯¼æ„ä¹‰çš„<br><a href="https://stackoverflow.com/questions/68029/got-error-122-from-storage-engine" target="_blank" rel="noopener">https://stackoverflow.com/questions/68029/got-error-122-from-storage-engine</a></p><ul><li>3.2.1 è®©å…¶æ‰©å®¹æ•°æ®ç£ç›˜ä¸º1.5Tï¼Œè¯•è¯•ï¼Œä¾æ—§è¿™ä¸ªé”™è¯¯ï¼›</li><li>3.2.2 ä¸´æ—¶ç›®å½•ä¿®æ”¹ä¸ºå¤§çš„ç£ç›˜ç©ºé—´ï¼Œè¯•è¯•ï¼Œä¾æ—§è¿™ä¸ªé”™è¯¯ï¼›</li><li>3.2.3 å–æ¶ˆç£ç›˜é™é¢ï¼Œè¯•è¯•ï¼Œä¾æ—§è¿™ä¸ªé”™è¯¯ï¼›</li><li>3.2.4 å°±æ˜¯ä¸€å¼€å§‹çš„repairå‘½ä»¤ä¿®å¤ï¼Œè¯•è¯•ï¼Œä¾æ—§è¿™ä¸ªé”™è¯¯ï¼›</li></ul><p>è¿™æ—¶çš„æˆ‘ï¼Œä¹Ÿæ— è¯­äº†ï¼Œä»€ä¹ˆé¬¼ï¼è°·æ­Œä¸€é¡µé¡µæœç´¢éªŒè¯ï¼Œæ²¡æœ‰ç”¨ï¼</p><h3 id="4-å…ˆéƒ¨ç½²ç›¸åŒç³»ç»Ÿçš„ç›¸åŒç‰ˆæœ¬çš„æœºå™¨å’ŒMySQL"><a href="#4-å…ˆéƒ¨ç½²ç›¸åŒç³»ç»Ÿçš„ç›¸åŒç‰ˆæœ¬çš„æœºå™¨å’ŒMySQL" class="headerlink" title="4.å…ˆéƒ¨ç½²ç›¸åŒç³»ç»Ÿçš„ç›¸åŒç‰ˆæœ¬çš„æœºå™¨å’ŒMySQL"></a>4.å…ˆéƒ¨ç½²ç›¸åŒç³»ç»Ÿçš„ç›¸åŒç‰ˆæœ¬çš„æœºå™¨å’ŒMySQL</h3><p>äºæ˜¯Jå“¥ï¼Œå¿«é€Ÿåœ¨ã€è‹¥æ³½æ•°æ®ã€‘çš„é˜¿é‡Œäº‘è´¦å·ä¸Šä¹°äº†1å°Ubuntu 16.04.6çš„æŒ‰é‡ä»˜è´¹æœºå™¨<br>è¿…é€Ÿéƒ¨ç½²MySQL5.7.26ã€‚</p><ul><li>4.1 è´­ä¹°æŒ‰é‡ä»˜è´¹æœºå™¨(å‡å¦‚ä¸ä¼šè´­ä¹°ï¼Œæ‰¾Jå“¥)</li><li>4.2 éƒ¨ç½²MySQL</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">a.æ›´æ–°apt-get</span><br><span class="line">$ apt-get update</span><br><span class="line"></span><br><span class="line">b.å®‰è£…MySQL-Server</span><br><span class="line">$ apt-get install mysql-server</span><br><span class="line"></span><br><span class="line">ä¹‹åä¼šé—®ä½ ï¼Œæ˜¯å¦è¦ä¸‹è½½æ–‡ä»¶ï¼Œ è¾“å…¥ y å°±å¥½äº†</span><br><span class="line">ç„¶åä¼šå‡ºç°è®©ä½ è®¾ç½® root å¯†ç çš„ç•Œé¢</span><br><span class="line">è¾“å…¥å¯†ç : ruozedata123</span><br><span class="line">ç„¶åå†é‡å¤ä¸€ä¸‹ï¼Œ</span><br><span class="line">å†æ¬¡è¾“å…¥å¯†ç : ruozedata123</span><br><span class="line"></span><br><span class="line">c.å®‰è£…MySQL-Client</span><br><span class="line">$ apt install mysql-client</span><br><span class="line"></span><br><span class="line">d.æˆ‘ä»¬å¯ä»¥ä½¿ç”¨</span><br><span class="line">$ mysql -uroot -pruozedata123</span><br><span class="line">æ¥è¿æ¥æœåŠ¡å™¨æœ¬åœ°çš„ MySQL</span><br></pre></td></tr></table></figure><h3 id="5-å°è¯•å…ˆé€šè¿‡frmæ–‡ä»¶æ¢å¤è¡¨ç»“æ„ï¼Œå¤±è´¥"><a href="#5-å°è¯•å…ˆé€šè¿‡frmæ–‡ä»¶æ¢å¤è¡¨ç»“æ„ï¼Œå¤±è´¥" class="headerlink" title="5.å°è¯•å…ˆé€šè¿‡frmæ–‡ä»¶æ¢å¤è¡¨ç»“æ„ï¼Œå¤±è´¥"></a>5.å°è¯•å…ˆé€šè¿‡frmæ–‡ä»¶æ¢å¤è¡¨ç»“æ„ï¼Œå¤±è´¥</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">a. å»ºç«‹ä¸€ä¸ªæ•°æ®åº“ï¼Œæ¯”å¦‚wenshu.</span><br><span class="line"></span><br><span class="line">b. åœ¨ruozedataæ•°æ®åº“ä¸‹å»ºç«‹åŒåçš„æ•°æ®è¡¨wenshu2018ï¼Œè¡¨ç»“æ„éšæ„ï¼Œè¿™é‡Œåªæœ‰ä¸€ä¸ªidå­—æ®µï¼Œæ“ä½œè¿‡ç¨‹ç‰‡æ®µå¦‚ä¸‹ï¼š</span><br><span class="line"></span><br><span class="line">mysql&gt; create table wenshu2018 (id bigint) engine=InnoDB;</span><br><span class="line">mysql&gt; show tables;</span><br><span class="line">+--------------+</span><br><span class="line">| Tables_in_aa |</span><br><span class="line">+--------------+</span><br><span class="line">| wenshu2018   |</span><br><span class="line">+--------------+</span><br><span class="line">1 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; desc wenshu2018;</span><br><span class="line">+-------+------------+------+-----+---------+-------+</span><br><span class="line">| Field | Type       | Null | Key | Default | Extra |</span><br><span class="line">+-------+------------+------+-----+---------+-------+</span><br><span class="line">| id    | bigint(20) | NO   |     | NULL    |       |</span><br><span class="line">+-------+------------+------+-----+---------+-------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">c.åœæ­¢mysqlæœåŠ¡å™¨ï¼Œå°†wenshu2018.frmæ–‡ä»¶scpè¿œç¨‹æ‹·è´åˆ°æ–°çš„æ­£å¸¸æ•°æ®åº“çš„æ•°æ®ç›®å½•wenshuä¸‹ï¼Œè¦†ç›–æ‰ä¸‹è¾¹åŒåçš„frmæ–‡ä»¶ï¼š</span><br><span class="line"></span><br><span class="line">d.é‡æ–°å¯åŠ¨MYSQLæœåŠ¡</span><br><span class="line"></span><br><span class="line">e.æµ‹è¯•ä¸‹æ˜¯å¦æ¢å¤æˆåŠŸï¼Œè¿›å…¥wenshuæ•°æ®åº“ï¼Œç”¨descå‘½ä»¤æµ‹è¯•ä¸‹ï¼Œé”™è¯¯ä¸º:</span><br><span class="line">mysql Tablespace is missing for table `wenshu`.`wenshu2018`.</span><br></pre></td></tr></table></figure><h3 id="6-å°è¯•æœ‰æ²¡æœ‰å¤‡ä»½çš„è¡¨ç»“æ„æ¢å¤æ•°æ®ï¼Œå¤±è´¥"><a href="#6-å°è¯•æœ‰æ²¡æœ‰å¤‡ä»½çš„è¡¨ç»“æ„æ¢å¤æ•°æ®ï¼Œå¤±è´¥" class="headerlink" title="6.å°è¯•æœ‰æ²¡æœ‰å¤‡ä»½çš„è¡¨ç»“æ„æ¢å¤æ•°æ®ï¼Œå¤±è´¥"></a>6.å°è¯•æœ‰æ²¡æœ‰å¤‡ä»½çš„è¡¨ç»“æ„æ¢å¤æ•°æ®ï¼Œå¤±è´¥</h3><p>åª³å¦‡å…¬å¸ç»™å‡ºä¸€ä¸ªè¡¨ç»“æ„,å¦‚ä¸‹ï¼Œç»è¿‡æµ‹è¯•æ— æ³•æ¢å¤ï¼ŒåŸå› å°±æ˜¯æ— æ³•å’Œibdæ–‡ä»¶åŒ¹é…ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">DROP TABLE IF EXISTS cpws_batch;</span><br><span class="line">CREATE TABLE cpws_batch  (</span><br><span class="line">  id int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  doc_id varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,</span><br><span class="line">  source text CHARACTER SET utf8 COLLATE utf8_general_ci NULL,</span><br><span class="line">  error_msg text CHARACTER SET utf8 COLLATE utf8_general_ci NULL,</span><br><span class="line">  crawl_time datetime NULL DEFAULT NULL,</span><br><span class="line">  status tinyint(4) NULL DEFAULT NULL COMMENT &apos;0/1 æˆåŠŸ/å¤±è´¥&apos;,</span><br><span class="line">  PRIMARY KEY (id) USING BTREE,</span><br><span class="line">  INDEX ix_status(status) USING BTREE,</span><br><span class="line">  INDEX ix_doc_id(doc_id) USING BTREE</span><br><span class="line">) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;</span><br></pre></td></tr></table></figure><h3 id="7-å¦‚ä½•è·å–æ­£ç¡®çš„è¡¨ç»“æ„ï¼Œè¿™æ˜¯ã€æˆåŠŸçš„ç¬¬ä¸€æ­¥ã€‘"><a href="#7-å¦‚ä½•è·å–æ­£ç¡®çš„è¡¨ç»“æ„ï¼Œè¿™æ˜¯ã€æˆåŠŸçš„ç¬¬ä¸€æ­¥ã€‘" class="headerlink" title="7.å¦‚ä½•è·å–æ­£ç¡®çš„è¡¨ç»“æ„ï¼Œè¿™æ˜¯ã€æˆåŠŸçš„ç¬¬ä¸€æ­¥ã€‘"></a>7.å¦‚ä½•è·å–æ­£ç¡®çš„è¡¨ç»“æ„ï¼Œè¿™æ˜¯ã€æˆåŠŸçš„ç¬¬ä¸€æ­¥ã€‘</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">$ curl -s get.dbsake.net &gt; /tmp/dbsake</span><br><span class="line">$ chmod u+x /tmp/dbsake</span><br><span class="line">$ /tmp/dbsake frmdump /mnt/mysql_data/wenshu/wenshu2018.frm </span><br><span class="line">--</span><br><span class="line">-- Table structure for table wenshu_0_1000</span><br><span class="line">-- Created with MySQL Version 5.7.25</span><br><span class="line">--</span><br><span class="line"></span><br><span class="line">CREATE TABLE wenshu2018 (</span><br><span class="line">  id int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  doc_id varchar(255) DEFAULT NULL,</span><br><span class="line">  source text,</span><br><span class="line">  error_msg text,</span><br><span class="line">  crawl_time datetime DEFAULT NULL,</span><br><span class="line">  status tinyint(4) DEFAULT NULL COMMENT &apos;0/1 æˆåŠŸ/å¤±è´¥&apos;,</span><br><span class="line">  PRIMARY KEY (id),</span><br><span class="line">  KEY ix_status (status),</span><br><span class="line">  KEY ix_doc_id (doc_id)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8 </span><br><span class="line">/*!50100  PARTITION BY RANGE (id)</span><br><span class="line">(PARTITION p0 VALUES LESS THAN (4000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p1 VALUES LESS THAN (8000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p2 VALUES LESS THAN (12000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p3 VALUES LESS THAN (16000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p4 VALUES LESS THAN (20000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p5 VALUES LESS THAN (24000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p6 VALUES LESS THAN (28000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p7 VALUES LESS THAN (32000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p8 VALUES LESS THAN (36000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p9 VALUES LESS THAN (40000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p10 VALUES LESS THAN (44000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p11 VALUES LESS THAN MAXVALUE ENGINE = InnoDB) */;</span><br></pre></td></tr></table></figure><p>å¯¹æ¯”Step6çš„è¡¨ç»“æ„ï¼Œæ„Ÿè§‰å°±å·®åˆ†åŒºè®¾ç½®è€Œå·²ï¼Œå‘ï¼<br>è¿™æ—¶ï¼ŒJå“¥æœ‰ç§ä¿¡å¿ƒï¼Œæ¢å¤åº”è¯¥å°èœäº†ã€‚</p><h3 id="8-ç”±äºæ¢å¤ECSæœºå™¨æ˜¯è‹¥æ³½æ•°æ®è´¦å·è´­ä¹°ï¼Œè¿™æ—¶éœ€è¦ä»åª³å¦‡å…¬å¸è´¦å·çš„æœºå™¨ä¼ è¾“è¿™å¼ è¡¨ibdæ–‡ä»¶ï¼Œå·®ä¸å¤š300Gï¼Œå°½ç®¡æˆ‘ä»¬æ˜¯é˜¿é‡Œäº‘çš„åŒä¸€ä¸ªåŒºåŸŸåŒä¸€ä¸ªå¯ç”¨åŒºï¼ŒåŠ ä¸Šè°ƒå¤§å¤–ç½‘å¸¦å®½ä¼ è¾“ï¼Œä¾ç„¶ä¸èƒ½ç­‰å¾…è¿™ä¹ˆä¹…ä¼ è¾“ï¼"><a href="#8-ç”±äºæ¢å¤ECSæœºå™¨æ˜¯è‹¥æ³½æ•°æ®è´¦å·è´­ä¹°ï¼Œè¿™æ—¶éœ€è¦ä»åª³å¦‡å…¬å¸è´¦å·çš„æœºå™¨ä¼ è¾“è¿™å¼ è¡¨ibdæ–‡ä»¶ï¼Œå·®ä¸å¤š300Gï¼Œå°½ç®¡æˆ‘ä»¬æ˜¯é˜¿é‡Œäº‘çš„åŒä¸€ä¸ªåŒºåŸŸåŒä¸€ä¸ªå¯ç”¨åŒºï¼ŒåŠ ä¸Šè°ƒå¤§å¤–ç½‘å¸¦å®½ä¼ è¾“ï¼Œä¾ç„¶ä¸èƒ½ç­‰å¾…è¿™ä¹ˆä¹…ä¼ è¾“ï¼" class="headerlink" title="8.ç”±äºæ¢å¤ECSæœºå™¨æ˜¯è‹¥æ³½æ•°æ®è´¦å·è´­ä¹°ï¼Œè¿™æ—¶éœ€è¦ä»åª³å¦‡å…¬å¸è´¦å·çš„æœºå™¨ä¼ è¾“è¿™å¼ è¡¨ibdæ–‡ä»¶ï¼Œå·®ä¸å¤š300Gï¼Œå°½ç®¡æˆ‘ä»¬æ˜¯é˜¿é‡Œäº‘çš„åŒä¸€ä¸ªåŒºåŸŸåŒä¸€ä¸ªå¯ç”¨åŒºï¼ŒåŠ ä¸Šè°ƒå¤§å¤–ç½‘å¸¦å®½ä¼ è¾“ï¼Œä¾ç„¶ä¸èƒ½ç­‰å¾…è¿™ä¹ˆä¹…ä¼ è¾“ï¼"></a>8.ç”±äºæ¢å¤ECSæœºå™¨æ˜¯è‹¥æ³½æ•°æ®è´¦å·è´­ä¹°ï¼Œè¿™æ—¶éœ€è¦ä»åª³å¦‡å…¬å¸è´¦å·çš„æœºå™¨ä¼ è¾“è¿™å¼ è¡¨ibdæ–‡ä»¶ï¼Œå·®ä¸å¤š300Gï¼Œå°½ç®¡æˆ‘ä»¬æ˜¯é˜¿é‡Œäº‘çš„åŒä¸€ä¸ªåŒºåŸŸåŒä¸€ä¸ªå¯ç”¨åŒºï¼ŒåŠ ä¸Šè°ƒå¤§å¤–ç½‘å¸¦å®½ä¼ è¾“ï¼Œä¾ç„¶ä¸èƒ½ç­‰å¾…è¿™ä¹ˆä¹…ä¼ è¾“ï¼</h3><h3 id="9-è¦æ±‚åª³å¦‡å…¬å¸è´­ä¹°åŒè´¦æˆ·ä¸‹åŒåŒºåŸŸçš„å¯ç”¨åŒºåŸŸçš„äº‘ä¸»æœºï¼Œç³»ç»Ÿç›˜300Gï¼Œæ²¡æœ‰ä¹°æ•°æ®ç›˜ï¼Œå…ˆå°è¯•åšæ¢å¤çœ‹çœ‹ï¼Œèƒ½ä¸èƒ½æˆåŠŸæ¢å¤ç¬¬ä¸€ä¸ªè¡¨å“Ÿï¼Ÿã€æˆåŠŸçš„ç¬¬äºŒæ­¥ã€‘"><a href="#9-è¦æ±‚åª³å¦‡å…¬å¸è´­ä¹°åŒè´¦æˆ·ä¸‹åŒåŒºåŸŸçš„å¯ç”¨åŒºåŸŸçš„äº‘ä¸»æœºï¼Œç³»ç»Ÿç›˜300Gï¼Œæ²¡æœ‰ä¹°æ•°æ®ç›˜ï¼Œå…ˆå°è¯•åšæ¢å¤çœ‹çœ‹ï¼Œèƒ½ä¸èƒ½æˆåŠŸæ¢å¤ç¬¬ä¸€ä¸ªè¡¨å“Ÿï¼Ÿã€æˆåŠŸçš„ç¬¬äºŒæ­¥ã€‘" class="headerlink" title="9.è¦æ±‚åª³å¦‡å…¬å¸è´­ä¹°åŒè´¦æˆ·ä¸‹åŒåŒºåŸŸçš„å¯ç”¨åŒºåŸŸçš„äº‘ä¸»æœºï¼Œç³»ç»Ÿç›˜300Gï¼Œæ²¡æœ‰ä¹°æ•°æ®ç›˜ï¼Œå…ˆå°è¯•åšæ¢å¤çœ‹çœ‹ï¼Œèƒ½ä¸èƒ½æˆåŠŸæ¢å¤ç¬¬ä¸€ä¸ªè¡¨å“Ÿï¼Ÿã€æˆåŠŸçš„ç¬¬äºŒæ­¥ã€‘"></a>9.è¦æ±‚åª³å¦‡å…¬å¸è´­ä¹°åŒè´¦æˆ·ä¸‹åŒåŒºåŸŸçš„å¯ç”¨åŒºåŸŸçš„äº‘ä¸»æœºï¼Œç³»ç»Ÿç›˜300Gï¼Œæ²¡æœ‰ä¹°æ•°æ®ç›˜ï¼Œå…ˆå°è¯•åšæ¢å¤çœ‹çœ‹ï¼Œèƒ½ä¸èƒ½æˆåŠŸæ¢å¤ç¬¬ä¸€ä¸ªè¡¨å“Ÿï¼Ÿã€æˆåŠŸçš„ç¬¬äºŒæ­¥ã€‘</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">9.1é¦–å…ˆéœ€è¦ä¸€ä¸ªè·Ÿè¦æ¢å¤çš„è¡¨ç»“æ„å®Œå…¨ä¸€è‡´çš„è¡¨ï¼Œè‡³å…³é‡è¦</span><br><span class="line">mysql&gt; CREATE DATABASE wenshu /*!40100 DEFAULT CHARACTER SET utf8mb4 */;</span><br><span class="line">USE wenshu;</span><br><span class="line">CREATE TABLE wenshu2018 (</span><br><span class="line">  id int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  doc_id varchar(255) DEFAULT NULL,</span><br><span class="line">  source text,</span><br><span class="line">  error_msg text,</span><br><span class="line">  crawl_time datetime DEFAULT NULL,</span><br><span class="line">  status tinyint(4) DEFAULT NULL COMMENT &apos;0/1 æˆåŠŸ/å¤±è´¥&apos;,</span><br><span class="line">  PRIMARY KEY (id),</span><br><span class="line">  KEY ix_status (status),</span><br><span class="line">  KEY ix_doc_id (doc_id)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8 </span><br><span class="line">/*!50100  PARTITION BY RANGE (id)</span><br><span class="line">(PARTITION p0 VALUES LESS THAN (4000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p1 VALUES LESS THAN (8000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p2 VALUES LESS THAN (12000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p3 VALUES LESS THAN (16000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p4 VALUES LESS THAN (20000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p5 VALUES LESS THAN (24000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p6 VALUES LESS THAN (28000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p7 VALUES LESS THAN (32000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p8 VALUES LESS THAN (36000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p9 VALUES LESS THAN (40000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p10 VALUES LESS THAN (44000000) ENGINE = InnoDB,</span><br><span class="line"> PARTITION p11 VALUES LESS THAN MAXVALUE ENGINE = InnoDB) */;</span><br><span class="line"></span><br><span class="line">9.2ç„¶åDISCARD TABLESPACE</span><br><span class="line">mysql&gt; ALTER TABLE wenshu.wenshu2018 DISCARD TABLESPACE;</span><br><span class="line"></span><br><span class="line">9.3æŠŠè¦æ¢å¤çš„ibdæ–‡ä»¶å¤åˆ¶åˆ°mysqlçš„dataæ–‡ä»¶å¤¹ä¸‹ï¼Œä¿®æ”¹ç”¨æˆ·å’Œç”¨æˆ·ç»„ä¸ºmysql</span><br><span class="line">$ scp wenshu2018#P#p*.ibd  æ–°å»ºæœºå™¨IP:/mnt/mysql_data/wenshu/</span><br><span class="line">$ chown -R mysql:mysql /mnt/mysql_data/wenshu/wenshu2018#P#p*.ibd</span><br><span class="line"></span><br><span class="line">9.4ç„¶åæ‰§è¡ŒIMPORT TABLESPACE</span><br><span class="line">mysql&gt; ALTER TABLE wenshu.wenshu2018 IMPORT TABLESPACE;</span><br><span class="line"></span><br><span class="line">9.5ç­‰å¾…ï¼Œæœ‰æˆï¼Œè€—æ—¶3hï¼Œè¿™æ—¶æˆ‘ç›¸ä¿¡åº”è¯¥ä¹ˆé—®é¢˜çš„</span><br><span class="line"></span><br><span class="line">9.6æŸ¥è¯¢æ•°æ®ï¼Œæœç„¶æ¢å¤æœ‰ç»“æœï¼Œå¿ƒé‡Œæš—æš—è‡ªå–œ</span><br><span class="line">mysql&gt; select * from wenshu.wenshu2018 limit 1\G;</span><br></pre></td></tr></table></figure><h3 id="10-ç»™åª³å¦‡å…¬å¸ä¸¤ä¸ªé€‰æ‹©ï¼Œè¿™ä¸ªå¾ˆé‡è¦ï¼Œåœ¨è‡ªå·±å…¬å¸ç»™é¢†å¯¼åšé€‰æ‹©æ—¶ï¼Œä¹Ÿè¦åº”è¯¥è¿™æ ·ï¼Œå¤šé¡¹é€‰æ‹©ï¼Œåˆ©å¼Šè¯´æ˜ï¼Œä¾›å¯¹æ–¹é€‰æ‹©"><a href="#10-ç»™åª³å¦‡å…¬å¸ä¸¤ä¸ªé€‰æ‹©ï¼Œè¿™ä¸ªå¾ˆé‡è¦ï¼Œåœ¨è‡ªå·±å…¬å¸ç»™é¢†å¯¼åšé€‰æ‹©æ—¶ï¼Œä¹Ÿè¦åº”è¯¥è¿™æ ·ï¼Œå¤šé¡¹é€‰æ‹©ï¼Œåˆ©å¼Šè¯´æ˜ï¼Œä¾›å¯¹æ–¹é€‰æ‹©" class="headerlink" title="10.ç»™åª³å¦‡å…¬å¸ä¸¤ä¸ªé€‰æ‹©ï¼Œè¿™ä¸ªå¾ˆé‡è¦ï¼Œåœ¨è‡ªå·±å…¬å¸ç»™é¢†å¯¼åšé€‰æ‹©æ—¶ï¼Œä¹Ÿè¦åº”è¯¥è¿™æ ·ï¼Œå¤šé¡¹é€‰æ‹©ï¼Œåˆ©å¼Šè¯´æ˜ï¼Œä¾›å¯¹æ–¹é€‰æ‹©"></a>10.ç»™åª³å¦‡å…¬å¸ä¸¤ä¸ªé€‰æ‹©ï¼Œè¿™ä¸ªå¾ˆé‡è¦ï¼Œåœ¨è‡ªå·±å…¬å¸ç»™é¢†å¯¼åšé€‰æ‹©æ—¶ï¼Œä¹Ÿè¦åº”è¯¥è¿™æ ·ï¼Œå¤šé¡¹é€‰æ‹©ï¼Œåˆ©å¼Šè¯´æ˜ï¼Œä¾›å¯¹æ–¹é€‰æ‹©</h3><ul><li>10.1 é‡æ–°è´­ä¹°ä¸€å°æ–°çš„æœåŠ¡å™¨ï¼Œåœ¨åˆå§‹åŒ–é…ç½®æ—¶ï¼Œå°±åŠ ä¸Š1å—1.5Tçš„å¤§ç£ç›˜ã€‚å¥½å¤„æ˜¯æ— éœ€æŒ‚ç›˜æ“ä½œï¼Œåå¤„æ˜¯éœ€è¦é‡æ–°åšç¬¬ä¸€ä¸ªè¡¨ï¼Œæµªè´¹3hï¼›</li><li>10.2 è´­ä¹°1.5Tçš„å¤§ç£ç›˜ï¼ŒæŒ‚è½½è¿™ä¸ªæœºå™¨ä¸Šã€‚å¥½å¤„æ˜¯æ— éœ€å†åšä¸€æ¬¡ç¬¬ä¸€ä¸ªè¡¨ï¼Œåå¤„æ˜¯éœ€è¦ä¿®æ”¹mysqlçš„æ•°æ®ç›®å½•æŒ‡å‘ä¸ºè¿™ä¸ªå¤§ç£ç›˜ã€‚ç³»ç»Ÿç›˜æ‰©å®¹æœ€å¤§ä¹Ÿå°±500Gï¼Œæ‰€ä»¥å¿…é¡»å¤–åŠ ä¸€ä¸ªæ•°æ®ç›˜1.5Tå®¹é‡ã€‚</li></ul><p>æ‰€ä»¥Jå“¥æ˜¯èŒåœºè€æ‰‹äº†ï¼è´¼ç¬‘ï¼</p><h3 id="11-æœåŠ¡å™¨åŠ æ•°æ®ç£ç›˜ï¼Œ1-5Tï¼Œè´­ä¹°ã€æŒ‚è½½ã€æ ¼å¼åŒ–"><a href="#11-æœåŠ¡å™¨åŠ æ•°æ®ç£ç›˜ï¼Œ1-5Tï¼Œè´­ä¹°ã€æŒ‚è½½ã€æ ¼å¼åŒ–" class="headerlink" title="11.æœåŠ¡å™¨åŠ æ•°æ®ç£ç›˜ï¼Œ1.5Tï¼Œè´­ä¹°ã€æŒ‚è½½ã€æ ¼å¼åŒ–"></a>11.æœåŠ¡å™¨åŠ æ•°æ®ç£ç›˜ï¼Œ1.5Tï¼Œè´­ä¹°ã€æŒ‚è½½ã€æ ¼å¼åŒ–</h3><p>æ¥ä¸‹æ¥çš„æ“ä½œæ˜¯æˆ‘åª³å¦‡ç‹¬ç«‹å®Œæˆçš„ï¼Œè¿™é‡Œè¡¨æ‰¬ä¸€ä¸‹:</p><ul><li>11.1 å…ˆä¹°äº‘ç›˜ <a href="https://help.aliyun.com/document_detail/25445.html?spm=a2c4g.11186623.6.753.40132c30MbE8n8" target="_blank" rel="noopener">https://help.aliyun.com/document_detail/25445.html?spm=a2c4g.11186623.6.753.40132c30MbE8n8</a></li><li>11.2 å†æŒ‚è½½äº‘ç›˜ åˆ°å¯¹åº”æœºå™¨ <a href="https://help.aliyun.com/document_detail/25446.html?spm=a2c4g.11186623.6.756.30874f291pXOwB" target="_blank" rel="noopener">https://help.aliyun.com/document_detail/25446.html?spm=a2c4g.11186623.6.756.30874f291pXOwB</a></li><li>11.3 æœ€åLinuxæ ¼å¼åŒ–æ•°æ®ç›˜ <a href="https://help.aliyun.com/document_detail/116650.html?spm=a2c4g.11186623.6.759.11f67d562yD9Lr" target="_blank" rel="noopener">https://help.aliyun.com/document_detail/116650.html?spm=a2c4g.11186623.6.759.11f67d562yD9Lr</a></li></ul><p>å›¾2æ‰€ç¤ºï¼Œdf -hå‘½ä»¤æŸ¥çœ‹ï¼Œå¤§ç£ç›˜/dev/vdb1<br><img src="/assets/blogImg/2.png" alt="å›¾2"></p><h3 id="12-MySQLä¿®æ”¹æ•°æ®ç›®å½•ä¸ºå¤§ç£ç›˜ï¼Œé‡æ–°å¯åŠ¨å¤±è´¥ï¼Œè§£å†³"><a href="#12-MySQLä¿®æ”¹æ•°æ®ç›®å½•ä¸ºå¤§ç£ç›˜ï¼Œé‡æ–°å¯åŠ¨å¤±è´¥ï¼Œè§£å†³" class="headerlink" title="12.MySQLä¿®æ”¹æ•°æ®ç›®å½•ä¸ºå¤§ç£ç›˜ï¼Œé‡æ–°å¯åŠ¨å¤±è´¥ï¼Œè§£å†³"></a>12.MySQLä¿®æ”¹æ•°æ®ç›®å½•ä¸ºå¤§ç£ç›˜ï¼Œé‡æ–°å¯åŠ¨å¤±è´¥ï¼Œè§£å†³</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">12.1 ä¿®æ”¹æ•°æ®ç›®å½•ä¸ºå¤§ç£ç›˜</span><br><span class="line">$ mkdir -p /mnt/mysql_data</span><br><span class="line">$ chown mysql:mysql /mnt/mysql_data</span><br><span class="line">$ vi /etc/mysql/mysql.conf.d/mysqld.cnf</span><br><span class="line">datadir         = /mnt/mysql_data</span><br><span class="line"></span><br><span class="line">12.2 æ— æ³•å¯åŠ¨mysql</span><br><span class="line">$ service mysql restart</span><br><span class="line">æ— æ³•å¯åŠ¨æˆåŠŸï¼ŒæŸ¥çœ‹æ—¥å¿—</span><br><span class="line">2019-05-28T03:41:31.181777Z 0 [Note] InnoDB: If the mysqld execution user is authorized, page cleaner thread priority can be changed. See the man page of setpriority().</span><br><span class="line">2019-05-28T03:41:31.191805Z 0 [ERROR] InnoDB: The innodb_system data file &apos;ibdata1&apos; must be writable</span><br><span class="line">2019-05-28T03:41:31.192055Z 0 [ERROR] InnoDB: The innodb_system data file &apos;ibdata1&apos; must be writable</span><br><span class="line">2019-05-28T03:41:31.192119Z 0 [ERROR] InnoDB: Plugin initialization aborted with error Generic error</span><br><span class="line"></span><br><span class="line">12.3 ç™¾æ€ä¸å¾—å…¶è§£ï¼ŒCentOSä¹Ÿæ²¡æœ‰è¿™ä¹ˆéº»çƒ¦ï¼ŒUbuntuéš¾é“è¿™ä¹ˆæäº‹å—ï¼Ÿ</span><br><span class="line">12.4 æ–°å¢mysqldå†…å®¹</span><br><span class="line">$ vi /etc/apparmor.d/local/usr.sbin.mysqld</span><br><span class="line"># Site-specific additions and overrides for usr.sbin.mysqld.</span><br><span class="line"># For more details, please see /etc/apparmor.d/local/README.</span><br><span class="line">/mnt/mysql_data/ r,</span><br><span class="line">/mnt/mysql_data/** rwk,</span><br><span class="line"></span><br><span class="line">12.5 reload apparmorçš„é…ç½®å¹¶é‡å¯</span><br><span class="line">$ service apparmor reload </span><br><span class="line">$ service apparmor restart </span><br><span class="line"> </span><br><span class="line">12.6 é‡å¯mysql</span><br><span class="line">$ service mysql restart</span><br><span class="line">å¦‚æœå¯åŠ¨ä¸äº†ï¼ŒæŸ¥çœ‹/var/log/mysql/error.log</span><br><span class="line">å¦‚æœå‡ºç°ï¼šInnoDB: The innodb_system data file &apos;ibdata1&apos; must be writable ä»”ç»†æ ¸å¯¹ç›®å½•æƒé™</span><br><span class="line"></span><br><span class="line">12.7 è¿›mysqlæŸ¥è¯¢æ•°æ®éªŒè¯ï¼ŒæˆåŠŸ</span><br><span class="line">select * from wenshu.wenshu2018 limit 1\G;</span><br></pre></td></tr></table></figure><h3 id="13-å¼€å§‹æŒ‡å¯¼æˆ‘åª³å¦‡åšç¬¬äºŒä¸ªã€ç¬¬ä¸‰ä¸ªè¡¨ï¼Œæ‰¹é‡æ¢å¤ï¼Œè€—æ—¶å…±è®¡16å°æ—¶ï¼Œå…¨éƒ¨æ¢å¤å®Œæˆã€‚"><a href="#13-å¼€å§‹æŒ‡å¯¼æˆ‘åª³å¦‡åšç¬¬äºŒä¸ªã€ç¬¬ä¸‰ä¸ªè¡¨ï¼Œæ‰¹é‡æ¢å¤ï¼Œè€—æ—¶å…±è®¡16å°æ—¶ï¼Œå…¨éƒ¨æ¢å¤å®Œæˆã€‚" class="headerlink" title="13.å¼€å§‹æŒ‡å¯¼æˆ‘åª³å¦‡åšç¬¬äºŒä¸ªã€ç¬¬ä¸‰ä¸ªè¡¨ï¼Œæ‰¹é‡æ¢å¤ï¼Œè€—æ—¶å…±è®¡16å°æ—¶ï¼Œå…¨éƒ¨æ¢å¤å®Œæˆã€‚"></a>13.å¼€å§‹æŒ‡å¯¼æˆ‘åª³å¦‡åšç¬¬äºŒä¸ªã€ç¬¬ä¸‰ä¸ªè¡¨ï¼Œæ‰¹é‡æ¢å¤ï¼Œè€—æ—¶å…±è®¡16å°æ—¶ï¼Œå…¨éƒ¨æ¢å¤å®Œæˆã€‚</h3><h2 id="æœ€å-è‹¥æ³½æ•°æ®Jå“¥æ€»ç»“ä¸€ä¸‹"><a href="#æœ€å-è‹¥æ³½æ•°æ®Jå“¥æ€»ç»“ä¸€ä¸‹" class="headerlink" title="æœ€å@è‹¥æ³½æ•°æ®Jå“¥æ€»ç»“ä¸€ä¸‹:"></a>æœ€å@è‹¥æ³½æ•°æ®Jå“¥æ€»ç»“ä¸€ä¸‹:</h2><ul><li>è¡¨ç»“æ„æ­£ç¡®çš„è·å–ï¼›</li><li>æœºå™¨ç£ç›˜è§„åˆ’æå‰æ€è€ƒï¼›</li><li>ibdæ•°æ®æ–‡ä»¶æ¢å¤ï¼›</li><li>æœ€ååŠ ä¸Šä¸€ä¸ªèªæ˜çš„åª³å¦‡ï¼(PS:è€æ¿ä¼šç»™åª³å¦‡æ¶¨è–ªæ°´ä¸ğŸ™…â€â™‚ï¸)</li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu May 30 2019 13:27:35 GMT+0800 (GMT+08:00) --&gt;&lt;h3 id=&quot;1-èƒŒæ™¯&quot;&gt;&lt;a href=&quot;#1-èƒŒæ™¯&quot; class=&quot;headerlink&quot; title=&quot;1.èƒŒæ™¯&quot;&gt;&lt;/a&gt;1.èƒŒæ™¯&lt;/h3&gt;&lt;p&gt;æœ¬äºº(&lt;a href=&quot;www.ruozedata.com&quot;&gt;è‹¥æ³½æ•°æ®&lt;/a&gt;Jå“¥)çš„åª³å¦‡ï¼Œæ˜¯ä¸ªæ¼‚äº®çš„å¦¹å­ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ä¸€æšçˆ¬è™«&amp;amp;Sparkå¼€å‘å·¥ç¨‹å¸ˆã€‚&lt;/p&gt;&lt;p&gt;å‰å¤©ï¼Œå¥¹çš„å…¬å¸MySQL(é˜¿é‡Œäº‘ECSæœåŠ¡å™¨)ï¼Œç”±äºç£ç›˜çˆ†äº†åŠ ä¸Šäººä¸ºçš„ä¿®å¤ï¼Œå¯¼è‡´å„ç§é—®é¢˜ï¼Œç„¶åç»è¿‡2å¤©çš„æŠ˜è…¾ï¼Œç»ˆäºå…¬å¸çš„å¤§ç¥ä¿®å¤ä¸äº†äº†ã€‚äºæ˜¯å°±ä¸¢ç»™å¥¹äº†ï¼Œé¡ºç†æˆç« çš„å°±ä¸¢ç»™æˆ‘äº†ã€‚æˆ‘æƒ³è¯´ï¼Œéš¾é“Jå“¥è¿™ä¹ˆå‡ºåå—ï¼Ÿé‚£ä¸ºäº†åœ¨å¦¹å­é¢å‰ä¸èƒ½ä¸¢æˆ‘ä»¬çœŸæ­£å¤§ä½¬çš„ç¥æŠ€ï¼Œäºæ˜¯ä¹æˆ‘å°±å¾ˆçˆ½å¿«æ¥äº†è¿™ä¸ªMySQLæ•…éšœæ¢å¤ï¼Œæ­¤æ¬¡æ•…éšœçš„æ˜¯ä¸€ä¸ªæ•°æ®ç›˜ï¼Œ1Tã€‚&lt;br&gt;è¿™æ—¶çš„æˆ‘ï¼Œè¯´çœŸçš„å¹¶æ²¡æœ‰æ„è¯†åˆ°ï¼Œæ­¤äº‹æ˜¯å¦‚æ­¤çš„ç¹æ‚ï¼Œç‰¹æ­¤å†™æ­¤åšæ–‡è®°å½•ä¸€ä¸‹ï¼Œæ¯•ç«ŸJå“¥æˆ‘å¹´çºªä¹Ÿå¤§äº†ã€‚&lt;/p&gt;&lt;p&gt;PS:&lt;br&gt;è¿™é‡Œåæ§½ä¸€ä¸‹ï¼Œå¹¶æ²¡æœ‰å‘¨æ—¥å…¨å¤‡+å‘¨1~å‘¨6å¢é‡å¤‡ä»½æœºåˆ¶å“Ÿï¼Œä¸ç„¶æ¢å¤å°±çˆ½æ­ªæ­ªäº†ã€‚&lt;br&gt;
    
    </summary>
    
      <category term="å…¶ä»–ç»„ä»¶" scheme="http://yoursite.com/categories/%E5%85%B6%E4%BB%96%E7%BB%84%E4%BB%B6/"/>
    
    
      <category term="æ¶æ„" scheme="http://yoursite.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="ç¯å¢ƒæ­å»º" scheme="http://yoursite.com/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="æ¡ˆä¾‹" scheme="http://yoursite.com/tags/%E6%A1%88%E4%BE%8B/"/>
    
  </entry>
  
  <entry>
    <title>è‹¥æ³½æ•°æ®-CDH5.16.1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²(å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ)</title>
    <link href="http://yoursite.com/2019/05/13/%E8%8B%A5%E6%B3%BD%E6%95%B0%E6%8D%AE-CDH5.16.1%E9%9B%86%E7%BE%A4%E4%BC%81%E4%B8%9A%E7%9C%9F%E6%AD%A3%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2(%E5%85%A8%E7%BD%91%E6%9C%80%E7%BB%86%EF%BC%8C%E9%85%8D%E5%A5%97%E8%A7%86%E9%A2%91%EF%BC%8C%E7%94%9F%E4%BA%A7%E5%8F%AF%E5%AE%9E%E8%B7%B5)/"/>
    <id>http://yoursite.com/2019/05/13/è‹¥æ³½æ•°æ®-CDH5.16.1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²(å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ)/</id>
    <published>2019-05-12T16:00:00.000Z</published>
    <updated>2019-05-30T05:27:04.836Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu May 30 2019 13:27:35 GMT+0800 (GMT+08:00) --><h2 id="è‹¥æ³½æ•°æ®"><a href="#è‹¥æ³½æ•°æ®" class="headerlink" title="è‹¥æ³½æ•°æ®"></a><a href="www.ruozedata.com">è‹¥æ³½æ•°æ®</a></h2><h2 id="CDH5-16-1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²-å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ"><a href="#CDH5-16-1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²-å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ" class="headerlink" title="CDH5.16.1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²(å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ)"></a>CDH5.16.1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²(å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ)</h2><p>è§†é¢‘:<a href="https://www.bilibili.com/video/av52167219" target="_blank" rel="noopener">https://www.bilibili.com/video/av52167219</a><br>PS:å»ºè®®å…ˆçœ‹è¯¾ç¨‹è§†é¢‘1-2ç¯‡ï¼Œå†æ ¹æ®è§†é¢‘æˆ–æ–‡æ¡£éƒ¨ç½²ï¼Œ<br>å¦‚æœ‰é—®é¢˜ï¼ŒåŠæ—¶ä¸@è‹¥æ³½æ•°æ®Jå“¥è”ç³»ã€‚</p><a id="more"></a><hr><h2 id="ä¸€-å‡†å¤‡å·¥ä½œ"><a href="#ä¸€-å‡†å¤‡å·¥ä½œ" class="headerlink" title="ä¸€.å‡†å¤‡å·¥ä½œ"></a>ä¸€.å‡†å¤‡å·¥ä½œ</h2><h4 id="1-ç¦»çº¿éƒ¨ç½²ä¸»è¦åˆ†ä¸ºä¸‰å—"><a href="#1-ç¦»çº¿éƒ¨ç½²ä¸»è¦åˆ†ä¸ºä¸‰å—" class="headerlink" title="1.ç¦»çº¿éƒ¨ç½²ä¸»è¦åˆ†ä¸ºä¸‰å—:"></a>1.ç¦»çº¿éƒ¨ç½²ä¸»è¦åˆ†ä¸ºä¸‰å—:</h4><p>a.MySQLç¦»çº¿éƒ¨ç½²<br>b.CMç¦»çº¿éƒ¨ç½²<br>c.Parcelæ–‡ä»¶ç¦»çº¿æºéƒ¨ç½²</p><h4 id="2-è§„åˆ’"><a href="#2-è§„åˆ’" class="headerlink" title="2.è§„åˆ’:"></a>2.è§„åˆ’:</h4><table><thead><tr><th>èŠ‚ç‚¹</th><th>MySQLéƒ¨ç½²ç»„ä»¶</th><th>Parcelæ–‡ä»¶ç¦»çº¿æº</th><th>CMæœåŠ¡è¿›ç¨‹</th><th>å¤§æ•°æ®ç»„ä»¶</th></tr></thead><tbody><tr><td>hadoop001</td><td>MySQL</td><td>Parcel</td><td>Activity Monitor<br></td><td>NN RM DN NM</td></tr><tr><td>hadoop002</td><td></td><td></td><td>Alert Publisher<br>Event Server</td><td>DN NM</td></tr><tr><td>hadoop003</td><td></td><td></td><td>Host Monitor<br>Service Monitor</td><td>DN NM</td></tr></tbody></table><h3 id="3-ä¸‹è½½æº"><a href="#3-ä¸‹è½½æº" class="headerlink" title="3.ä¸‹è½½æº:"></a>3.ä¸‹è½½æº:</h3><ul><li>CM<br><a href="http://archive.cloudera.com/cm5/cm/5/cloudera-manager-centos7-cm5.16.1_x86_64.tar.gz" target="_blank" rel="noopener">cloudera-manager-centos7-cm5.16.1_x86_64.tar.gz</a></li><li>Parcel<br><a href="http://archive.cloudera.com/cdh5/parcels/5.16.1/CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel" target="_blank" rel="noopener">CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel</a><br><a href="http://archive.cloudera.com/cdh5/parcels/5.16.1/CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel.sha1" target="_blank" rel="noopener">CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel.sha1</a><br><a href="http://archive.cloudera.com/cdh5/parcels/5.16.1/manifest.json" target="_blank" rel="noopener">manifest.json</a></li><li><p>JDK<br><a href="https://www.oracle.com/technetwork/java/javase/downloads/java-archive-javase8-2177648.html" target="_blank" rel="noopener">https://www.oracle.com/technetwork/java/javase/downloads/java-archive-javase8-2177648.html</a><br>ä¸‹è½½jdk-8u202-linux-x64.tar.gz</p></li><li><p>MySQL<br><a href="https://dev.mysql.com/downloads/mysql/5.7.html#downloads" target="_blank" rel="noopener">https://dev.mysql.com/downloads/mysql/5.7.html#downloads</a><br>ä¸‹è½½mysql-5.7.26-el7-x86_64.tar.gz</p></li><li><p>MySQL jdbc jar<br><a href="http://central.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar" target="_blank" rel="noopener">mysql-connector-java-5.1.47.jar</a><br>ä¸‹è½½å®Œæˆåè¦é‡å‘½åå»æ‰ç‰ˆæœ¬å·ï¼Œ<br>mv mysql-connector-java-5.1.47.jar mysql-connector-java.jar</p></li></ul><hr><p>###å‡†å¤‡å¥½ç™¾åº¦äº‘,ä¸‹è½½å®‰è£…åŒ…:<br>é“¾æ¥:<a href="https://pan.baidu.com/s/10s-NaFLfztKuWImZTiBMjA" target="_blank" rel="noopener">https://pan.baidu.com/s/10s-NaFLfztKuWImZTiBMjA</a> å¯†ç :viqp</p><h2 id="äºŒ-é›†ç¾¤èŠ‚ç‚¹åˆå§‹åŒ–"><a href="#äºŒ-é›†ç¾¤èŠ‚ç‚¹åˆå§‹åŒ–" class="headerlink" title="äºŒ.é›†ç¾¤èŠ‚ç‚¹åˆå§‹åŒ–"></a>äºŒ.é›†ç¾¤èŠ‚ç‚¹åˆå§‹åŒ–</h2><h3 id="1-é˜¿é‡Œäº‘ä¸Šæµ·åŒºè´­ä¹°3å°ï¼ŒæŒ‰é‡ä»˜è´¹è™šæ‹Ÿæœº"><a href="#1-é˜¿é‡Œäº‘ä¸Šæµ·åŒºè´­ä¹°3å°ï¼ŒæŒ‰é‡ä»˜è´¹è™šæ‹Ÿæœº" class="headerlink" title="1.é˜¿é‡Œäº‘ä¸Šæµ·åŒºè´­ä¹°3å°ï¼ŒæŒ‰é‡ä»˜è´¹è™šæ‹Ÿæœº"></a>1.é˜¿é‡Œäº‘ä¸Šæµ·åŒºè´­ä¹°3å°ï¼ŒæŒ‰é‡ä»˜è´¹è™šæ‹Ÿæœº</h3><p>CentOS7.2æ“ä½œç³»ç»Ÿï¼Œ2æ ¸8Gæœ€ä½é…ç½®</p><h3 id="2-å½“å‰ç¬”è®°æœ¬æˆ–å°å¼æœºé…ç½®hostsæ–‡ä»¶"><a href="#2-å½“å‰ç¬”è®°æœ¬æˆ–å°å¼æœºé…ç½®hostsæ–‡ä»¶" class="headerlink" title="2.å½“å‰ç¬”è®°æœ¬æˆ–å°å¼æœºé…ç½®hostsæ–‡ä»¶"></a>2.å½“å‰ç¬”è®°æœ¬æˆ–å°å¼æœºé…ç½®hostsæ–‡ä»¶</h3><ul><li>MAC: /etc/hosts</li><li>Window: C:\windows\system32\drivers\etc\hosts</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">å…¬ç½‘åœ°å€: </span><br><span class="line">106.15.234.222 hadoop001  </span><br><span class="line">106.15.235.200 hadoop002  </span><br><span class="line">106.15.234.239 hadoop003</span><br></pre></td></tr></table></figure><h3 id="3-è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„hostsæ–‡ä»¶"><a href="#3-è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„hostsæ–‡ä»¶" class="headerlink" title="3.è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„hostsæ–‡ä»¶"></a>3.è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„hostsæ–‡ä»¶</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ç§æœ‰åœ°é“ã€å†…ç½‘åœ°å€:</span><br><span class="line">echo &quot;172.19.7.96 hadoop001&quot;&gt;&gt; /etc/hosts</span><br><span class="line">echo &quot;172.19.7.98 hadoop002&quot;&gt;&gt; /etc/hosts</span><br><span class="line">echo &quot;172.19.7.97 hadoop003&quot;&gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure><h3 id="4-å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„é˜²ç«å¢™åŠæ¸…ç©ºè§„åˆ™"><a href="#4-å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„é˜²ç«å¢™åŠæ¸…ç©ºè§„åˆ™" class="headerlink" title="4.å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„é˜²ç«å¢™åŠæ¸…ç©ºè§„åˆ™"></a>4.å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„é˜²ç«å¢™åŠæ¸…ç©ºè§„åˆ™</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld </span><br><span class="line">systemctl disable firewalld</span><br><span class="line">iptables -F</span><br></pre></td></tr></table></figure><h3 id="5-å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„selinux"><a href="#5-å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„selinux" class="headerlink" title="5.å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„selinux"></a>5.å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„selinux</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/selinux/config</span><br><span class="line">å°†SELINUX=enforcingæ”¹ä¸ºSELINUX=disabled </span><br><span class="line">è®¾ç½®åéœ€è¦é‡å¯æ‰èƒ½ç”Ÿæ•ˆ</span><br></pre></td></tr></table></figure><h3 id="6-è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„æ—¶åŒºä¸€è‡´åŠæ—¶é’ŸåŒæ­¥"><a href="#6-è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„æ—¶åŒºä¸€è‡´åŠæ—¶é’ŸåŒæ­¥" class="headerlink" title="6.è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„æ—¶åŒºä¸€è‡´åŠæ—¶é’ŸåŒæ­¥"></a>6.è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„æ—¶åŒºä¸€è‡´åŠæ—¶é’ŸåŒæ­¥</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">6.1.æ—¶åŒº</span><br><span class="line">[root@hadoop001 ~]# date</span><br><span class="line">Sat May 11 10:07:53 CST 2019</span><br><span class="line">[root@hadoop001 ~]# timedatectl</span><br><span class="line">      Local time: Sat 2019-05-11 10:10:31 CST</span><br><span class="line">  Universal time: Sat 2019-05-11 02:10:31 UTC</span><br><span class="line">        RTC time: Sat 2019-05-11 10:10:29</span><br><span class="line">       Time zone: Asia/Shanghai (CST, +0800)</span><br><span class="line">     NTP enabled: yes</span><br><span class="line">NTP synchronized: yes</span><br><span class="line"> RTC in local TZ: yes</span><br><span class="line">      DST active: n/a</span><br><span class="line"></span><br><span class="line">#æŸ¥çœ‹å‘½ä»¤å¸®åŠ©ï¼Œå­¦ä¹ è‡³å…³é‡è¦ï¼Œæ— éœ€ç™¾åº¦ï¼Œå¤ªğŸ‘</span><br><span class="line">[root@hadoop001 ~]# timedatectl --help</span><br><span class="line">timedatectl [OPTIONS...] COMMAND ...</span><br><span class="line"></span><br><span class="line">Query or change system time and date settings.</span><br><span class="line"></span><br><span class="line">  -h --help                Show this help message</span><br><span class="line">     --version             Show package version</span><br><span class="line">     --no-pager            Do not pipe output into a pager</span><br><span class="line">     --no-ask-password     Do not prompt for password</span><br><span class="line">  -H --host=[USER@]HOST    Operate on remote host</span><br><span class="line">  -M --machine=CONTAINER   Operate on local container</span><br><span class="line">     --adjust-system-clock Adjust system clock when changing local RTC mode</span><br><span class="line"></span><br><span class="line">Commands:</span><br><span class="line">  status                   Show current time settings</span><br><span class="line">  set-time TIME            Set system time</span><br><span class="line">  set-timezone ZONE        Set system time zone</span><br><span class="line">  list-timezones           Show known time zones</span><br><span class="line">  set-local-rtc BOOL       Control whether RTC is in local time</span><br><span class="line">  set-ntp BOOL             Control whether NTP is enabled</span><br><span class="line"></span><br><span class="line">#æŸ¥çœ‹å“ªäº›æ—¶åŒº</span><br><span class="line">[root@hadoop001 ~]# timedatectl list-timezones</span><br><span class="line">Africa/Abidjan</span><br><span class="line">Africa/Accra</span><br><span class="line">Africa/Addis_Ababa</span><br><span class="line">Africa/Algiers</span><br><span class="line">Africa/Asmara</span><br><span class="line">Africa/Bamako</span><br><span class="line"></span><br><span class="line">#æ‰€æœ‰èŠ‚ç‚¹è®¾ç½®äºšæ´²ä¸Šæµ·æ—¶åŒº </span><br><span class="line">[root@hadoop001 ~]# timedatectl set-timezone Asia/Shanghai</span><br><span class="line">[root@hadoop002 ~]# timedatectl set-timezone Asia/Shanghai</span><br><span class="line">[root@hadoop003 ~]# timedatectl set-timezone Asia/Shanghai</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">6.2.æ—¶é—´</span><br><span class="line">#æ‰€æœ‰èŠ‚ç‚¹å®‰è£…ntp</span><br><span class="line">[root@hadoop001 ~]# yum install -y ntp</span><br><span class="line"></span><br><span class="line">#é€‰å–hadoop001ä¸ºntpçš„ä¸»èŠ‚ç‚¹</span><br><span class="line">[root@hadoop001 ~]# vi /etc/ntp.conf </span><br><span class="line"></span><br><span class="line">#time</span><br><span class="line">server 0.asia.pool.ntp.org</span><br><span class="line">server 1.asia.pool.ntp.org</span><br><span class="line">server 2.asia.pool.ntp.org</span><br><span class="line">server 3.asia.pool.ntp.org</span><br><span class="line">#å½“å¤–éƒ¨æ—¶é—´ä¸å¯ç”¨æ—¶ï¼Œå¯ä½¿ç”¨æœ¬åœ°ç¡¬ä»¶æ—¶é—´</span><br><span class="line">server 127.127.1.0 iburst local clock </span><br><span class="line">#å…è®¸å“ªäº›ç½‘æ®µçš„æœºå™¨æ¥åŒæ­¥æ—¶é—´</span><br><span class="line">restrict 172.19.7.0 mask 255.255.255.0 nomodify notrap</span><br><span class="line"></span><br><span class="line">#å¼€å¯ntpdåŠæŸ¥çœ‹çŠ¶æ€</span><br><span class="line">[root@hadoop001 ~]# systemctl start ntpd</span><br><span class="line">[root@hadoop001 ~]# systemctl status ntpd</span><br><span class="line"> ntpd.service - Network Time Service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/ntpd.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Sat 2019-05-11 10:15:00 CST; 11min ago</span><br><span class="line"> Main PID: 18518 (ntpd)</span><br><span class="line">   CGroup: /system.slice/ntpd.service</span><br><span class="line">           â””â”€18518 /usr/sbin/ntpd -u ntp:ntp -g</span><br><span class="line"></span><br><span class="line">May 11 10:15:00 hadoop001 systemd[1]: Starting Network Time Service...</span><br><span class="line">May 11 10:15:00 hadoop001 ntpd[18518]: proto: precision = 0.088 usec</span><br><span class="line">May 11 10:15:00 hadoop001 ntpd[18518]: 0.0.0.0 c01d 0d kern kernel time sync enabled</span><br><span class="line">May 11 10:15:00 hadoop001 systemd[1]: Started Network Time Service.</span><br><span class="line"></span><br><span class="line">#éªŒè¯</span><br><span class="line">[root@hadoop001 ~]# ntpq -p</span><br><span class="line">     remote           refid      st t when poll reach   delay   offset  jitter</span><br><span class="line">==============================================================================</span><br><span class="line"> LOCAL(0)        .LOCL.          10 l  726   64    0    0.000    0.000   0.000</span><br><span class="line"></span><br><span class="line">#å…¶ä»–ä»èŠ‚ç‚¹åœæ­¢ç¦ç”¨ntpdæœåŠ¡ </span><br><span class="line">[root@hadoop002 ~]# systemctl stop ntpd</span><br><span class="line">[root@hadoop002 ~]# systemctl disable ntpd</span><br><span class="line">Removed symlink /etc/systemd/system/multi-user.target.wants/ntpd.service.</span><br><span class="line">[root@hadoop002 ~]# /usr/sbin/ntpdate hadoop001</span><br><span class="line">11 May 10:29:22 ntpdate[9370]: adjust time server 172.19.7.96 offset 0.000867 sec</span><br><span class="line">#æ¯å¤©å‡Œæ™¨åŒæ­¥hadoop001èŠ‚ç‚¹æ—¶é—´</span><br><span class="line">[root@hadoop002 ~]# crontab -e</span><br><span class="line">00 00 * * * /usr/sbin/ntpdate hadoop001  </span><br><span class="line"></span><br><span class="line">[root@hadoop003 ~]# systemctl stop ntpd</span><br><span class="line">[root@hadoop004 ~]# systemctl disable ntpd</span><br><span class="line">Removed symlink /etc/systemd/system/multi-user.target.wants/ntpd.service.</span><br><span class="line">[root@hadoop005 ~]# /usr/sbin/ntpdate hadoop001</span><br><span class="line">11 May 10:29:22 ntpdate[9370]: adjust time server 172.19.7.96 offset 0.000867 sec</span><br><span class="line">#æ¯å¤©å‡Œæ™¨åŒæ­¥hadoop001èŠ‚ç‚¹æ—¶é—´</span><br><span class="line">[root@hadoop003 ~]# crontab -e</span><br><span class="line">00 00 * * * /usr/sbin/ntpdate hadoop001</span><br></pre></td></tr></table></figure><h3 id="7-éƒ¨ç½²é›†ç¾¤çš„JDK"><a href="#7-éƒ¨ç½²é›†ç¾¤çš„JDK" class="headerlink" title="7.éƒ¨ç½²é›†ç¾¤çš„JDK"></a>7.éƒ¨ç½²é›†ç¾¤çš„JDK</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mkdir /usr/java</span><br><span class="line">tar -xzvf jdk-8u45-linux-x64.tar.gz -C /usr/java/</span><br><span class="line">#åˆ‡è®°å¿…é¡»ä¿®æ­£æ‰€å±ç”¨æˆ·åŠç”¨æˆ·ç»„</span><br><span class="line">chown -R root:root /usr/java/jdk1.8.0_45</span><br><span class="line"></span><br><span class="line">echo &quot;export JAVA_HOME=/usr/java/jdk1.8.0_45&quot; &gt;&gt; /etc/profile</span><br><span class="line">echo &quot;export PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;PATH&#125;&quot; &gt;&gt; /etc/profile</span><br><span class="line">source /etc/profile</span><br><span class="line">which java</span><br></pre></td></tr></table></figure><h3 id="8-hadoop001èŠ‚ç‚¹ç¦»çº¿éƒ¨ç½²MySQL5-7-å‡å¦‚è§‰å¾—å›°éš¾å“Ÿï¼Œå°±è‡ªè¡Œç™¾åº¦RPMéƒ¨ç½²ï¼Œå› ä¸ºè¯¥éƒ¨ç½²æ–‡æ¡£æ˜¯æˆ‘å¸ç”Ÿäº§æ–‡æ¡£"><a href="#8-hadoop001èŠ‚ç‚¹ç¦»çº¿éƒ¨ç½²MySQL5-7-å‡å¦‚è§‰å¾—å›°éš¾å“Ÿï¼Œå°±è‡ªè¡Œç™¾åº¦RPMéƒ¨ç½²ï¼Œå› ä¸ºè¯¥éƒ¨ç½²æ–‡æ¡£æ˜¯æˆ‘å¸ç”Ÿäº§æ–‡æ¡£" class="headerlink" title="8.hadoop001èŠ‚ç‚¹ç¦»çº¿éƒ¨ç½²MySQL5.7(å‡å¦‚è§‰å¾—å›°éš¾å“Ÿï¼Œå°±è‡ªè¡Œç™¾åº¦RPMéƒ¨ç½²ï¼Œå› ä¸ºè¯¥éƒ¨ç½²æ–‡æ¡£æ˜¯æˆ‘å¸ç”Ÿäº§æ–‡æ¡£)"></a>8.hadoop001èŠ‚ç‚¹ç¦»çº¿éƒ¨ç½²MySQL5.7(å‡å¦‚è§‰å¾—å›°éš¾å“Ÿï¼Œå°±è‡ªè¡Œç™¾åº¦RPMéƒ¨ç½²ï¼Œå› ä¸ºè¯¥éƒ¨ç½²æ–‡æ¡£æ˜¯æˆ‘å¸ç”Ÿäº§æ–‡æ¡£)</h3><ul><li>æ–‡æ¡£é“¾æ¥:<a href="https://github.com/Hackeruncle/MySQL" target="_blank" rel="noopener">https://github.com/Hackeruncle/MySQL</a></li><li>è§†é¢‘é“¾æ¥:<a href="https://pan.baidu.com/s/1jdM8WeIg8syU0evL1-tDOQ" target="_blank" rel="noopener">https://pan.baidu.com/s/1jdM8WeIg8syU0evL1-tDOQ</a> å¯†ç :whic</li></ul><h3 id="9-åˆ›å»ºCDHçš„å…ƒæ•°æ®åº“å’Œç”¨æˆ·ã€amonæœåŠ¡çš„æ•°æ®åº“åŠç”¨æˆ·"><a href="#9-åˆ›å»ºCDHçš„å…ƒæ•°æ®åº“å’Œç”¨æˆ·ã€amonæœåŠ¡çš„æ•°æ®åº“åŠç”¨æˆ·" class="headerlink" title="9.åˆ›å»ºCDHçš„å…ƒæ•°æ®åº“å’Œç”¨æˆ·ã€amonæœåŠ¡çš„æ•°æ®åº“åŠç”¨æˆ·"></a>9.åˆ›å»ºCDHçš„å…ƒæ•°æ®åº“å’Œç”¨æˆ·ã€amonæœåŠ¡çš„æ•°æ®åº“åŠç”¨æˆ·</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">create database cmf DEFAULT CHARACTER SET utf8;</span><br><span class="line">create database amon DEFAULT CHARACTER SET utf8;</span><br><span class="line">grant all on cmf.* TO &apos;cmf&apos;@&apos;%&apos; IDENTIFIED BY &apos;Ruozedata123456!&apos;;</span><br><span class="line">grant all on amon.* TO &apos;amon&apos;@&apos;%&apos; IDENTIFIED BY &apos;Ruozedata123456!&apos;;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><h3 id="10-hadoop001èŠ‚ç‚¹éƒ¨ç½²mysql-jdbc-jar"><a href="#10-hadoop001èŠ‚ç‚¹éƒ¨ç½²mysql-jdbc-jar" class="headerlink" title="10.hadoop001èŠ‚ç‚¹éƒ¨ç½²mysql jdbc jar"></a>10.hadoop001èŠ‚ç‚¹éƒ¨ç½²mysql jdbc jar</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /usr/share/java/</span><br><span class="line">cp mysql-connector-java.jar /usr/share/java/</span><br></pre></td></tr></table></figure><h2 id="ä¸‰-CDHéƒ¨ç½²"><a href="#ä¸‰-CDHéƒ¨ç½²" class="headerlink" title="ä¸‰.CDHéƒ¨ç½²"></a>ä¸‰.CDHéƒ¨ç½²</h2><h3 id="1-ç¦»çº¿éƒ¨ç½²cm-serveråŠagent"><a href="#1-ç¦»çº¿éƒ¨ç½²cm-serveråŠagent" class="headerlink" title="1.ç¦»çº¿éƒ¨ç½²cm serveråŠagent"></a>1.ç¦»çº¿éƒ¨ç½²cm serveråŠagent</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">1.1.æ‰€æœ‰èŠ‚ç‚¹åˆ›å»ºç›®å½•åŠè§£å‹</span><br><span class="line">mkdir /opt/cloudera-manager</span><br><span class="line">tar -zxvf cloudera-manager-centos7-cm5.16.1_x86_64.tar.gz -C /opt/cloudera-manager/</span><br><span class="line"></span><br><span class="line">1.2.æ‰€æœ‰èŠ‚ç‚¹ä¿®æ”¹agentçš„é…ç½®ï¼ŒæŒ‡å‘serverçš„èŠ‚ç‚¹hadoop001</span><br><span class="line">sed -i &quot;s/server_host=localhost/server_host=hadoop001/g&quot; /opt/cloudera-manager/cm-5.16.1/etc/cloudera-scm-agent/config.ini</span><br><span class="line"></span><br><span class="line">1.3.ä¸»èŠ‚ç‚¹ä¿®æ”¹serverçš„é…ç½®:</span><br><span class="line">vi /opt/cloudera-manager/cm-5.16.1/etc/cloudera-scm-server/db.properties </span><br><span class="line">com.cloudera.cmf.db.type=mysql</span><br><span class="line">com.cloudera.cmf.db.host=hadoop001</span><br><span class="line">com.cloudera.cmf.db.name=cmf</span><br><span class="line">com.cloudera.cmf.db.user=cmf</span><br><span class="line">com.cloudera.cmf.db.password=Ruozedata123456!</span><br><span class="line">com.cloudera.cmf.db.setupType=EXTERNAL</span><br><span class="line"></span><br><span class="line">1.4.æ‰€æœ‰èŠ‚ç‚¹åˆ›å»ºç”¨æˆ·</span><br><span class="line">useradd --system --home=/opt/cloudera-manager/cm-5.16.1/run/cloudera-scm-server/ --no-create-home --shell=/bin/false --comment &quot;Cloudera SCM User&quot; cloudera-scm</span><br><span class="line"></span><br><span class="line">1.5.ç›®å½•ä¿®æ”¹ç”¨æˆ·åŠç”¨æˆ·ç»„</span><br><span class="line">chown -R cloudera-scm:cloudera-scm /opt/cloudera-manager</span><br></pre></td></tr></table></figure><h3 id="2-hadoop001èŠ‚ç‚¹éƒ¨ç½²ç¦»çº¿parcelæº"><a href="#2-hadoop001èŠ‚ç‚¹éƒ¨ç½²ç¦»çº¿parcelæº" class="headerlink" title="2.hadoop001èŠ‚ç‚¹éƒ¨ç½²ç¦»çº¿parcelæº"></a>2.hadoop001èŠ‚ç‚¹éƒ¨ç½²ç¦»çº¿parcelæº</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">2.1.éƒ¨ç½²ç¦»çº¿parcelæº</span><br><span class="line">$ mkdir -p /opt/cloudera/parcel-repo</span><br><span class="line">$ ll</span><br><span class="line">total 3081664</span><br><span class="line">-rw-r--r-- 1 root root 2127506677 May  9 18:04 CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel</span><br><span class="line">-rw-r--r-- 1 root root         41 May  9 18:03 CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel.sha1</span><br><span class="line">-rw-r--r-- 1 root root  841524318 May  9 18:03 cloudera-manager-centos7-cm5.16.1_x86_64.tar.gz</span><br><span class="line">-rw-r--r-- 1 root root  185515842 Aug 10  2017 jdk-8u144-linux-x64.tar.gz</span><br><span class="line">-rw-r--r-- 1 root root      66538 May  9 18:03 manifest.json</span><br><span class="line">-rw-r--r-- 1 root root     989495 May 25  2017 mysql-connector-java.jar</span><br><span class="line">$ cp CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel /opt/cloudera/parcel-repo/</span><br><span class="line"></span><br><span class="line">#åˆ‡è®°cpæ—¶ï¼Œé‡å‘½åå»æ‰1ï¼Œä¸ç„¶åœ¨éƒ¨ç½²è¿‡ç¨‹CMè®¤ä¸ºå¦‚ä¸Šæ–‡ä»¶ä¸‹è½½æœªå®Œæ•´ï¼Œä¼šæŒç»­ä¸‹è½½</span><br><span class="line">$ cp CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel.sha1 /opt/cloudera/parcel-repo/CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel.sha</span><br><span class="line">$ cp manifest.json /opt/cloudera/parcel-repo/</span><br><span class="line"></span><br><span class="line">2.2.ç›®å½•ä¿®æ”¹ç”¨æˆ·åŠç”¨æˆ·ç»„</span><br><span class="line">$ chown -R cloudera-scm:cloudera-scm /opt/cloudera/</span><br></pre></td></tr></table></figure><h3 id="3-æ‰€æœ‰èŠ‚ç‚¹åˆ›å»ºè½¯ä»¶å®‰è£…ç›®å½•ã€ç”¨æˆ·åŠç”¨æˆ·ç»„æƒé™"><a href="#3-æ‰€æœ‰èŠ‚ç‚¹åˆ›å»ºè½¯ä»¶å®‰è£…ç›®å½•ã€ç”¨æˆ·åŠç”¨æˆ·ç»„æƒé™" class="headerlink" title="3.æ‰€æœ‰èŠ‚ç‚¹åˆ›å»ºè½¯ä»¶å®‰è£…ç›®å½•ã€ç”¨æˆ·åŠç”¨æˆ·ç»„æƒé™"></a>3.æ‰€æœ‰èŠ‚ç‚¹åˆ›å»ºè½¯ä»¶å®‰è£…ç›®å½•ã€ç”¨æˆ·åŠç”¨æˆ·ç»„æƒé™</h3><p>mkdir -p /opt/cloudera/parcels<br>chown -R cloudera-scm:cloudera-scm /opt/cloudera/</p><h3 id="4-hadoop001èŠ‚ç‚¹å¯åŠ¨Server"><a href="#4-hadoop001èŠ‚ç‚¹å¯åŠ¨Server" class="headerlink" title="4.hadoop001èŠ‚ç‚¹å¯åŠ¨Server"></a>4.hadoop001èŠ‚ç‚¹å¯åŠ¨Server</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">4.1.å¯åŠ¨server</span><br><span class="line">/opt/cloudera-manager/cm-5.16.1/etc/init.d/cloudera-scm-server start</span><br><span class="line"></span><br><span class="line">4.2.é˜¿é‡Œäº‘webç•Œé¢ï¼Œè®¾ç½®è¯¥hadoop001èŠ‚ç‚¹é˜²ç«å¢™æ”¾å¼€7180ç«¯å£</span><br><span class="line">4.3.ç­‰å¾…1minï¼Œæ‰“å¼€ http://hadoop001:7180 è´¦å·å¯†ç :admin/admin</span><br><span class="line">4.4.å‡å¦‚æ‰“ä¸å¼€ï¼Œå»çœ‹serverçš„logï¼Œæ ¹æ®é”™è¯¯ä»”ç»†æ’æŸ¥é”™è¯¯</span><br></pre></td></tr></table></figure><h3 id="5-æ‰€æœ‰èŠ‚ç‚¹å¯åŠ¨Agent"><a href="#5-æ‰€æœ‰èŠ‚ç‚¹å¯åŠ¨Agent" class="headerlink" title="5.æ‰€æœ‰èŠ‚ç‚¹å¯åŠ¨Agent"></a>5.æ‰€æœ‰èŠ‚ç‚¹å¯åŠ¨Agent</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/cloudera-manager/cm-5.16.1/etc/init.d/cloudera-scm-agent start</span><br></pre></td></tr></table></figure><h3 id="6-æ¥ä¸‹æ¥ï¼Œå…¨éƒ¨Webç•Œé¢æ“ä½œ"><a href="#6-æ¥ä¸‹æ¥ï¼Œå…¨éƒ¨Webç•Œé¢æ“ä½œ" class="headerlink" title="6.æ¥ä¸‹æ¥ï¼Œå…¨éƒ¨Webç•Œé¢æ“ä½œ"></a>6.æ¥ä¸‹æ¥ï¼Œå…¨éƒ¨Webç•Œé¢æ“ä½œ</h3><p><a href="http://hadoop001:7180/" target="_blank" rel="noopener">http://hadoop001:7180/</a><br>è´¦å·å¯†ç :admin/admin</p><h3 id="7-æ¬¢è¿ä½¿ç”¨Cloudera-Managerâ€“æœ€ç»ˆç”¨æˆ·è®¸å¯æ¡æ¬¾ä¸æ¡ä»¶ã€‚å‹¾é€‰"><a href="#7-æ¬¢è¿ä½¿ç”¨Cloudera-Managerâ€“æœ€ç»ˆç”¨æˆ·è®¸å¯æ¡æ¬¾ä¸æ¡ä»¶ã€‚å‹¾é€‰" class="headerlink" title="7.æ¬¢è¿ä½¿ç”¨Cloudera Managerâ€“æœ€ç»ˆç”¨æˆ·è®¸å¯æ¡æ¬¾ä¸æ¡ä»¶ã€‚å‹¾é€‰"></a>7.æ¬¢è¿ä½¿ç”¨Cloudera Managerâ€“æœ€ç»ˆç”¨æˆ·è®¸å¯æ¡æ¬¾ä¸æ¡ä»¶ã€‚å‹¾é€‰</h3><p><img src="install pictures/1.png" alt="avatar"></p><h3 id="8-æ¬¢è¿ä½¿ç”¨Cloudera-Managerâ€“æ‚¨æƒ³è¦éƒ¨ç½²å“ªä¸ªç‰ˆæœ¬ï¼Ÿé€‰æ‹©Cloudera-Expresså…è´¹ç‰ˆæœ¬"><a href="#8-æ¬¢è¿ä½¿ç”¨Cloudera-Managerâ€“æ‚¨æƒ³è¦éƒ¨ç½²å“ªä¸ªç‰ˆæœ¬ï¼Ÿé€‰æ‹©Cloudera-Expresså…è´¹ç‰ˆæœ¬" class="headerlink" title="8.æ¬¢è¿ä½¿ç”¨Cloudera Managerâ€“æ‚¨æƒ³è¦éƒ¨ç½²å“ªä¸ªç‰ˆæœ¬ï¼Ÿé€‰æ‹©Cloudera Expresså…è´¹ç‰ˆæœ¬"></a>8.æ¬¢è¿ä½¿ç”¨Cloudera Managerâ€“æ‚¨æƒ³è¦éƒ¨ç½²å“ªä¸ªç‰ˆæœ¬ï¼Ÿé€‰æ‹©Cloudera Expresså…è´¹ç‰ˆæœ¬</h3><p><img src="install pictures/2.png" alt="avatar"></p><h3 id="9-æ„Ÿè°¢æ‚¨é€‰æ‹©Cloudera-Managerå’ŒCDH"><a href="#9-æ„Ÿè°¢æ‚¨é€‰æ‹©Cloudera-Managerå’ŒCDH" class="headerlink" title="9.æ„Ÿè°¢æ‚¨é€‰æ‹©Cloudera Managerå’ŒCDH"></a>9.æ„Ÿè°¢æ‚¨é€‰æ‹©Cloudera Managerå’ŒCDH</h3><p><img src="install pictures/3.png" alt="avatar"></p><h3 id="10-ä¸ºCDHé›†ç¾¤å®‰è£…æŒ‡å¯¼ä¸»æœºã€‚é€‰æ‹©-å½“å‰ç®¡ç†çš„ä¸»æœº-ï¼Œå…¨éƒ¨å‹¾é€‰"><a href="#10-ä¸ºCDHé›†ç¾¤å®‰è£…æŒ‡å¯¼ä¸»æœºã€‚é€‰æ‹©-å½“å‰ç®¡ç†çš„ä¸»æœº-ï¼Œå…¨éƒ¨å‹¾é€‰" class="headerlink" title="10.ä¸ºCDHé›†ç¾¤å®‰è£…æŒ‡å¯¼ä¸»æœºã€‚é€‰æ‹©[å½“å‰ç®¡ç†çš„ä¸»æœº]ï¼Œå…¨éƒ¨å‹¾é€‰"></a>10.ä¸ºCDHé›†ç¾¤å®‰è£…æŒ‡å¯¼ä¸»æœºã€‚é€‰æ‹©[å½“å‰ç®¡ç†çš„ä¸»æœº]ï¼Œå…¨éƒ¨å‹¾é€‰</h3><p><img src="install pictures/4.png" alt="avatar"></p><h3 id="11-é€‰æ‹©å­˜å‚¨åº“"><a href="#11-é€‰æ‹©å­˜å‚¨åº“" class="headerlink" title="11.é€‰æ‹©å­˜å‚¨åº“"></a>11.é€‰æ‹©å­˜å‚¨åº“</h3><p><img src="install pictures/5.png" alt="avatar"></p><h3 id="12-é›†ç¾¤å®‰è£…â€“æ­£åœ¨å®‰è£…é€‰å®šParcelå‡å¦‚"><a href="#12-é›†ç¾¤å®‰è£…â€“æ­£åœ¨å®‰è£…é€‰å®šParcelå‡å¦‚" class="headerlink" title="12.é›†ç¾¤å®‰è£…â€“æ­£åœ¨å®‰è£…é€‰å®šParcelå‡å¦‚"></a>12.é›†ç¾¤å®‰è£…â€“æ­£åœ¨å®‰è£…é€‰å®šParcelå‡å¦‚</h3><p>æœ¬åœ°parcelç¦»çº¿æºé…ç½®æ­£ç¡®ï¼Œåˆ™â€ä¸‹è½½â€é˜¶æ®µç¬é—´å®Œæˆï¼Œå…¶ä½™é˜¶æ®µè§†èŠ‚ç‚¹æ•°ä¸å†…éƒ¨ç½‘ç»œæƒ…å†µå†³å®šã€‚<br><img src="install pictures/6.png" alt="avatar"></p><h3 id="13-æ£€æŸ¥ä¸»æœºæ­£ç¡®æ€§"><a href="#13-æ£€æŸ¥ä¸»æœºæ­£ç¡®æ€§" class="headerlink" title="13.æ£€æŸ¥ä¸»æœºæ­£ç¡®æ€§"></a>13.æ£€æŸ¥ä¸»æœºæ­£ç¡®æ€§</h3><p><img src="install pictures/7.png" alt="avatar"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">13.1.å»ºè®®å°†/proc/sys/vm/swappinessè®¾ç½®ä¸ºæœ€å¤§å€¼10ã€‚</span><br><span class="line">swappinesså€¼æ§åˆ¶æ“ä½œç³»ç»Ÿå°è¯•äº¤æ¢å†…å­˜çš„ç§¯æï¼›</span><br><span class="line">swappiness=0ï¼šè¡¨ç¤ºæœ€å¤§é™åº¦ä½¿ç”¨ç‰©ç†å†…å­˜ï¼Œä¹‹åæ‰æ˜¯swapç©ºé—´ï¼›</span><br><span class="line">swappiness=100ï¼šè¡¨ç¤ºç§¯æä½¿ç”¨swapåˆ†åŒºï¼Œå¹¶ä¸”æŠŠå†…å­˜ä¸Šçš„æ•°æ®åŠæ—¶æ¬è¿åˆ°swapç©ºé—´ï¼›</span><br><span class="line">å¦‚æœæ˜¯æ··åˆæœåŠ¡å™¨ï¼Œä¸å»ºè®®å®Œå…¨ç¦ç”¨swapï¼Œå¯ä»¥å°è¯•é™ä½swappinessã€‚</span><br><span class="line"></span><br><span class="line">ä¸´æ—¶è°ƒæ•´ï¼š</span><br><span class="line">sysctl vm.swappiness=10</span><br><span class="line"></span><br><span class="line">æ°¸ä¹…è°ƒæ•´ï¼š</span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; /etc/sysctl.conf</span><br><span class="line"># Adjust swappiness value</span><br><span class="line">vm.swappiness=10</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">13.2.å·²å¯ç”¨é€æ˜å¤§é¡µé¢å‹ç¼©ï¼Œå¯èƒ½ä¼šå¯¼è‡´é‡å¤§æ€§èƒ½é—®é¢˜ï¼Œå»ºè®®ç¦ç”¨æ­¤è®¾ç½®ã€‚</span><br><span class="line">ä¸´æ—¶è°ƒæ•´ï¼š</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line"></span><br><span class="line">æ°¸ä¹…è°ƒæ•´ï¼š</span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; /etc/rc.d/rc.local</span><br><span class="line"># Disable transparent_hugepage</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># centos7.xç³»ç»Ÿï¼Œéœ€è¦ä¸º&quot;/etc/rc.d/rc.local&quot;æ–‡ä»¶èµ‹äºˆæ‰§è¡Œæƒé™</span><br><span class="line">chmod +x /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure><h3 id="14-è‡ªå®šä¹‰æœåŠ¡ï¼Œé€‰æ‹©éƒ¨ç½²Zookeeperã€HDFSã€YarnæœåŠ¡"><a href="#14-è‡ªå®šä¹‰æœåŠ¡ï¼Œé€‰æ‹©éƒ¨ç½²Zookeeperã€HDFSã€YarnæœåŠ¡" class="headerlink" title="14.è‡ªå®šä¹‰æœåŠ¡ï¼Œé€‰æ‹©éƒ¨ç½²Zookeeperã€HDFSã€YarnæœåŠ¡"></a>14.è‡ªå®šä¹‰æœåŠ¡ï¼Œé€‰æ‹©éƒ¨ç½²Zookeeperã€HDFSã€YarnæœåŠ¡</h3><p><img src="install pictures/8.png" alt="avatar"></p><h3 id="15-è‡ªå®šä¹‰è§’è‰²åˆ†é…"><a href="#15-è‡ªå®šä¹‰è§’è‰²åˆ†é…" class="headerlink" title="15.è‡ªå®šä¹‰è§’è‰²åˆ†é…"></a>15.è‡ªå®šä¹‰è§’è‰²åˆ†é…</h3><p><img src="install pictures/9.png" alt="avatar"></p><h3 id="16-æ•°æ®åº“è®¾ç½®"><a href="#16-æ•°æ®åº“è®¾ç½®" class="headerlink" title="16.æ•°æ®åº“è®¾ç½®"></a>16.æ•°æ®åº“è®¾ç½®</h3><p><img src="install pictures/10.png" alt="avatar"></p><h3 id="17-å®¡æ”¹è®¾ç½®ï¼Œé»˜è®¤å³å¯"><a href="#17-å®¡æ”¹è®¾ç½®ï¼Œé»˜è®¤å³å¯" class="headerlink" title="17.å®¡æ”¹è®¾ç½®ï¼Œé»˜è®¤å³å¯"></a>17.å®¡æ”¹è®¾ç½®ï¼Œé»˜è®¤å³å¯</h3><p><img src="install pictures/11.png" alt="avatar"></p><h3 id="18-é¦–æ¬¡è¿è¡Œ"><a href="#18-é¦–æ¬¡è¿è¡Œ" class="headerlink" title="18.é¦–æ¬¡è¿è¡Œ"></a>18.é¦–æ¬¡è¿è¡Œ</h3><p><img src="install pictures/12.png" alt="avatar"></p><h3 id="19-æ­å–œæ‚¨"><a href="#19-æ­å–œæ‚¨" class="headerlink" title="19.æ­å–œæ‚¨!"></a>19.æ­å–œæ‚¨!</h3><p><img src="install pictures/13.png" alt="avatar"></p><h3 id="20-ä¸»é¡µ"><a href="#20-ä¸»é¡µ" class="headerlink" title="20.ä¸»é¡µ"></a>20.ä¸»é¡µ</h3><p><img src="install pictures/14.png" alt="avatar"></p><hr><h3 id="CDHå…¨å¥—è¯¾ç¨‹ç›®å½•ï¼Œå¦‚æœ‰buyï¼ŒåŠ å¾®ä¿¡-ruoze-star"><a href="#CDHå…¨å¥—è¯¾ç¨‹ç›®å½•ï¼Œå¦‚æœ‰buyï¼ŒåŠ å¾®ä¿¡-ruoze-star" class="headerlink" title="CDHå…¨å¥—è¯¾ç¨‹ç›®å½•ï¼Œå¦‚æœ‰buyï¼ŒåŠ å¾®ä¿¡(ruoze_star)"></a>CDHå…¨å¥—è¯¾ç¨‹ç›®å½•ï¼Œå¦‚æœ‰buyï¼ŒåŠ å¾®ä¿¡(ruoze_star)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">0.é’äº‘ç¯å¢ƒä»‹ç»å’Œä½¿ç”¨ </span><br><span class="line">1.Preparation        </span><br><span class="line">è°ˆè°ˆæ€æ ·å…¥é—¨å¤§æ•°æ® </span><br><span class="line">è°ˆè°ˆæ€æ ·åšå¥½ä¸€ä¸ªå¤§æ•°æ®å¹³å°çš„è¿è¥å·¥ä½œ </span><br><span class="line">Linuxæœºå™¨,å„è½¯ä»¶ç‰ˆæœ¬ä»‹ç»åŠå®‰è£…(å½•æ’­) </span><br><span class="line">2.Introduction      </span><br><span class="line">Clouderaã€CMåŠCDHä»‹ç» </span><br><span class="line">CDHç‰ˆæœ¬é€‰æ‹© </span><br><span class="line">CDHå®‰è£…å‡ ç§æ–¹å¼è§£è¯» </span><br><span class="line">3.Install&amp;UnInstall  </span><br><span class="line">é›†ç¾¤èŠ‚ç‚¹è§„åˆ’,ç¯å¢ƒå‡†å¤‡(NTP,Jdk and etc) </span><br><span class="line">MySQLç¼–è¯‘å®‰è£…åŠå¸¸ç”¨å‘½ä»¤ </span><br><span class="line">æ¨è:CDHç¦»çº¿å®‰è£…(è¸©å‘å¿ƒå¾—,å…¨é¢å‰–æ) </span><br><span class="line">è§£è¯»æš´åŠ›å¸è½½è„šæœ¬ </span><br><span class="line"></span><br><span class="line">4.CDH Management      </span><br><span class="line">CDHä½“ç³»æ¶æ„å‰–æ </span><br><span class="line">CDHé…ç½®æ–‡ä»¶æ·±åº¦è§£æ </span><br><span class="line">CMçš„å¸¸ç”¨å‘½ä»¤ </span><br><span class="line">CDHé›†ç¾¤æ­£ç¡®å¯åŠ¨å’Œåœæ­¢é¡ºåº </span><br><span class="line">CDH Tsquery Language </span><br><span class="line">CDHå¸¸è§„ç®¡ç†(ç›‘æ§/é¢„è­¦/é…ç½®/èµ„æº/æ—¥å¿—/å®‰å…¨) </span><br><span class="line"></span><br><span class="line">5.Maintenance Experiment  </span><br><span class="line">HDFS HA é…ç½® åŠhadoop/hdfså¸¸è§„å‘½ä»¤ </span><br><span class="line">Yarn HA é…ç½® åŠyarnå¸¸è§„å‘½ä»¤ </span><br><span class="line">Other CDH Components HA é…ç½® </span><br><span class="line">CDHåŠ¨æ€æ·»åŠ åˆ é™¤æœåŠ¡(hive/spark/hbase) </span><br><span class="line">CDHåŠ¨æ€æ·»åŠ åˆ é™¤æœºå™¨ </span><br><span class="line">CDHåŠ¨æ€æ·»åŠ åˆ é™¤åŠè¿ç§»DataNodeè¿›ç¨‹ç­‰ </span><br><span class="line">CDHå‡çº§(5.10.0--&gt;5.12.0) </span><br><span class="line"></span><br><span class="line">6.Resource Management    </span><br><span class="line">Linux Cgroups </span><br><span class="line">é™æ€èµ„æºæ±  </span><br><span class="line">åŠ¨æ€èµ„æºæ±  </span><br><span class="line">å¤šç§Ÿæˆ·æ¡ˆä¾‹ </span><br><span class="line"></span><br><span class="line">7.Performance Tunning    </span><br><span class="line">Memory/CPU/Network/DiskåŠé›†ç¾¤è§„åˆ’ </span><br><span class="line">Linuxå‚æ•° </span><br><span class="line">HDFSå‚æ•° </span><br><span class="line">MapReduceåŠYarnå‚æ•° </span><br><span class="line">å…¶ä»–æœåŠ¡å‚æ•° </span><br><span class="line"></span><br><span class="line">8.Cases Share </span><br><span class="line">CDH4&amp;5ä¹‹Alternativeså‘½ä»¤ çš„ç ”ç©¶ </span><br><span class="line">CDH5.8.2å®‰è£…ä¹‹Hash verification failed </span><br><span class="line">è®°å½•ä¸€æ¬¡CDH4.8.6 é…ç½®HDFS HA å‘ </span><br><span class="line">CDH5.0é›†ç¾¤IPæ›´æ”¹ </span><br><span class="line">CDHçš„active namenode exit(GC)å’Œå½©è›‹åˆ†äº« </span><br><span class="line"></span><br><span class="line">9. Kerberos</span><br><span class="line">Kerberosç®€ä»‹</span><br><span class="line">Kerberosä½“ç³»ç»“æ„</span><br><span class="line">Kerberoså·¥ä½œæœºåˆ¶</span><br><span class="line">Kerberoså®‰è£…éƒ¨ç½²</span><br><span class="line">CDHå¯ç”¨kerberos</span><br><span class="line">Kerberoså¼€å‘ä½¿ç”¨(çœŸå®ä»£ç )</span><br><span class="line"></span><br><span class="line">10.Summary         </span><br><span class="line">æ€»ç»“</span><br></pre></td></tr></table></figure><hr><h4 id="Join-us-if-you-have-a-dream"><a href="#Join-us-if-you-have-a-dream" class="headerlink" title="Join us if you have a dream."></a>Join us if you have a dream.</h4><h5 id="è‹¥æ³½æ•°æ®å®˜ç½‘-http-ruozedata-com"><a href="#è‹¥æ³½æ•°æ®å®˜ç½‘-http-ruozedata-com" class="headerlink" title="è‹¥æ³½æ•°æ®å®˜ç½‘: http://ruozedata.com"></a>è‹¥æ³½æ•°æ®å®˜ç½‘: <a href="http://ruozedata.com" target="_blank" rel="noopener">http://ruozedata.com</a></h5><h5 id="è…¾è®¯è¯¾å ‚ï¼Œæœè‹¥æ³½æ•°æ®-http-ruoze-ke-qq-com"><a href="#è…¾è®¯è¯¾å ‚ï¼Œæœè‹¥æ³½æ•°æ®-http-ruoze-ke-qq-com" class="headerlink" title="è…¾è®¯è¯¾å ‚ï¼Œæœè‹¥æ³½æ•°æ®: http://ruoze.ke.qq.com"></a>è…¾è®¯è¯¾å ‚ï¼Œæœè‹¥æ³½æ•°æ®: <a href="http://ruoze.ke.qq.com" target="_blank" rel="noopener">http://ruoze.ke.qq.com</a></h5><h5 id="Bilibiliç½‘ç«™-æœè‹¥æ³½æ•°æ®-https-space-bilibili-com-356836323"><a href="#Bilibiliç½‘ç«™-æœè‹¥æ³½æ•°æ®-https-space-bilibili-com-356836323" class="headerlink" title="Bilibiliç½‘ç«™,æœè‹¥æ³½æ•°æ®: https://space.bilibili.com/356836323"></a>Bilibiliç½‘ç«™,æœè‹¥æ³½æ•°æ®: <a href="https://space.bilibili.com/356836323" target="_blank" rel="noopener">https://space.bilibili.com/356836323</a></h5><h5 id="è‹¥æ³½å¤§æ•°æ®â€“å®˜æ–¹åšå®¢"><a href="#è‹¥æ³½å¤§æ•°æ®â€“å®˜æ–¹åšå®¢" class="headerlink" title="è‹¥æ³½å¤§æ•°æ®â€“å®˜æ–¹åšå®¢"></a><a href="https://ruozedata.github.io" target="_blank" rel="noopener">è‹¥æ³½å¤§æ•°æ®â€“å®˜æ–¹åšå®¢</a></h5><h5 id="è‹¥æ³½å¤§æ•°æ®â€“åšå®¢ä¸€è§ˆ"><a href="#è‹¥æ³½å¤§æ•°æ®â€“åšå®¢ä¸€è§ˆ" class="headerlink" title="è‹¥æ³½å¤§æ•°æ®â€“åšå®¢ä¸€è§ˆ"></a><a href="https://github.com/ruozedata/BigData/blob/master/blog/BigDataBlogOverview.md" target="_blank" rel="noopener">è‹¥æ³½å¤§æ•°æ®â€“åšå®¢ä¸€è§ˆ</a></h5><h5 id="è‹¥æ³½å¤§æ•°æ®â€“å†…éƒ¨å­¦å‘˜é¢è¯•é¢˜"><a href="#è‹¥æ³½å¤§æ•°æ®â€“å†…éƒ¨å­¦å‘˜é¢è¯•é¢˜" class="headerlink" title="è‹¥æ³½å¤§æ•°æ®â€“å†…éƒ¨å­¦å‘˜é¢è¯•é¢˜"></a><a href="https://github.com/ruozedata/BigData/blob/master/interview/%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98.md" target="_blank" rel="noopener">è‹¥æ³½å¤§æ•°æ®â€“å†…éƒ¨å­¦å‘˜é¢è¯•é¢˜</a></h5><h5 id="æ‰«ä¸€æ‰«ï¼Œå­¦ä¸€å­¦"><a href="#æ‰«ä¸€æ‰«ï¼Œå­¦ä¸€å­¦" class="headerlink" title="æ‰«ä¸€æ‰«ï¼Œå­¦ä¸€å­¦:"></a>æ‰«ä¸€æ‰«ï¼Œå­¦ä¸€å­¦:</h5><p><img src="install pictures/è‹¥æ³½æ•°æ®--æ‰«æå…¥å£.png" alt="avatar"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu May 30 2019 13:27:35 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;è‹¥æ³½æ•°æ®&quot;&gt;&lt;a href=&quot;#è‹¥æ³½æ•°æ®&quot; class=&quot;headerlink&quot; title=&quot;è‹¥æ³½æ•°æ®&quot;&gt;&lt;/a&gt;&lt;a href=&quot;www.ruozedata.com&quot;&gt;è‹¥æ³½æ•°æ®&lt;/a&gt;&lt;/h2&gt;&lt;h2 id=&quot;CDH5-16-1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²-å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ&quot;&gt;&lt;a href=&quot;#CDH5-16-1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²-å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ&quot; class=&quot;headerlink&quot; title=&quot;CDH5.16.1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²(å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ)&quot;&gt;&lt;/a&gt;CDH5.16.1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²(å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ)&lt;/h2&gt;&lt;p&gt;è§†é¢‘:&lt;a href=&quot;https://www.bilibili.com/video/av52167219&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.bilibili.com/video/av52167219&lt;/a&gt;&lt;br&gt;PS:å»ºè®®å…ˆçœ‹è¯¾ç¨‹è§†é¢‘1-2ç¯‡ï¼Œå†æ ¹æ®è§†é¢‘æˆ–æ–‡æ¡£éƒ¨ç½²ï¼Œ&lt;br&gt;å¦‚æœ‰é—®é¢˜ï¼ŒåŠæ—¶ä¸@è‹¥æ³½æ•°æ®Jå“¥è”ç³»ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="CDH" scheme="http://yoursite.com/categories/CDH/"/>
    
    
      <category term="cdh" scheme="http://yoursite.com/tags/cdh/"/>
    
  </entry>
  
  <entry>
    <title>dockerå¸¸ç”¨å‘½ä»¤ä»¥åŠå®‰è£…mysql</title>
    <link href="http://yoursite.com/2019/05/08/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%BB%A5%E5%8F%8A%E5%AE%89%E8%A3%85mysql/"/>
    <id>http://yoursite.com/2019/05/08/dockerå¸¸ç”¨å‘½ä»¤ä»¥åŠå®‰è£…mysql/</id>
    <published>2019-05-07T16:00:00.000Z</published>
    <updated>2019-05-13T08:00:04.117Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --><h3 id="1-ç®€ä»‹"><a href="#1-ç®€ä»‹" class="headerlink" title="1.ç®€ä»‹"></a>1.ç®€ä»‹</h3><p>Dockeræ˜¯ä¸€ä¸ªå¼€æºçš„åº”ç”¨å®¹å™¨å¼•æ“ï¼›æ˜¯ä¸€ä¸ªè½»é‡çº§å®¹å™¨æŠ€æœ¯ï¼›</p><p>Dockeræ”¯æŒå°†è½¯ä»¶ç¼–è¯‘æˆä¸€ä¸ªé•œåƒï¼›ç„¶ååœ¨é•œåƒä¸­å„ç§è½¯ä»¶åšå¥½é…ç½®ï¼Œå°†é•œåƒå‘å¸ƒå‡ºå»ï¼Œå…¶ä»–ä½¿ç”¨è€…å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™ä¸ªé•œåƒï¼›</p><p>è¿è¡Œä¸­çš„è¿™ä¸ªé•œåƒç§°ä¸ºå®¹å™¨ï¼Œå®¹å™¨å¯åŠ¨æ˜¯éå¸¸å¿«é€Ÿçš„ã€‚<br><a id="more"></a></p><h3 id="2-æ ¸å¿ƒæ¦‚å¿µ"><a href="#2-æ ¸å¿ƒæ¦‚å¿µ" class="headerlink" title="2.æ ¸å¿ƒæ¦‚å¿µ"></a>2.æ ¸å¿ƒæ¦‚å¿µ</h3><p>dockerä¸»æœº(Host)ï¼šå®‰è£…äº†Dockerç¨‹åºçš„æœºå™¨ï¼ˆDockerç›´æ¥å®‰è£…åœ¨æ“ä½œç³»ç»Ÿä¹‹ä¸Šï¼‰ï¼›</p><p>dockerå®¢æˆ·ç«¯(Client)ï¼šè¿æ¥dockerä¸»æœºè¿›è¡Œæ“ä½œï¼›</p><p>dockerä»“åº“(Registry)ï¼šç”¨æ¥ä¿å­˜å„ç§æ‰“åŒ…å¥½çš„è½¯ä»¶é•œåƒï¼›</p><p>dockeré•œåƒ(Images)ï¼šè½¯ä»¶æ‰“åŒ…å¥½çš„é•œåƒï¼›æ”¾åœ¨dockerä»“åº“ä¸­ï¼›</p><p>dockerå®¹å™¨(Container)ï¼šé•œåƒå¯åŠ¨åçš„å®ä¾‹ç§°ä¸ºä¸€ä¸ªå®¹å™¨ï¼›å®¹å™¨æ˜¯ç‹¬ç«‹è¿è¡Œçš„ä¸€ä¸ªæˆ–ä¸€ç»„åº”ç”¨</p><h3 id="3-å®‰è£…ç¯å¢ƒ"><a href="#3-å®‰è£…ç¯å¢ƒ" class="headerlink" title="3.å®‰è£…ç¯å¢ƒ"></a>3.å®‰è£…ç¯å¢ƒ</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">VM ware Workstation10</span><br><span class="line">CentOS-7-x86_64-DVD-1804.iso</span><br><span class="line">uname -r</span><br><span class="line">3.10.0-862.el7.x86_64</span><br></pre></td></tr></table></figure><p><strong>æ£€æŸ¥å†…æ ¸ç‰ˆæœ¬ï¼Œå¿…é¡»æ˜¯3.10åŠä»¥ä¸Š</strong> æŸ¥çœ‹å‘½ä»¤ï¼šuname -r</p><h3 id="4-åœ¨linuxè™šæ‹Ÿæœºä¸Šå®‰è£…docker"><a href="#4-åœ¨linuxè™šæ‹Ÿæœºä¸Šå®‰è£…docker" class="headerlink" title="4.åœ¨linuxè™šæ‹Ÿæœºä¸Šå®‰è£…docker"></a>4.åœ¨linuxè™šæ‹Ÿæœºä¸Šå®‰è£…docker</h3><p>æ­¥éª¤ï¼š</p><p>1ã€æ£€æŸ¥å†…æ ¸ç‰ˆæœ¬ï¼Œå¿…é¡»æ˜¯3.10åŠä»¥ä¸Š<br>uname -r</p><p>2ã€å®‰è£…docker<br>yum install docker</p><p>3ã€è¾“å…¥yç¡®è®¤å®‰è£…<br>Dependency Updated:<br>audit.x86_64 0:2.8.1-3.el7_5.1 audit-libs.x86_64 0:2.8.1-3.el7_5.1</p><p>Complete!<br>(æˆåŠŸæ ‡å¿—)</p><p>4ã€å¯åŠ¨docker<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop000 ~]# systemctl start docker</span><br><span class="line">[root@hadoop000 ~]# docker -v</span><br><span class="line">Docker version 1.13.1, build 8633870/1.13.1</span><br></pre></td></tr></table></figure><p></p><p>5ã€å¼€æœºå¯åŠ¨docker<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop000 ~]# systemctl enable docker</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.</span><br></pre></td></tr></table></figure><p></p><p>6ã€åœæ­¢docker<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop000 ~]# systemctl stop docker</span><br><span class="line">``` </span><br><span class="line">### 5.å¸¸ç”¨å‘½ä»¤</span><br><span class="line"></span><br><span class="line">é•œåƒæ“ä½œ</span><br><span class="line">|æ“ä½œ|å‘½ä»¤|è¯´æ˜|</span><br><span class="line">|---|---|---|</span><br><span class="line">æ£€ç´¢|docker search å…³é”®å­— egï¼šdocker search redis|æˆ‘ä»¬ç»å¸¸å»docker hubä¸Šæ£€ç´¢é•œåƒçš„è¯¦ç»†ä¿¡æ¯ï¼Œå¦‚é•œåƒçš„TAGã€‚|</span><br><span class="line">æ‹‰å–|docker pull é•œåƒå:tag|:tagæ˜¯å¯é€‰çš„ï¼Œtagè¡¨ç¤ºæ ‡ç­¾ï¼Œå¤šä¸ºè½¯ä»¶çš„ç‰ˆæœ¬ï¼Œé»˜è®¤æ˜¯latest</span><br><span class="line">åˆ—è¡¨|docker images|æŸ¥çœ‹æ‰€æœ‰æœ¬åœ°é•œåƒ</span><br><span class="line">åˆ é™¤|docker rmi image-id|åˆ é™¤æŒ‡å®šçš„æœ¬åœ°é•œåƒ</span><br><span class="line"></span><br><span class="line">å½“ç„¶å¤§å®¶ä¹Ÿå¯ä»¥åœ¨å®˜ç½‘æŸ¥æ‰¾ï¼šhttps://hub.docker.com/</span><br><span class="line"></span><br><span class="line">å®¹å™¨æ“ä½œ</span><br><span class="line">è½¯ä»¶é•œåƒï¼ˆQQå®‰è£…ç¨‹åºï¼‰----è¿è¡Œé•œåƒ----äº§ç”Ÿä¸€ä¸ªå®¹å™¨ï¼ˆæ­£åœ¨è¿è¡Œçš„è½¯ä»¶ï¼Œè¿è¡Œçš„QQï¼‰ï¼›</span><br><span class="line"></span><br><span class="line">æ­¥éª¤ï¼š</span><br><span class="line"></span><br><span class="line">- 1ã€æœç´¢é•œåƒ</span><br><span class="line">[root@localhost ~]# docker search tomcat</span><br><span class="line">- 2ã€æ‹‰å–é•œåƒ</span><br><span class="line">[root@localhost ~]# docker pull tomcat</span><br><span class="line">- 3ã€æ ¹æ®é•œåƒå¯åŠ¨å®¹å™¨</span><br><span class="line">docker run --name mytomcat -d tomcat:latest</span><br><span class="line">- 4ã€docker ps  </span><br><span class="line">æŸ¥çœ‹è¿è¡Œä¸­çš„å®¹å™¨</span><br><span class="line">- 5ã€ åœæ­¢è¿è¡Œä¸­çš„å®¹å™¨</span><br><span class="line">docker stop  å®¹å™¨çš„id</span><br><span class="line">- 6ã€æŸ¥çœ‹æ‰€æœ‰çš„å®¹å™¨</span><br><span class="line">docker ps -a</span><br><span class="line">- 7ã€å¯åŠ¨å®¹å™¨</span><br><span class="line">docker start å®¹å™¨id</span><br><span class="line">- 8ã€åˆ é™¤ä¸€ä¸ªå®¹å™¨</span><br><span class="line"> docker rm å®¹å™¨id</span><br><span class="line">- 9ã€å¯åŠ¨ä¸€ä¸ªåšäº†ç«¯å£æ˜ å°„çš„tomcat</span><br><span class="line">[root@localhost ~]# docker run -d -p 8888:8080 tomcat</span><br><span class="line">-dï¼šåå°è¿è¡Œ</span><br><span class="line">-p: å°†ä¸»æœºçš„ç«¯å£æ˜ å°„åˆ°å®¹å™¨çš„ä¸€ä¸ªç«¯å£    ä¸»æœºç«¯å£:å®¹å™¨å†…éƒ¨çš„ç«¯å£</span><br><span class="line"></span><br><span class="line">- 10ã€ä¸ºäº†æ¼”ç¤ºç®€å•å…³é—­äº†linuxçš„é˜²ç«å¢™</span><br><span class="line">service firewalld status ï¼›æŸ¥çœ‹é˜²ç«å¢™çŠ¶æ€</span><br><span class="line">service firewalld stopï¼šå…³é—­é˜²ç«å¢™</span><br><span class="line">systemctl disable firewalld.service #ç¦æ­¢firewallå¼€æœºå¯åŠ¨</span><br><span class="line">- 11ã€æŸ¥çœ‹å®¹å™¨çš„æ—¥å¿—</span><br><span class="line">docker logs container-name/container-id</span><br><span class="line"></span><br><span class="line">æ›´å¤šå‘½ä»¤å‚çœ‹</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/docker/</span><br><span class="line">å¯ä»¥å‚è€ƒé•œåƒæ–‡æ¡£</span><br><span class="line"></span><br><span class="line">### 6.ä½¿ç”¨dockerå®‰è£…mysql</span><br><span class="line"></span><br><span class="line">- docker pull mysql</span><br></pre></td></tr></table></figure><p></p><p>docker pull mysql<br>Using default tag: latest<br>Trying to pull repository docker.io/library/mysql â€¦<br>latest: Pulling from docker.io/library/mysql<br>a5a6f2f73cd8: Pull complete<br>936836019e67: Pull complete<br>283fa4c95fb4: Pull complete<br>1f212fb371f9: Pull complete<br>e2ae0d063e89: Pull complete<br>5ed0ae805b65: Pull complete<br>0283dc49ef4e: Pull complete<br>a7e1170b4fdb: Pull complete<br>88918a9e4742: Pull complete<br>241282fa67c2: Pull complete<br>b0fecf619210: Pull complete<br>bebf9f901dcc: Pull complete<br>Digest: sha256:b7f7479f0a2e7a3f4ce008329572f3497075dc000d8b89bac3134b0fb0288de8<br>Status: Downloaded newer image for docker.io/mysql:latest<br>[root@hadoop000 ~]# docker images<br>REPOSITORY TAG IMAGE ID CREATED SIZE<br>docker.io/mysql latest f991c20cb508 10 days ago 486 MB<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- å¯åŠ¨</span><br></pre></td></tr></table></figure><p></p><p>[root@hadoop000 ~]# docker images<br>REPOSITORY TAG IMAGE ID CREATED SIZE<br>docker.io/mysql latest f991c20cb508 10 days ago 486 MB<br>[root@hadoop000 ~]# docker run â€“name mysql01 -d mysql<br>756620c8e5832f4f7ef3e82117c31760d18ec169d45b8d48c0a10ff2536dcc4a<br>[root@hadoop000 ~]# docker ps -a<br>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES<br>756620c8e583 mysql â€œdocker-entrypointâ€¦â€ 9 seconds ago Exited (1) 7 seconds ago mysql01<br>[root@hadoop000 ~]# docker logs 756620c8e583<br>error: database is uninitialized and password option is not specified<br>You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">å¯ä»¥çœ‹åˆ°ä¸Šé¢å¯åŠ¨çš„æ–¹å¼æ˜¯é”™è¯¯çš„ï¼Œæç¤ºæˆ‘ä»¬è¦å¸¦ä¸Šå…·ä½“çš„å¯†ç </span><br></pre></td></tr></table></figure><p></p><p>[root@hadoop000 ~]# docker run -p 3306:3306 â€“name mysql02 -e MYSQL_ROOT_PASSWORD=123456 -d mysql<br>eae86796e132027df994e5f29775eb04c6a1039a92905c247f1d149714fedc06<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">```</span><br><span class="line">â€“nameï¼šç»™æ–°åˆ›å»ºçš„å®¹å™¨å‘½åï¼Œæ­¤å¤„å‘½åä¸ºpwc-mysql</span><br><span class="line">-eï¼šé…ç½®ä¿¡æ¯ï¼Œæ­¤å¤„é…ç½®mysqlçš„rootç”¨æˆ·çš„ç™»é™†å¯†ç </span><br><span class="line">-pï¼šç«¯å£æ˜ å°„ï¼Œæ­¤å¤„æ˜ å°„ä¸»æœº3306ç«¯å£åˆ°å®¹å™¨pwc-mysqlçš„3306ç«¯å£</span><br><span class="line">-dï¼šæˆåŠŸå¯åŠ¨å®¹å™¨åè¾“å‡ºå®¹å™¨çš„å®Œæ•´IDï¼Œä¾‹å¦‚ä¸Šå›¾ 73f8811f669ee...</span><br></pre></td></tr></table></figure><p></p><ul><li><p>æŸ¥çœ‹æ˜¯å¦å¯åŠ¨æˆåŠŸ</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop000 ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                               NAMES</span><br><span class="line">eae86796e132        mysql               &quot;docker-entrypoint...&quot;   8 minutes ago       Up 8 minutes        0.0.0.0:3306-&gt;3306/tcp, 33060/tcp   mysql02</span><br></pre></td></tr></table></figure></li><li><p>ç™»é™†MySQL</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it mysql04 /bin/bash</span><br><span class="line">root@e34aba02c0c3:/# mysql -uroot -p123456 </span><br><span class="line">mysql: [Warning] Using a password on the command line interface can be insecure.</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 80</span><br><span class="line">Server version: 8.0.13 MySQL Community Server - GPL</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure></li><li><p>å…¶ä»–çš„é«˜çº§æ“ä½œ</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker run --name mysql03 -v /conf/mysql:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag</span><br><span class="line">æŠŠä¸»æœºçš„/conf/mysqlæ–‡ä»¶å¤¹æŒ‚è½½åˆ° mysqldockerå®¹å™¨çš„/etc/mysql/conf.dæ–‡ä»¶å¤¹é‡Œé¢</span><br><span class="line">æ”¹mysqlçš„é…ç½®æ–‡ä»¶å°±åªéœ€è¦æŠŠmysqlé…ç½®æ–‡ä»¶æ”¾åœ¨è‡ªå®šä¹‰çš„æ–‡ä»¶å¤¹ä¸‹ï¼ˆ/conf/mysqlï¼‰</span><br><span class="line"></span><br><span class="line">docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci</span><br><span class="line">æŒ‡å®šmysqlçš„ä¸€äº›é…ç½®å‚æ•°</span><br></pre></td></tr></table></figure></li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --&gt;&lt;h3 id=&quot;1-ç®€ä»‹&quot;&gt;&lt;a href=&quot;#1-ç®€ä»‹&quot; class=&quot;headerlink&quot; title=&quot;1.ç®€ä»‹&quot;&gt;&lt;/a&gt;1.ç®€ä»‹&lt;/h3&gt;&lt;p&gt;Dockeræ˜¯ä¸€ä¸ªå¼€æºçš„åº”ç”¨å®¹å™¨å¼•æ“ï¼›æ˜¯ä¸€ä¸ªè½»é‡çº§å®¹å™¨æŠ€æœ¯ï¼›&lt;/p&gt;&lt;p&gt;Dockeræ”¯æŒå°†è½¯ä»¶ç¼–è¯‘æˆä¸€ä¸ªé•œåƒï¼›ç„¶ååœ¨é•œåƒä¸­å„ç§è½¯ä»¶åšå¥½é…ç½®ï¼Œå°†é•œåƒå‘å¸ƒå‡ºå»ï¼Œå…¶ä»–ä½¿ç”¨è€…å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™ä¸ªé•œåƒï¼›&lt;/p&gt;&lt;p&gt;è¿è¡Œä¸­çš„è¿™ä¸ªé•œåƒç§°ä¸ºå®¹å™¨ï¼Œå®¹å™¨å¯åŠ¨æ˜¯éå¸¸å¿«é€Ÿçš„ã€‚&lt;br&gt;
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="docker" scheme="http://yoursite.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>è‹¥æ³½æ•°æ®è¯¾ç¨‹ä¸€è§ˆ</title>
    <link href="http://yoursite.com/2019/05/08/%E8%8B%A5%E6%B3%BD%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B8%80%E8%A7%88/"/>
    <id>http://yoursite.com/2019/05/08/è‹¥æ³½æ•°æ®è¯¾ç¨‹ä¸€è§ˆ/</id>
    <published>2019-05-07T16:00:00.000Z</published>
    <updated>2019-05-13T08:00:08.535Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --><h1 id="è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—"><a href="#è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—" class="headerlink" title="è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—"></a>è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—</h1><h2 id="åŸºç¡€ç­"><a href="#åŸºç¡€ç­" class="headerlink" title="åŸºç¡€ç­"></a>åŸºç¡€ç­</h2><h3 id="Liunx"><a href="#Liunx" class="headerlink" title="Liunx"></a>Liunx</h3><ul><li>VMè™šæ‹Ÿæœºå®‰è£…</li><li>Liunxå¸¸ç”¨å‘½ä»¤ï¼ˆé‡ç‚¹ï¼‰</li><li>å¼€å‘ç¯å¢ƒæ­</li></ul><h3 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h3><ul><li>æºç å®‰è£…&amp;yumå®‰è£…</li><li>CRUDç¼–å†™</li><li>æƒé™æ§åˆ¶</li></ul><h3 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h3><ul><li>æ¶æ„ä»‹ç»&amp;&amp;æºç ç¼–è¯‘</li><li>ä¼ªåˆ†å¸ƒå¼å®‰è£…&amp;&amp;ä¼ä¸šåº”ç”¨</li><li><p>HDFSï¼ˆé‡ç‚¹ï¼‰</p><ul><li>æ¶æ„è®¾è®¡</li><li>å‰¯æœ¬æ”¾ç½®ç­–ç•¥</li><li>è¯»å†™æµç¨‹</li></ul></li><li><p>YARNï¼ˆé‡ç‚¹ï¼‰</p><ul><li>æ¶æ„è®¾è®¡</li><li>å·¥ä½œæµç¨‹</li><li>è°ƒåº¦ç®¡ç†&amp;&amp;å¸¸è§å‚æ•°é…ç½®ï¼ˆè°ƒä¼˜ï¼‰</li></ul></li><li><p>MapReduce</p><ul><li>æ¶æ„è®¾è®¡</li><li>wordcountåŸç†&amp;&amp;joinåŸç†å’Œæ¡ˆä¾‹<a id="more"></a><h3 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h3></li></ul></li><li><p>æ¶æ„è®¾è®¡</p></li><li>Hive DDL&amp;DML</li><li>joinåœ¨å¤§æ•°æ®ä¸­çš„ä½¿ç”¨</li><li>ä½¿ç”¨è‡ªå¸¦UDFå’Œå¼€å‘è‡ªå®šä¹‰UDF</li></ul><h3 id="Sqoop"><a href="#Sqoop" class="headerlink" title="Sqoop"></a>Sqoop</h3><ul><li>æ¶æ„è®¾è®¡</li><li>RDBMSå¯¼å…¥å¯¼å‡º</li></ul><h3 id="æ•´åˆé¡¹ç›®å°†æ‰€æœ‰ç»„ä»¶åˆä½œä½¿ç”¨ã€‚"><a href="#æ•´åˆé¡¹ç›®å°†æ‰€æœ‰ç»„ä»¶åˆä½œä½¿ç”¨ã€‚" class="headerlink" title="æ•´åˆé¡¹ç›®å°†æ‰€æœ‰ç»„ä»¶åˆä½œä½¿ç”¨ã€‚"></a>æ•´åˆé¡¹ç›®å°†æ‰€æœ‰ç»„ä»¶åˆä½œä½¿ç”¨ã€‚</h3><h3 id="äººå·¥æ™ºèƒ½åŸºç¡€"><a href="#äººå·¥æ™ºèƒ½åŸºç¡€" class="headerlink" title="äººå·¥æ™ºèƒ½åŸºç¡€"></a>äººå·¥æ™ºèƒ½åŸºç¡€</h3><ul><li>pythonåŸºç¡€</li><li>å¸¸ç”¨åº“â€”â€”pandasã€numpyã€sklearnã€keras</li></ul><h2 id="é«˜çº§ç­"><a href="#é«˜çº§ç­" class="headerlink" title="é«˜çº§ç­"></a>é«˜çº§ç­</h2><h3 id="scalaç¼–ç¨‹ï¼ˆé‡ç‚¹ï¼‰"><a href="#scalaç¼–ç¨‹ï¼ˆé‡ç‚¹ï¼‰" class="headerlink" title="scalaç¼–ç¨‹ï¼ˆé‡ç‚¹ï¼‰"></a>scalaç¼–ç¨‹ï¼ˆé‡ç‚¹ï¼‰</h3><h3 id="Sparkï¼ˆäº”æ˜Ÿé‡ç‚¹ï¼‰"><a href="#Sparkï¼ˆäº”æ˜Ÿé‡ç‚¹ï¼‰" class="headerlink" title="Sparkï¼ˆäº”æ˜Ÿé‡ç‚¹ï¼‰"></a>Sparkï¼ˆäº”æ˜Ÿé‡ç‚¹ï¼‰</h3><h3 id="Hadoopé«˜çº§"><a href="#Hadoopé«˜çº§" class="headerlink" title="Hadoopé«˜çº§"></a>Hadoopé«˜çº§</h3><h3 id="Hiveé«˜çº§"><a href="#Hiveé«˜çº§" class="headerlink" title="Hiveé«˜çº§"></a>Hiveé«˜çº§</h3><h3 id="Flume"><a href="#Flume" class="headerlink" title="Flume"></a>Flume</h3><h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><h3 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h3><h3 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h3><h3 id="CDH"><a href="#CDH" class="headerlink" title="CDH"></a>CDH</h3><h3 id="å®¹å™¨"><a href="#å®¹å™¨" class="headerlink" title="å®¹å™¨"></a>å®¹å™¨</h3><h3 id="è°ƒåº¦å¹³å°"><a href="#è°ƒåº¦å¹³å°" class="headerlink" title="è°ƒåº¦å¹³å°"></a>è°ƒåº¦å¹³å°</h3><h2 id="çº¿ä¸‹ç­"><a href="#çº¿ä¸‹ç­" class="headerlink" title="çº¿ä¸‹ç­"></a>çº¿ä¸‹ç­</h2><p><img src="/assets/blogImg/è‹¥æ³½æ•°æ®.png" alt="enter description here"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—&quot;&gt;&lt;a href=&quot;#è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—&quot; class=&quot;headerlink&quot; title=&quot;è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—&quot;&gt;&lt;/a&gt;è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—&lt;/h1&gt;&lt;h2 id=&quot;åŸºç¡€ç­&quot;&gt;&lt;a href=&quot;#åŸºç¡€ç­&quot; class=&quot;headerlink&quot; title=&quot;åŸºç¡€ç­&quot;&gt;&lt;/a&gt;åŸºç¡€ç­&lt;/h2&gt;&lt;h3 id=&quot;Liunx&quot;&gt;&lt;a href=&quot;#Liunx&quot; class=&quot;headerlink&quot; title=&quot;Liunx&quot;&gt;&lt;/a&gt;Liunx&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;VMè™šæ‹Ÿæœºå®‰è£…&lt;/li&gt;&lt;li&gt;Liunxå¸¸ç”¨å‘½ä»¤ï¼ˆé‡ç‚¹ï¼‰&lt;/li&gt;&lt;li&gt;å¼€å‘ç¯å¢ƒæ­&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;MySQL&quot;&gt;&lt;a href=&quot;#MySQL&quot; class=&quot;headerlink&quot; title=&quot;MySQL&quot;&gt;&lt;/a&gt;MySQL&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;æºç å®‰è£…&amp;amp;yumå®‰è£…&lt;/li&gt;&lt;li&gt;CRUDç¼–å†™&lt;/li&gt;&lt;li&gt;æƒé™æ§åˆ¶&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;Hadoop&quot;&gt;&lt;a href=&quot;#Hadoop&quot; class=&quot;headerlink&quot; title=&quot;Hadoop&quot;&gt;&lt;/a&gt;Hadoop&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;æ¶æ„ä»‹ç»&amp;amp;&amp;amp;æºç ç¼–è¯‘&lt;/li&gt;&lt;li&gt;ä¼ªåˆ†å¸ƒå¼å®‰è£…&amp;amp;&amp;amp;ä¼ä¸šåº”ç”¨&lt;/li&gt;&lt;li&gt;&lt;p&gt;HDFSï¼ˆé‡ç‚¹ï¼‰&lt;/p&gt;&lt;ul&gt;&lt;li&gt;æ¶æ„è®¾è®¡&lt;/li&gt;&lt;li&gt;å‰¯æœ¬æ”¾ç½®ç­–ç•¥&lt;/li&gt;&lt;li&gt;è¯»å†™æµç¨‹&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;YARNï¼ˆé‡ç‚¹ï¼‰&lt;/p&gt;&lt;ul&gt;&lt;li&gt;æ¶æ„è®¾è®¡&lt;/li&gt;&lt;li&gt;å·¥ä½œæµç¨‹&lt;/li&gt;&lt;li&gt;è°ƒåº¦ç®¡ç†&amp;amp;&amp;amp;å¸¸è§å‚æ•°é…ç½®ï¼ˆè°ƒä¼˜ï¼‰&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MapReduce&lt;/p&gt;&lt;ul&gt;&lt;li&gt;æ¶æ„è®¾è®¡&lt;/li&gt;&lt;li&gt;wordcountåŸç†&amp;amp;&amp;amp;joinåŸç†å’Œæ¡ˆä¾‹
    
    </summary>
    
      <category term="è¯¾ç¨‹" scheme="http://yoursite.com/categories/%E8%AF%BE%E7%A8%8B/"/>
    
    
      <category term="è¯¾ç¨‹" scheme="http://yoursite.com/tags/%E8%AF%BE%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>spark2.4.2è¯¦ç»†ä»‹ç»</title>
    <link href="http://yoursite.com/2019/04/23/spark2.4.2%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2019/04/23/spark2.4.2è¯¦ç»†ä»‹ç»/</id>
    <published>2019-04-22T16:00:00.000Z</published>
    <updated>2019-05-13T08:58:29.254Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --><p>Sparkå‘å¸ƒäº†æœ€æ–°çš„ç‰ˆæœ¬spark-2.4.2<br>æ ¹æ®å®˜ç½‘ä»‹ç»ï¼Œæ­¤ç‰ˆæœ¬å¯¹äºä½¿ç”¨spark2.4çš„ç”¨æˆ·æ¥è¯´å¸®åŠ©æ˜¯å·¨å¤§çš„</p><h4 id="ç‰ˆæœ¬ä»‹ç»"><a href="#ç‰ˆæœ¬ä»‹ç»" class="headerlink" title="ç‰ˆæœ¬ä»‹ç»"></a>ç‰ˆæœ¬ä»‹ç»</h4><p><img src="/assets/blogImg/spark2.4.2_1.jpg" alt="enter description here"><br>Spark2.4.2æ˜¯ä¸€ä¸ªåŒ…å«ç¨³å®šæ€§ä¿®å¤çš„ç»´æŠ¤ç‰ˆæœ¬ã€‚ æ­¤ç‰ˆæœ¬åŸºäºSpark2.4ç»´æŠ¤åˆ†æ”¯ã€‚<font color="#FF4500"> <strong>æˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‰€æœ‰2.4ç”¨æˆ·å‡çº§åˆ°æ­¤ç¨³å®šç‰ˆæœ¬ã€‚</strong></font><br><a id="more"></a></p><h4 id="æ˜¾è‘—çš„å˜åŒ–"><a href="#æ˜¾è‘—çš„å˜åŒ–" class="headerlink" title="æ˜¾è‘—çš„å˜åŒ–"></a>æ˜¾è‘—çš„å˜åŒ–</h4><p><img src="/assets/blogImg/spark2.4.2_2.jpg" alt="enter description here"></p><ul><li>SPARK-27419ï¼šåœ¨spark2.4ä¸­å°†spark.executor.heartbeatIntervalè®¾ç½®ä¸ºå°äº1ç§’çš„å€¼æ—¶ï¼Œå®ƒå°†å§‹ç»ˆå¤±è´¥ã€‚ å› ä¸ºè¯¥å€¼å°†è½¬æ¢ä¸º0ï¼Œå¿ƒè·³å°†å§‹ç»ˆè¶…æ—¶ï¼Œå¹¶æœ€ç»ˆç»ˆæ­¢æ‰§è¡Œç¨‹åºã€‚</li><li>è¿˜åŸSPARK-25250ï¼šå¯èƒ½å¯¼è‡´ä½œä¸šæ°¸ä¹…æŒ‚èµ·ï¼Œåœ¨2.4.2ä¸­è¿˜åŸã€‚</li></ul><h4 id="è¯¦ç»†æ›´æ”¹"><a href="#è¯¦ç»†æ›´æ”¹" class="headerlink" title="è¯¦ç»†æ›´æ”¹"></a>è¯¦ç»†æ›´æ”¹</h4><p><img src="/assets/blogImg/spark2.4.2_3.jpg" alt="enter description here"></p><h6 id="BUG"><a href="#BUG" class="headerlink" title="BUG"></a>BUG</h6><table><thead><tr><th>issues</th><th>å†…å®¹æ‘˜è¦</th></tr></thead><tbody><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-26961" target="_blank" rel="noopener">[ SPARK-26961 ]</a></td><td>åœ¨Spark Driverä¸­å‘ç°Javaæ­»é”</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-26998" target="_blank" rel="noopener">[ SPARK-26998 ]</a></td><td>åœ¨Standaloneæ¨¡å¼ä¸‹æ‰§è¡Œâ€™ps -efâ€™ç¨‹åºè¿›ç¨‹,è¾“å‡ºspark.ssl.keyStorePasswordçš„æ˜æ–‡</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27216" target="_blank" rel="noopener">[ SPARK-27216 ]</a></td><td>å°†RoaringBitmapå‡çº§åˆ°0.7.45ä»¥ä¿®å¤Kryoä¸å®‰å…¨çš„ser / dseré—®é¢˜</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27244" target="_blank" rel="noopener">[ SPARK-27244 ]</a></td><td>ä½¿ç”¨é€‰é¡¹logConf = trueæ—¶å¯†ç å°†ä»¥confçš„æ˜æ–‡å½¢å¼è®°å½•</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27267" target="_blank" rel="noopener">[ SPARK-27267 ]</a></td><td>ç”¨Snappy 1.1.7.1è§£å‹ã€å‹ç¼©ç©ºåºåˆ—åŒ–æ•°æ®æ—¶å¤±è´¥</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27275" target="_blank" rel="noopener">[ SPARK-27275 ]</a></td><td>EncryptedMessage.transferToä¸­çš„æ½œåœ¨æŸå</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27301" target="_blank" rel="noopener">[ SPARK-27301 ]</a></td><td>DStreamCheckpointDataå› æ–‡ä»¶ç³»ç»Ÿå·²ç¼“å­˜è€Œæ— æ³•æ¸…ç†</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27338" target="_blank" rel="noopener">[ SPARK-27338 ]</a></td><td>TaskMemoryManagerå’ŒUnsafeExternalSorter $ SpillableIteratorä¹‹é—´çš„æ­»é”</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27351" target="_blank" rel="noopener">[ SPARK-27351 ]</a></td><td>åœ¨ä»…ä½¿ç”¨ç©ºå€¼åˆ—çš„AggregateEstimationä¹‹åçš„é”™è¯¯outputRowsä¼°è®¡</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27390" target="_blank" rel="noopener">[ SPARK-27390 ]</a></td><td>ä¿®å¤åŒ…åç§°ä¸åŒ¹é…</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27394" target="_blank" rel="noopener">[ SPARK-27394 ]</a></td><td>å½“æ²¡æœ‰ä»»åŠ¡å¼€å§‹æˆ–ç»“æŸæ—¶ï¼ŒUI çš„é™ˆæ—§æ€§å¯èƒ½æŒç»­æ•°åˆ†é’Ÿæˆ–æ•°å°æ—¶</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27403" target="_blank" rel="noopener">[ SPARK-27403 ]</a></td><td>ä¿®å¤updateTableStatsä»¥ä½¿ç”¨æ–°ç»Ÿè®¡ä¿¡æ¯æˆ–æ— æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27406" target="_blank" rel="noopener">[ SPARK-27406 ]</a></td><td>å½“ä¸¤å°æœºå™¨å…·æœ‰ä¸åŒçš„Oopså¤§å°æ—¶ï¼ŒUnsafeArrayDataåºåˆ—åŒ–ä¼šä¸­æ–­</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27419" target="_blank" rel="noopener">[ SPARK-27419 ]</a></td><td>å°†spark.executor.heartbeatIntervalè®¾ç½®ä¸ºå°äº1ç§’çš„å€¼æ—¶ï¼Œå®ƒå°†å§‹ç»ˆå¤±è´¥</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27453" target="_blank" rel="noopener">[ SPARK-27453 ]</a></td><td>DSV1é™é»˜åˆ é™¤DataFrameWriter.partitionBy</td></tr></tbody></table><h6 id="æ”¹è¿›"><a href="#æ”¹è¿›" class="headerlink" title="æ”¹è¿›"></a>æ”¹è¿›</h6><table><thead><tr><th>issues</th><th>å†…å®¹æ‘˜è¦</th></tr></thead><tbody><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27346" target="_blank" rel="noopener">[ SPARK-27346 ]</a></td><td>æ¾å¼€åœ¨ExpressionInfoçš„â€™examplesâ€™å­—æ®µä¸­æ¢è¡Œæ–­è¨€æ¡ä»¶</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27358" target="_blank" rel="noopener">[ SPARK-27358 ]</a></td><td>å°†jqueryæ›´æ–°ä¸º1.12.xä»¥è·å–å®‰å…¨ä¿®å¤ç¨‹åº</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27479" target="_blank" rel="noopener">[ SPARK-27479 ]</a></td><td>éšè—â€œorg.apache.spark.util.kvstoreâ€çš„APIæ–‡æ¡£</td></tr></tbody></table><h6 id="å·¥ä½œ"><a href="#å·¥ä½œ" class="headerlink" title="å·¥ä½œ"></a>å·¥ä½œ</h6><table><thead><tr><th>issues</th><th>å†…å®¹æ‘˜è¦</th></tr></thead><tbody><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27382" target="_blank" rel="noopener">[ SPARK-27382 ]</a></td><td>åœ¨HiveExternalCatalogVersionsSuiteä¸­æ›´æ–°Spark 2.4.xæµ‹è¯•</td></tr></tbody></table><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;Sparkå‘å¸ƒäº†æœ€æ–°çš„ç‰ˆæœ¬spark-2.4.2&lt;br&gt;æ ¹æ®å®˜ç½‘ä»‹ç»ï¼Œæ­¤ç‰ˆæœ¬å¯¹äºä½¿ç”¨spark2.4çš„ç”¨æˆ·æ¥è¯´å¸®åŠ©æ˜¯å·¨å¤§çš„&lt;/p&gt;&lt;h4 id=&quot;ç‰ˆæœ¬ä»‹ç»&quot;&gt;&lt;a href=&quot;#ç‰ˆæœ¬ä»‹ç»&quot; class=&quot;headerlink&quot; title=&quot;ç‰ˆæœ¬ä»‹ç»&quot;&gt;&lt;/a&gt;ç‰ˆæœ¬ä»‹ç»&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;/assets/blogImg/spark2.4.2_1.jpg&quot; alt=&quot;enter description here&quot;&gt;&lt;br&gt;Spark2.4.2æ˜¯ä¸€ä¸ªåŒ…å«ç¨³å®šæ€§ä¿®å¤çš„ç»´æŠ¤ç‰ˆæœ¬ã€‚ æ­¤ç‰ˆæœ¬åŸºäºSpark2.4ç»´æŠ¤åˆ†æ”¯ã€‚&lt;font color=&quot;#FF4500&quot;&gt; &lt;strong&gt;æˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‰€æœ‰2.4ç”¨æˆ·å‡çº§åˆ°æ­¤ç¨³å®šç‰ˆæœ¬ã€‚&lt;/strong&gt;&lt;/font&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>æˆ‘å¸Kafka+Flink+MySQLç”Ÿäº§å®Œæ•´æ¡ˆä¾‹ä»£ç </title>
    <link href="http://yoursite.com/2018/12/20/%E6%88%91%E5%8F%B8Kafka+Flink+MySQL%E7%94%9F%E4%BA%A7%E5%AE%8C%E6%95%B4%E6%A1%88%E4%BE%8B%E4%BB%A3%E7%A0%81/"/>
    <id>http://yoursite.com/2018/12/20/æˆ‘å¸Kafka+Flink+MySQLç”Ÿäº§å®Œæ•´æ¡ˆä¾‹ä»£ç /</id>
    <published>2018-12-19T16:00:00.000Z</published>
    <updated>2019-05-03T01:24:05.187Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --><font color="#FF4500"><br></font><h6 id="1-ç‰ˆæœ¬ä¿¡æ¯ï¼š"><a href="#1-ç‰ˆæœ¬ä¿¡æ¯ï¼š" class="headerlink" title="1.ç‰ˆæœ¬ä¿¡æ¯ï¼š"></a>1.ç‰ˆæœ¬ä¿¡æ¯ï¼š</h6><p>Flink Version:1.6.2<br>Kafka Version:0.9.0.0<br>MySQL Version:5.6.21</p><h6 id="2-Kafka-æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š-IP-TIME-URL-STATU-CODE-REFERER"><a href="#2-Kafka-æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š-IP-TIME-URL-STATU-CODE-REFERER" class="headerlink" title="2.Kafka æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š[IP TIME URL STATU_CODE REFERER]"></a>2.Kafka æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š[IP TIME URL STATU_CODE REFERER]</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.74.103.143    2018-12-20 18:12:00  &quot;GET /class/130.html HTTP/1.1&quot;     404 https://search.yahoo.com/search?p=Flinkå®æˆ˜</span><br></pre></td></tr></table></figure><a id="more"></a><h6 id="3-å·¥ç¨‹pom-xml"><a href="#3-å·¥ç¨‹pom-xml" class="headerlink" title="3.å·¥ç¨‹pom.xml"></a>3.å·¥ç¨‹pom.xml</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&lt;scala.version&gt;2.11.8&lt;/scala.version&gt;</span><br><span class="line">&lt;flink.version&gt;1.6.2&lt;/flink.version&gt;</span><br><span class="line"> &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;flink-java&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;flink-streaming-java_2.11&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;flink-clients_2.11&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;!--Flink-Kafka --&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;flink-connector-kafka-0.9_2.11&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;mysql&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;5.1.39&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>4.sConfç±» å®šä¹‰ä¸MySQLè¿æ¥çš„JDBCçš„å‚æ•°<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">package com.soul.conf;</span><br><span class="line">/**</span><br><span class="line"> * @author è‹¥æ³½æ•°æ®soulChun</span><br><span class="line"> * @create 2018-12-20-15:11</span><br><span class="line"> */</span><br><span class="line">public class sConf &#123;</span><br><span class="line">    public static final String USERNAME = &quot;root&quot;;</span><br><span class="line">    public static final String PASSWORD = &quot;www.ruozedata.com&quot;;</span><br><span class="line">    public static final String DRIVERNAME = &quot;com.mysql.jdbc.Driver&quot;;</span><br><span class="line">    public static final String URL = &quot;jdbc:mysql://localhost:3306/soul&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h6 id="5-MySQLSlinkç±»"><a href="#5-MySQLSlinkç±»" class="headerlink" title="5.MySQLSlinkç±»"></a>5.MySQLSlinkç±»</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">package com.soul.kafka;</span><br><span class="line">import com.soul.conf.sConf;</span><br><span class="line">import org.apache.flink.api.java.tuple.Tuple5;</span><br><span class="line">import org.apache.flink.configuration.Configuration;</span><br><span class="line">import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;</span><br><span class="line">import java.sql.Connection;</span><br><span class="line">import java.sql.DriverManager;</span><br><span class="line">import java.sql.PreparedStatement;</span><br><span class="line">/**</span><br><span class="line"> * @author è‹¥æ³½æ•°æ®soulChun</span><br><span class="line"> * @create 2018-12-20-15:09</span><br><span class="line"> */</span><br><span class="line">public class MySQLSink extends RichSinkFunction&lt;Tuple5&lt;String, String, String, String, String&gt;&gt; &#123;</span><br><span class="line">    private static final long serialVersionUID = 1L;</span><br><span class="line">    private Connection connection;</span><br><span class="line">    private PreparedStatement preparedStatement;</span><br><span class="line">    public void invoke(Tuple5&lt;String, String, String, String, String&gt; value) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            if (connection == null) &#123;</span><br><span class="line">                Class.forName(sConf.DRIVERNAME);</span><br><span class="line">                connection = DriverManager.getConnection(sConf.URL, sConf.USERNAME, sConf.PASSWORD);</span><br><span class="line">            &#125;</span><br><span class="line">            String sql = &quot;insert into log_info (ip,time,courseid,status_code,referer) values (?,?,?,?,?)&quot;;</span><br><span class="line">            preparedStatement = connection.prepareStatement(sql);</span><br><span class="line">            preparedStatement.setString(1, value.f0);</span><br><span class="line">            preparedStatement.setString(2, value.f1);</span><br><span class="line">            preparedStatement.setString(3, value.f2);</span><br><span class="line">            preparedStatement.setString(4, value.f3);</span><br><span class="line">            preparedStatement.setString(5, value.f4);</span><br><span class="line">            System.out.println(&quot;Start insert&quot;);</span><br><span class="line">            preparedStatement.executeUpdate();</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    public void open(Configuration parms) throws Exception &#123;</span><br><span class="line">        Class.forName(sConf.DRIVERNAME);</span><br><span class="line">        connection = DriverManager.getConnection(sConf.URL, sConf.USERNAME, sConf.PASSWORD);</span><br><span class="line">    &#125;</span><br><span class="line">    public void close() throws Exception &#123;</span><br><span class="line">        if (preparedStatement != null) &#123;</span><br><span class="line">            preparedStatement.close();</span><br><span class="line">        &#125;</span><br><span class="line">        if (connection != null) &#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="6-æ•°æ®æ¸…æ´—æ—¥æœŸå·¥å…·ç±»"><a href="#6-æ•°æ®æ¸…æ´—æ—¥æœŸå·¥å…·ç±»" class="headerlink" title="6.æ•°æ®æ¸…æ´—æ—¥æœŸå·¥å…·ç±»"></a>6.æ•°æ®æ¸…æ´—æ—¥æœŸå·¥å…·ç±»</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">package com.soul.utils;</span><br><span class="line">import org.apache.commons.lang3.time.FastDateFormat;</span><br><span class="line">import java.util.Date;</span><br><span class="line">/**</span><br><span class="line"> * @author soulChun</span><br><span class="line"> * @create 2018-12-19-18:44</span><br><span class="line"> */</span><br><span class="line">public class DateUtils &#123;</span><br><span class="line">    private static FastDateFormat SOURCE_FORMAT = FastDateFormat.getInstance(&quot;yyyy-MM-dd HH:mm:ss&quot;);</span><br><span class="line">    private static FastDateFormat TARGET_FORMAT = FastDateFormat.getInstance(&quot;yyyyMMddHHmmss&quot;);</span><br><span class="line">    public static Long  getTime(String  time) throws Exception&#123;</span><br><span class="line">        return SOURCE_FORMAT.parse(time).getTime();</span><br><span class="line">    &#125;</span><br><span class="line">    public static String parseMinute(String time) throws  Exception&#123;</span><br><span class="line">        return TARGET_FORMAT.format(new Date(getTime(time)));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //æµ‹è¯•ä¸€ä¸‹</span><br><span class="line">    public static void main(String[] args) throws Exception&#123;</span><br><span class="line">        String time = &quot;2018-12-19 18:55:00&quot;;</span><br><span class="line">        System.out.println(parseMinute(time));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="7-MySQLå»ºè¡¨"><a href="#7-MySQLå»ºè¡¨" class="headerlink" title="7.MySQLå»ºè¡¨"></a>7.MySQLå»ºè¡¨</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">create table log_info(</span><br><span class="line">ID INT NOT NULL AUTO_INCREMENT,</span><br><span class="line">IP VARCHAR(50),</span><br><span class="line">TIME VARCHAR(50),</span><br><span class="line">CourseID VARCHAR(10),</span><br><span class="line">Status_Code VARCHAR(10),</span><br><span class="line">Referer VARCHAR(100),</span><br><span class="line">PRIMARY KEY ( ID )</span><br><span class="line">)ENGINE=InnoDB DEFAULT CHARSET=utf8;</span><br></pre></td></tr></table></figure><h6 id="8-ä¸»ç¨‹åºï¼š"><a href="#8-ä¸»ç¨‹åºï¼š" class="headerlink" title="8.ä¸»ç¨‹åºï¼š"></a>8.ä¸»ç¨‹åºï¼š</h6><p>ä¸»è¦æ˜¯å°†timeçš„æ ¼å¼è½¬æˆyyyyMMddHHmmss,</p><p>è¿˜æœ‰å–URLä¸­çš„è¯¾ç¨‹IDï¼Œå°†ä¸æ˜¯/classå¼€å¤´çš„è¿‡æ»¤æ‰ã€‚<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">package com.soul.kafka;</span><br><span class="line">import com.soul.utils.DateUtils;</span><br><span class="line">import org.apache.flink.api.common.functions.FilterFunction;</span><br><span class="line">import org.apache.flink.api.common.functions.MapFunction;</span><br><span class="line">import org.apache.flink.api.common.serialization.SimpleStringSchema;</span><br><span class="line">import org.apache.flink.api.java.tuple.Tuple5;</span><br><span class="line">import org.apache.flink.streaming.api.TimeCharacteristic;</span><br><span class="line">import org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line">import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line">import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09;</span><br><span class="line">import java.util.Properties;</span><br><span class="line">/**</span><br><span class="line"> * @author soulChun</span><br><span class="line"> * @create 2018-12-19-17:23</span><br><span class="line"> */</span><br><span class="line">public class FlinkCleanKafka &#123;</span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.enableCheckpointing(5000);</span><br><span class="line">        Properties properties = new Properties();</span><br><span class="line">        properties.setProperty(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);//kafkaçš„èŠ‚ç‚¹çš„IPæˆ–è€…hostNameï¼Œå¤šä¸ªä½¿ç”¨é€—å·åˆ†éš”</span><br><span class="line">        properties.setProperty(&quot;zookeeper.connect&quot;, &quot;localhost:2181&quot;);//zookeeperçš„èŠ‚ç‚¹çš„IPæˆ–è€…hostNameï¼Œå¤šä¸ªä½¿ç”¨é€—å·è¿›è¡Œåˆ†éš”</span><br><span class="line">        properties.setProperty(&quot;group.id&quot;, &quot;test-consumer-group&quot;);//flink consumer flinkçš„æ¶ˆè´¹è€…çš„group.id</span><br><span class="line">        FlinkKafkaConsumer09&lt;String&gt; myConsumer = new FlinkKafkaConsumer09&lt;String&gt;(&quot;imooc_topic&quot;, new SimpleStringSchema(), properties);</span><br><span class="line">        DataStream&lt;String&gt; stream = env.addSource(myConsumer);</span><br><span class="line">//        stream.print().setParallelism(2);</span><br><span class="line">        DataStream CleanData = stream.map(new MapFunction&lt;String, Tuple5&lt;String, String, String, String, String&gt;&gt;() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public Tuple5&lt;String, String, String, String, String&gt; map(String value) throws Exception &#123;</span><br><span class="line">                String[] data = value.split(&quot;\\\t&quot;);</span><br><span class="line">                String CourseID = null;</span><br><span class="line">                String url = data[2].split(&quot;\\ &quot;)[2];</span><br><span class="line">                if (url.startsWith(&quot;/class&quot;)) &#123;</span><br><span class="line">                    String CourseHTML = url.split(&quot;\\/&quot;)[2];</span><br><span class="line">                    CourseID = CourseHTML.substring(0, CourseHTML.lastIndexOf(&quot;.&quot;));</span><br><span class="line">//                    System.out.println(CourseID);</span><br><span class="line">                &#125;</span><br><span class="line">                return Tuple5.of(data[0], DateUtils.parseMinute(data[1]), CourseID, data[3], data[4]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).filter(new FilterFunction&lt;Tuple5&lt;String, String, String, String, String&gt;&gt;() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public boolean filter(Tuple5&lt;String, String, String, String, String&gt; value) throws Exception &#123;</span><br><span class="line">                return value.f2 != null;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        CleanData.addSink(new MySQLSink());</span><br><span class="line">        env.execute(&quot;Flink kafka&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h6 id="9-å¯åŠ¨ä¸»ç¨‹åºï¼ŒæŸ¥çœ‹MySQLè¡¨æ•°æ®åœ¨é€’å¢"><a href="#9-å¯åŠ¨ä¸»ç¨‹åºï¼ŒæŸ¥çœ‹MySQLè¡¨æ•°æ®åœ¨é€’å¢" class="headerlink" title="9.å¯åŠ¨ä¸»ç¨‹åºï¼ŒæŸ¥çœ‹MySQLè¡¨æ•°æ®åœ¨é€’å¢"></a>9.å¯åŠ¨ä¸»ç¨‹åºï¼ŒæŸ¥çœ‹MySQLè¡¨æ•°æ®åœ¨é€’å¢</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select count(*) from log_info;</span><br><span class="line">+----------+</span><br><span class="line">| count(*) |</span><br><span class="line">+----------+</span><br><span class="line">|    15137 |</span><br><span class="line">+----------+</span><br></pre></td></tr></table></figure><p>Kafkaè¿‡æ¥çš„æ¶ˆæ¯æ˜¯æˆ‘æ¨¡æ‹Ÿçš„ï¼Œä¸€åˆ†é’Ÿäº§ç”Ÿ100æ¡ã€‚</p><p>ä»¥ä¸Šæ˜¯æˆ‘å¸ç”Ÿäº§é¡¹ç›®ä»£ç çš„æŠ½å–å‡ºæ¥çš„æ¡ˆä¾‹ä»£ç V1ã€‚ç¨åè¿˜æœ‰WaterMarkä¹‹ç±»ä¼šåšåˆ†äº«ã€‚</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --&gt;&lt;font color=&quot;#FF4500&quot;&gt;&lt;br&gt;&lt;/font&gt;&lt;h6 id=&quot;1-ç‰ˆæœ¬ä¿¡æ¯ï¼š&quot;&gt;&lt;a href=&quot;#1-ç‰ˆæœ¬ä¿¡æ¯ï¼š&quot; class=&quot;headerlink&quot; title=&quot;1.ç‰ˆæœ¬ä¿¡æ¯ï¼š&quot;&gt;&lt;/a&gt;1.ç‰ˆæœ¬ä¿¡æ¯ï¼š&lt;/h6&gt;&lt;p&gt;Flink Version:1.6.2&lt;br&gt;Kafka Version:0.9.0.0&lt;br&gt;MySQL Version:5.6.21&lt;/p&gt;&lt;h6 id=&quot;2-Kafka-æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š-IP-TIME-URL-STATU-CODE-REFERER&quot;&gt;&lt;a href=&quot;#2-Kafka-æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š-IP-TIME-URL-STATU-CODE-REFERER&quot; class=&quot;headerlink&quot; title=&quot;2.Kafka æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š[IP TIME URL STATU_CODE REFERER]&quot;&gt;&lt;/a&gt;2.Kafka æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š[IP TIME URL STATU_CODE REFERER]&lt;/h6&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1.74.103.143    2018-12-20 18:12:00  &amp;quot;GET /class/130.html HTTP/1.1&amp;quot;     404 https://search.yahoo.com/search?p=Flinkå®æˆ˜&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Flink" scheme="http://yoursite.com/categories/Flink/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Sparkåœ¨æºç¨‹çš„å®è·µï¼ˆäºŒï¼‰</title>
    <link href="http://yoursite.com/2018/12/16/Spark%E5%9C%A8%E6%90%BA%E7%A8%8B%E7%9A%84%E5%AE%9E%E8%B7%B5%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>http://yoursite.com/2018/12/16/Sparkåœ¨æºç¨‹çš„å®è·µï¼ˆäºŒï¼‰/</id>
    <published>2018-12-15T16:00:00.000Z</published>
    <updated>2019-05-22T12:19:20.084Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed May 22 2019 20:21:18 GMT+0800 (GMT+08:00) --><p>ä»¥ä¸‹å†…å®¹æ¥è‡ªç¬¬ä¸‰å±Šæºç¨‹å¤§æ•°æ®æ²™é¾™</p><h3 id="ä¸ƒã€é‡åˆ°çš„é—®é¢˜"><a href="#ä¸ƒã€é‡åˆ°çš„é—®é¢˜" class="headerlink" title="ä¸ƒã€é‡åˆ°çš„é—®é¢˜"></a>ä¸ƒã€é‡åˆ°çš„é—®é¢˜</h3><h5 id="orc-split"><a href="#orc-split" class="headerlink" title="orc split"></a>orc split</h5><p>Sparkè¯»å–Hiveè¡¨ç”¨çš„å„ä¸ªæ–‡ä»¶æ ¼å¼çš„InuptFormatï¼Œè®¡ç®—è¯»å–è¡¨éœ€è¦çš„taskæ•°é‡ä¾èµ–äºInputFormat#getSplits<br>ç”±äºå¤§éƒ¨åˆ†è¡¨çš„å­˜å‚¨æ ¼å¼ä¸»è¦ä½¿ç”¨çš„æ˜¯orcï¼Œå½“ä¸€ä¸ªorcæ–‡ä»¶è¶…è¿‡256MBï¼Œsplitç®—æ³•å¹¶è¡Œå»è¯»å–orcå…ƒæ•°æ®ï¼Œæœ‰æ—¶å€™Driverå†…å­˜é£™å‡ï¼ŒOOM crashï¼ŒFull GCå¯¼è‡´network timeoutï¼Œspark context stop<br>Hiveè¯»è¿™äº›å¤§è¡¨ä¸ºä½•æ²¡æœ‰é—®é¢˜ï¼Ÿå› ä¸ºHiveé»˜è®¤ä½¿ç”¨çš„æ˜¯CombineHiveInputFormatï¼Œsplitæ˜¯åŸºäºæ–‡ä»¶å¤§å°çš„ã€‚<br>Sparkä¹Ÿéœ€è¦å®ç°ç±»ä¼¼äºHiveçš„CombineInputFormatï¼Œè¿˜èƒ½è§£å†³å°æ–‡ä»¶è¿‡å¤šå¯¼è‡´æäº¤taskæ•°é‡è¿‡å¤šçš„é—®é¢˜ã€‚<br>Executor Container killed<br>Executor : Container killed by YARN for exceeding memory limits. 13.9 GB of 12 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead<br><a id="more"></a></p><h5 id="åŸå› ï¼š"><a href="#åŸå› ï¼š" class="headerlink" title="åŸå› ï¼š"></a>åŸå› ï¼š</h5><p>1.Shuffle Readæ—¶nettyå †å¤–å†…å­˜çš„ä½¿ç”¨<br>2.Window function spill thresholdè¿‡å°ï¼Œå¯¼è‡´æ¯4096æ¡æˆ–è€…64MBä¸ºä¸€ä¸ªæ–‡ä»¶å†™åˆ°ç£ç›˜<br>å¤–éƒ¨æ’åºåŒæ—¶æ‰“å¼€æ¯ä¸ªæ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶å ç”¨1MBçš„å †å¤–å†…å­˜ï¼Œå¯¼è‡´containerä½¿ç”¨çš„å†…å­˜è¿œè¶…è¿‡ç”³è¯·çš„å†…å­˜ï¼Œé‚è¢«yarn killã€‚<br>è§£å†³ï¼š<br>Patchï¼š<br>[SPARK-19659] Fetch big blocks to disk when shuffle-read<br>[SPARK-21369][CORE] Donâ€™t use Scala Tuple2 in common/network-<em><br>å‚æ•°ï¼šspark.reducer.maxReqSizeShuffleToMem=209715200<br>Patchï¼š<br>[SPARK-21595]Separate thresholds for buffering and spilling in ExternalAppendOnlyUnsafeRowArray<br>å‚æ•°ï¼š<br>spark.sql.windowExec.buffer.in.memory.threshold=4096<br>spark.sql.windowExec.buffer.spill.threshold= 1024 </em>1024 * 1024 / 2</p><h5 id="å°æ–‡ä»¶é—®é¢˜"><a href="#å°æ–‡ä»¶é—®é¢˜" class="headerlink" title="å°æ–‡ä»¶é—®é¢˜"></a>å°æ–‡ä»¶é—®é¢˜</h5><p>Sparkå†™æ•°æ®æ—¶ç”Ÿæˆå¾ˆå¤šå°æ–‡ä»¶ï¼Œå¯¹NameNodeäº§ç”Ÿå·¨å¤§çš„å‹åŠ›ï¼Œåœ¨ä¸€å¼€å§‹Sparkç°åº¦ä¸Šçº¿çš„æ—¶å€™ï¼Œæ–‡ä»¶æ•°å’ŒBlockæ•°é£™å‡ï¼Œæ–‡ä»¶å˜å°å¯¼è‡´å‹ç¼©ç‡é™ä½ï¼Œå®¹é‡ä¹Ÿè·Ÿç€ä¸Šå»ã€‚</p><h5 id="ç§»æ¤Hive-MergeFileTaskçš„å®ç°"><a href="#ç§»æ¤Hive-MergeFileTaskçš„å®ç°" class="headerlink" title="ç§»æ¤Hive MergeFileTaskçš„å®ç°"></a>ç§»æ¤Hive MergeFileTaskçš„å®ç°</h5><p>åœ¨Sparkæœ€åå†™ç›®æ ‡è¡¨çš„é˜¶æ®µè¿½åŠ å…¥äº†ä¸€ä¸ªMergeFileTaskï¼Œå‚è€ƒäº†Hiveçš„å®ç°<br>org.apache.hadoop.hive.ql.io.merge.MergeFileTask<br>org.apache.hadoop.hive.ql.exec.OrcFileMergeOperator</p><h5 id="æ— æ•°æ®çš„æƒ…å†µä¸‹ä¸åˆ›å»ºç©ºæ–‡ä»¶"><a href="#æ— æ•°æ®çš„æƒ…å†µä¸‹ä¸åˆ›å»ºç©ºæ–‡ä»¶" class="headerlink" title="æ— æ•°æ®çš„æƒ…å†µä¸‹ä¸åˆ›å»ºç©ºæ–‡ä»¶"></a>æ— æ•°æ®çš„æƒ…å†µä¸‹ä¸åˆ›å»ºç©ºæ–‡ä»¶</h5><p>[SPARK-21435][SQL]<br>Empty files should be skipped while write to file</p><h3 id="å…«ã€ä¼˜åŒ–"><a href="#å…«ã€ä¼˜åŒ–" class="headerlink" title="å…«ã€ä¼˜åŒ–"></a>å…«ã€ä¼˜åŒ–</h3><p>1.æŸ¥è¯¢åˆ†åŒºè¡¨æ—¶æ”¯æŒbroadcast joinï¼ŒåŠ é€ŸæŸ¥è¯¢<br>2.å‡å°‘Broadcast joinçš„å†…å­˜å‹åŠ› SPARK-22170<br>3.Fetchå¤±è´¥åèƒ½å¿«é€Ÿå¤±è´¥ï¼Œä»¥å…ä½œä¸šå¡å‡ ä¸ªå°æ—¶ SPARK-19753<br>4.Spark Thrift Serverç¨³å®šæ€§<br>ç»å¸¸æŒ‚æ‰ï¼Œæ—¥å¿—é‡Œå¼‚å¸¸ï¼Œmore than one active taskSet for stage<br>Apply SPARK-23433ä»æœ‰å°‘æ•°æŒ‚æ‰çš„æƒ…å†µï¼Œ<br>æäº¤SPARK-24677åˆ°ç¤¾åŒºï¼Œä¿®å¤ä¹‹<br>5.ä½œä¸šhangä½ SPARK-21834 SPARK-19326 SPARK-11334</p><h3 id="ä¹ã€æœªæ¥è®¡åˆ’"><a href="#ä¹ã€æœªæ¥è®¡åˆ’" class="headerlink" title="ä¹ã€æœªæ¥è®¡åˆ’"></a>ä¹ã€æœªæ¥è®¡åˆ’</h3><h5 id="è‡ªåŠ¨è°ƒä¼˜å†…å­˜"><a href="#è‡ªåŠ¨è°ƒä¼˜å†…å­˜" class="headerlink" title="è‡ªåŠ¨è°ƒä¼˜å†…å­˜"></a>è‡ªåŠ¨è°ƒä¼˜å†…å­˜</h5><p>æ‰‹æœºspark driverå’Œexecutorå†…å­˜ä½¿ç”¨æƒ…å†µ<br>æ ¹æ®ä½œä¸šå†å²çš„å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œåœ¨è°ƒåº¦ç³»ç»Ÿç«¯è‡ªåŠ¨è®¾ç½®åˆé€‚çš„å†…å­˜<br><a href="https://github.com/uber-common/jvm-profiler" target="_blank" rel="noopener">https://github.com/uber-common/jvm-profiler</a></p><h5 id="spark-adaptive"><a href="#spark-adaptive" class="headerlink" title="spark adaptive"></a>spark adaptive</h5><p>åŠ¨æ€è°ƒæ•´æ‰§è¡Œè®¡åˆ’ SortMergeJoinè½¬åŒ–ä¸ºBroadcastHashJoin<br>åŠ¨æ€å¤„ç†æ•°æ®å€¾æ–œ<br><a href="https://issues.apache.org/jira/browse/SPARK-23128" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/SPARK-23128</a><br><a href="https://github.com/Intel-bigdata/spark-adaptive" target="_blank" rel="noopener">https://github.com/Intel-bigdata/spark-adaptive</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed May 22 2019 20:21:18 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;ä»¥ä¸‹å†…å®¹æ¥è‡ªç¬¬ä¸‰å±Šæºç¨‹å¤§æ•°æ®æ²™é¾™&lt;/p&gt;&lt;h3 id=&quot;ä¸ƒã€é‡åˆ°çš„é—®é¢˜&quot;&gt;&lt;a href=&quot;#ä¸ƒã€é‡åˆ°çš„é—®é¢˜&quot; class=&quot;headerlink&quot; title=&quot;ä¸ƒã€é‡åˆ°çš„é—®é¢˜&quot;&gt;&lt;/a&gt;ä¸ƒã€é‡åˆ°çš„é—®é¢˜&lt;/h3&gt;&lt;h5 id=&quot;orc-split&quot;&gt;&lt;a href=&quot;#orc-split&quot; class=&quot;headerlink&quot; title=&quot;orc split&quot;&gt;&lt;/a&gt;orc split&lt;/h5&gt;&lt;p&gt;Sparkè¯»å–Hiveè¡¨ç”¨çš„å„ä¸ªæ–‡ä»¶æ ¼å¼çš„InuptFormatï¼Œè®¡ç®—è¯»å–è¡¨éœ€è¦çš„taskæ•°é‡ä¾èµ–äºInputFormat#getSplits&lt;br&gt;ç”±äºå¤§éƒ¨åˆ†è¡¨çš„å­˜å‚¨æ ¼å¼ä¸»è¦ä½¿ç”¨çš„æ˜¯orcï¼Œå½“ä¸€ä¸ªorcæ–‡ä»¶è¶…è¿‡256MBï¼Œsplitç®—æ³•å¹¶è¡Œå»è¯»å–orcå…ƒæ•°æ®ï¼Œæœ‰æ—¶å€™Driverå†…å­˜é£™å‡ï¼ŒOOM crashï¼ŒFull GCå¯¼è‡´network timeoutï¼Œspark context stop&lt;br&gt;Hiveè¯»è¿™äº›å¤§è¡¨ä¸ºä½•æ²¡æœ‰é—®é¢˜ï¼Ÿå› ä¸ºHiveé»˜è®¤ä½¿ç”¨çš„æ˜¯CombineHiveInputFormatï¼Œsplitæ˜¯åŸºäºæ–‡ä»¶å¤§å°çš„ã€‚&lt;br&gt;Sparkä¹Ÿéœ€è¦å®ç°ç±»ä¼¼äºHiveçš„CombineInputFormatï¼Œè¿˜èƒ½è§£å†³å°æ–‡ä»¶è¿‡å¤šå¯¼è‡´æäº¤taskæ•°é‡è¿‡å¤šçš„é—®é¢˜ã€‚&lt;br&gt;Executor Container killed&lt;br&gt;Executor : Container killed by YARN for exceeding memory limits. 13.9 GB of 12 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead&lt;br&gt;
    
    </summary>
    
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>Sparkåœ¨æºç¨‹çš„å®è·µï¼ˆä¸€ï¼‰</title>
    <link href="http://yoursite.com/2018/12/09/Spark%E5%9C%A8%E6%90%BA%E7%A8%8B%E7%9A%84%E5%AE%9E%E8%B7%B5%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://yoursite.com/2018/12/09/Sparkåœ¨æºç¨‹çš„å®è·µï¼ˆä¸€ï¼‰/</id>
    <published>2018-12-08T16:00:00.000Z</published>
    <updated>2019-05-21T12:44:42.154Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue May 21 2019 20:46:50 GMT+0800 (GMT+08:00) --><a id="more"></a><h3 id="ä¸€ã€Sparkåœ¨æºç¨‹åº”ç”¨çš„ç°çŠ¶"><a href="#ä¸€ã€Sparkåœ¨æºç¨‹åº”ç”¨çš„ç°çŠ¶" class="headerlink" title="ä¸€ã€Sparkåœ¨æºç¨‹åº”ç”¨çš„ç°çŠ¶"></a>ä¸€ã€Sparkåœ¨æºç¨‹åº”ç”¨çš„ç°çŠ¶</h3><h6 id="é›†ç¾¤è§„æ¨¡ï¼š"><a href="#é›†ç¾¤è§„æ¨¡ï¼š" class="headerlink" title="é›†ç¾¤è§„æ¨¡ï¼š"></a>é›†ç¾¤è§„æ¨¡ï¼š</h6><p>å¹³å‡æ¯å¤©MRä»»åŠ¡æ•°ï¼š30W+</p><h6 id="å¼€å‘å¹³å°ï¼š"><a href="#å¼€å‘å¹³å°ï¼š" class="headerlink" title="å¼€å‘å¹³å°ï¼š"></a>å¼€å‘å¹³å°ï¼š</h6><p>è°ƒåº¦ç³»ç»Ÿè¿è¡Œçš„ä»»åŠ¡æ•°ï¼š10W+<br>æ¯å¤©è¿è¡Œä»»åŠ¡å®ä¾‹æ•°ï¼š23W+<br>ETL/è®¡ç®—ä»»åŠ¡ï¼š~58%</p><h6 id="æŸ¥è¯¢å¹³å°"><a href="#æŸ¥è¯¢å¹³å°" class="headerlink" title="æŸ¥è¯¢å¹³å°:"></a>æŸ¥è¯¢å¹³å°:</h6><p>adhocæŸ¥è¯¢ï¼š2W+<br>æ”¯æŒSpark/Hive/Presto<br><img src="/assets/blogImg/1209_1.png" alt="enter description here"></p><h3 id="äºŒã€Hiveä¸Sparkçš„åŒºåˆ«"><a href="#äºŒã€Hiveä¸Sparkçš„åŒºåˆ«" class="headerlink" title="äºŒã€Hiveä¸Sparkçš„åŒºåˆ«"></a>äºŒã€Hiveä¸Sparkçš„åŒºåˆ«</h3><h6 id="Hiveï¼š"><a href="#Hiveï¼š" class="headerlink" title="Hiveï¼š"></a>Hiveï¼š</h6><p>ä¼˜ç‚¹ï¼šè¿è¡Œç¨³å®šï¼Œå®¢æˆ·ç«¯å†…å­˜æ¶ˆè€—å°ã€‚<br>å­˜åœ¨é—®é¢˜ï¼šç”Ÿæˆå¤šä¸ªMapReduceä½œä¸šï¼›ä¸­é—´ç»“æœè½åœ°ï¼ŒIOå¼€é”€å¤§ï¼›é¢‘ç¹ç”³è¯·å’Œé‡Šæ”¾containerï¼Œèµ„æºæ²¡æœ‰åˆç†å……åˆ†åˆ©ç”¨</p><h6 id="Sparkï¼š"><a href="#Sparkï¼š" class="headerlink" title="Sparkï¼š"></a>Sparkï¼š</h6><p>å¿«ï¼šé«˜æ•ˆçš„DAGæ‰§è¡Œå¼•æ“ï¼Œå¯ä»¥åŸºäºå†…å­˜æ¥é«˜æ•ˆçš„å¤„ç†æ•°æ®æµï¼ŒèŠ‚çœå¤§é‡IOå¼€é”€<br>é€šç”¨æ€§ï¼šSparkSQLèƒ½ç›´æ¥ä½¿ç”¨HiveQLè¯­æ³•ï¼ŒHive Metastoreï¼ŒSerdesï¼ŒUDFs<br><img src="/assets/blogImg/1209_2.png" alt="enter description here"></p><h3 id="ä¸‰ã€è¿ç§»SparkSQLçš„æŒ‘æˆ˜"><a href="#ä¸‰ã€è¿ç§»SparkSQLçš„æŒ‘æˆ˜" class="headerlink" title="ä¸‰ã€è¿ç§»SparkSQLçš„æŒ‘æˆ˜"></a>ä¸‰ã€è¿ç§»SparkSQLçš„æŒ‘æˆ˜</h3><h6 id="å…¼å®¹æ€§ï¼š"><a href="#å…¼å®¹æ€§ï¼š" class="headerlink" title="å…¼å®¹æ€§ï¼š"></a>å…¼å®¹æ€§ï¼š</h6><p>HiveåŸå…ˆçš„æƒé™æ§åˆ¶<br>SQLè¯­æ³•ï¼ŒUDFå’ŒHiveçš„å…¼å®¹æ€§</p><h6 id="ç¨³å®šæ€§ï¼š"><a href="#ç¨³å®šæ€§ï¼š" class="headerlink" title="ç¨³å®šæ€§ï¼š"></a>ç¨³å®šæ€§ï¼š</h6><p>è¿ç§»é€æ˜ï¼Œä½ä¼˜å…ˆçº§ç”¨æˆ·æ— æ„ŸçŸ¥<br>ç›‘æ§ä½œä¸šè¿ç§»åæˆåŠŸç‡åŠè¿è¡Œæ—¶é•¿å¯¹æ¯”</p><h6 id="å‡†ç¡®æ€§ï¼š"><a href="#å‡†ç¡®æ€§ï¼š" class="headerlink" title="å‡†ç¡®æ€§ï¼š"></a>å‡†ç¡®æ€§ï¼š</h6><p>æ•°æ®ä¸€è‡´<br>åŠŸèƒ½å¢å¼ºï¼š<br>ç”¨æˆ·ä½“éªŒï¼Œæ˜¯å¦æ˜“ç”¨ï¼ŒæŠ¥é”™ä¿¡æ¯æ˜¯å¦å¯è¯»<br>æ½œåœ¨Bug<br>å‘¨è¾¹ç³»ç»Ÿé…åˆæ”¹é€ <br>è¡€ç¼˜æ”¶é›†</p><h3 id="å››ã€å…¼å®¹æ€§æ”¹é€ "><a href="#å››ã€å…¼å®¹æ€§æ”¹é€ " class="headerlink" title="å››ã€å…¼å®¹æ€§æ”¹é€ "></a>å››ã€å…¼å®¹æ€§æ”¹é€ </h3><h6 id="ç§»æ¤hiveæƒé™"><a href="#ç§»æ¤hiveæƒé™" class="headerlink" title="ç§»æ¤hiveæƒé™"></a>ç§»æ¤hiveæƒé™</h6><p>Sparkæ²¡æœ‰æƒé™è®¤è¯æ¨¡å—ï¼Œå¯å¯¹ä»»æ„è¡¨è¿›è¡ŒæŸ¥è¯¢ï¼Œæœ‰å®‰å…¨éšæ‚£<br>éœ€è¦ä¸Hiveå…±äº«åŒä¸€å¥—æƒé™</p><h6 id="æ–¹æ¡ˆï¼š"><a href="#æ–¹æ¡ˆï¼š" class="headerlink" title="æ–¹æ¡ˆï¼š"></a>æ–¹æ¡ˆï¼š</h6><p>æ‰§è¡ŒSQLæ—¶ï¼Œå¯¹SQLè§£æå¾—åˆ°LogicalPlanï¼Œå¯¹LogicalPlanè¿›è¡Œéå†ï¼Œæå–è¯»å–çš„è¡¨åŠå†™å…¥çš„è¡¨ï¼Œè°ƒç”¨Hvieçš„è®¤è¯æ–¹æ³•è¿›è¡Œæ£€æŸ¥ï¼Œå¦‚æœæœ‰æƒé™åˆ™ç»§ç»­æ‰§è¡Œï¼Œå¦åˆ™æ‹’ç»è¯¥ç”¨æˆ·çš„æ“ä½œã€‚<br>SQLè¯­æ³•å’Œhiveå…¼å®¹<br>Sparkåˆ›å»ºçš„æŸäº›è§†å›¾ï¼Œåœ¨HiveæŸ¥è¯¢æ—¶æŠ¥é”™ï¼ŒSparkåˆ›å»ºçš„è§†å›¾ä¸ä¼šå¯¹SQLè¿›è¡Œå±•å¼€ï¼Œè§†å›¾å®šä¹‰æ²¡æœ‰å½“å‰çš„DBä¿¡æ¯ï¼ŒHiveä¸å…¼å®¹è¯»å–è¿™æ ·çš„è§†å›¾</p><h6 id="æ–¹æ¡ˆï¼šã€"><a href="#æ–¹æ¡ˆï¼šã€" class="headerlink" title="æ–¹æ¡ˆï¼šã€"></a>æ–¹æ¡ˆï¼šã€</h6><p>ä¿æŒä¸Hiveä¸€è‡´ï¼Œåœ¨Sparkåˆ›å»ºå’Œä¿®æ”¹è§†å›¾æ—¶ï¼Œä½¿ç”¨hive cli driverå»æ‰§è¡Œcreate/alter view sql<br>UDFä¸hiveå…¼å®¹<br>UDFè®¡ç®—ç»“æœä¸ä¸€æ ·ï¼Œå³ä½¿æ˜¯æ­£å¸¸æ•°æ®ï¼ŒSparkè¿”å›nullï¼ŒHiveç»“æœæ­£ç¡®ï¼›å¼‚å¸¸æ•°æ®ï¼ŒSparkæŠ›exceptionå¯¼è‡´ä½œä¸šå¤±è´¥ï¼ŒHiveè¿”å›çš„nullã€‚</p><h6 id="æ–¹æ¡ˆï¼š-1"><a href="#æ–¹æ¡ˆï¼š-1" class="headerlink" title="æ–¹æ¡ˆï¼š"></a>æ–¹æ¡ˆï¼š</h6><p>Sparkå‡½æ•°ä¿®å¤ï¼Œæ¯”å¦‚roundå‡½æ•°<br>å°†hiveä¸€äº›å‡½æ•°ç§»æ¤ï¼Œå¹¶æ³¨å†Œæˆæ°¸ä¹…å‡½æ•°<br>æ•´ç†Sparkå’ŒHiveè¯­æ³•å’ŒUDFå·®å¼‚<br>äº”ã€ç¨³å®šæ€§å’Œå‡†ç¡®æ€§</p><h6 id="ç¨³å®šæ€§ï¼š-1"><a href="#ç¨³å®šæ€§ï¼š-1" class="headerlink" title="ç¨³å®šæ€§ï¼š"></a>ç¨³å®šæ€§ï¼š</h6><p>è¿ç§»é€æ˜ï¼šè°ƒåº¦ç³»ç»Ÿå¯¹ä½ä¼˜å…ˆçº§ä½œä¸šï¼ŒæŒ‰ä½œä¸šç²’åº¦åˆ‡æ¢æˆSparkæ‰§è¡Œï¼Œå¤±è´¥åå†åˆ‡æ¢æˆhive<br>ç°åº¦å˜æ›´ï¼Œå¤šç§å˜æ›´è§„åˆ™ï¼šæ”¯æŒå¤šç‰ˆæœ¬Sparkï¼Œè‡ªåŠ¨åˆ‡æ¢å¼•æ“ï¼ŒSpark v2 -&gt; Spark v1 -&gt; Hiveï¼›ç°åº¦æ¨é€å‚æ•°ï¼Œè°ƒä¼˜å‚æ•°ï¼ŒæŸäº›åŠŸèƒ½<br>ç›‘æ§ï¼šæ¯æ—¥ç»Ÿè®¡sparkå’Œhiveè¿è¡Œå¯¹æ¯”ï¼Œæ¯æ—¶æ”¶é›†ä½œä¸šç²’åº¦å¤±è´¥çš„Sparkä½œä¸šï¼Œåˆ†æå¤±è´¥åŸå› <br>å‡†ç¡®æ€§ï¼š<br>æ•°æ®è´¨é‡ç³»ç»Ÿï¼šæ ¡éªŒä»»åŠ¡ï¼Œæ£€æŸ¥æ•°æ®å‡†ç¡®æ€§</p><h3 id="å…­ã€åŠŸèƒ½å¢å¼º"><a href="#å…­ã€åŠŸèƒ½å¢å¼º" class="headerlink" title="å…­ã€åŠŸèƒ½å¢å¼º"></a>å…­ã€åŠŸèƒ½å¢å¼º</h3><h6 id="Spark-Thrift-Serverï¼š"><a href="#Spark-Thrift-Serverï¼š" class="headerlink" title="Spark Thrift Serverï¼š"></a>Spark Thrift Serverï¼š</h6><ul><li>1.åŸºäºdelegation tokençš„impersontion<br>Driverï¼š<br>ä¸ºä¸åŒçš„ç”¨æˆ·æ‹¿delegation tokenï¼Œå†™åˆ°stagingç›®å½•ï¼Œè®°å½•User-&gt;SQL-&gt;Jobæ˜ å°„å…³ç³»ï¼Œåˆ†å‘taskå¸¦ä¸Šå¯¹åº”çš„username<br>Executorï¼š<br>æ ¹æ®taskä¿¡æ¯å¸¦çš„usernameæ‰¾åˆ°stagingç›®å½•ä¸‹çš„tokenï¼ŒåŠ åˆ°å½“å‰proxy userçš„ugiï¼Œå®ç°impersonate</li><li>2.åŸºäºzookeeperçš„æœåŠ¡å‘ç°ï¼Œæ”¯æŒå¤šå°server<br>è¿™ä¸€å—ä¸»è¦ç§»æ¤äº†Hive zookeeperçš„å®ç°</li><li>3.é™åˆ¶å¤§æŸ¥è¯¢ä½œä¸šï¼Œé˜²æ­¢driver OOM<br>é™åˆ¶æ¯ä¸ªjobäº§ç”Ÿçš„taskæœ€å¤§æ•°é‡<br>é™åˆ¶æŸ¥è¯¢SQLçš„æœ€å¤§è¡Œæ•°ï¼Œå®¢æˆ·ç«¯æŸ¥è¯¢å¤§æ‰¹é‡æ•°æ®ï¼Œæ•°æ®æŒ¤å‹åœ¨Thrift Serverï¼Œå †å†…å†…å­˜é£™å‡ï¼Œå¼ºåˆ¶åœ¨åªæœ‰æŸ¥çš„SQLåŠ ä¸Šlimit<br>é™åˆ¶æŸ¥è¯¢SQLçš„ç»“æœé›†æ•°æ®å¤§å°</li><li>4.ç›‘æ§<br>å¯¹æ¯ä¸ªserverå®šæ—¶æŸ¥è¯¢ï¼Œæ£€æµ‹æ˜¯å¦å¯ç”¨<br>å¤šè¿è¡Œæ—¶é•¿è¾ƒä¹…çš„ä½œä¸šï¼Œä¸»åŠ¨kill<h6 id="ç”¨æˆ·ä½“éªŒ"><a href="#ç”¨æˆ·ä½“éªŒ" class="headerlink" title="ç”¨æˆ·ä½“éªŒ"></a>ç”¨æˆ·ä½“éªŒ</h6>ç”¨æˆ·çœ‹åˆ°çš„æ˜¯ç±»ä¼¼Hive MRè¿›åº¦çš„æ—¥å¿—ï¼ŒINFOçº§åˆ«æ—¥å¿—æ”¶é›†åˆ°ESï¼Œå¯ä¾›æ—¥å¿—çš„åˆ†æå’Œæ’æŸ¥é—®é¢˜<br>æ”¶é›†ç”Ÿæˆçš„è¡¨æˆ–è€…åˆ†åŒºçš„numRows numFile totalSizeï¼Œè¾“å‡ºåˆ°æ—¥å¿—<br>å¯¹ç®€å•çš„è¯­å¥ï¼Œå¦‚DDLè¯­å¥ï¼Œè‡ªåŠ¨ä½¿ç”¨â€“master=localæ–¹å¼å¯åŠ¨<h6 id="Combine-input-Format"><a href="#Combine-input-Format" class="headerlink" title="Combine input Format"></a>Combine input Format</h6>åœ¨HadoopTableReader#makeRDDForTableï¼Œæ‹¿åˆ°å¯¹åº”tableçš„InputFormatClassï¼Œè½¬æ¢æˆå¯¹åº”æ ¼å¼çš„CombineInputFormat<br>é€šè¿‡å¼€å…³æ¥å†³å®šæ˜¯å¦å¯ç”¨è¿™ä¸ªç‰¹æ€§<br>set spark.sql.combine.input.splits.enable=true<br>é€šè¿‡å‚æ•°æ¥è°ƒæ•´æ¯ä¸ªsplitçš„total input size<br>mapreduce.input.fileinputformat.split.maxsize=256MB <em>1024</em>1024<br>ä¹‹å‰driverè¯»å¤§è¡¨é«˜å³°æ—¶æ®µsplitéœ€è¦30åˆ†é’Ÿä¸æ­¢ï¼Œæ‰æŠŠä»»åŠ¡æäº¤ä¸Šï¼Œç°åœ¨åªè¦å‡ åˆ†é’Ÿå°±ç®—å¥½splitçš„æ•°é‡å¹¶æäº¤ä»»åŠ¡ï¼Œä¹Ÿè§£å†³äº†ä¸€äº›è¡¨ä¸å¤§ï¼Œå°æ–‡ä»¶å¤šï¼Œèƒ½åˆå¹¶åˆ°åŒä¸€ä¸ªtaskè¿›è¡Œè¯»å–</li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue May 21 2019 20:46:50 GMT+0800 (GMT+08:00) --&gt;
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>ä»£ç  | Sparkè¯»å–mongoDBæ•°æ®å†™å…¥Hiveæ™®é€šè¡¨å’Œåˆ†åŒºè¡¨</title>
    <link href="http://yoursite.com/2018/11/20/Spark%E8%AF%BB%E5%8F%96mongoDB%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5Hive%E6%99%AE%E9%80%9A%E8%A1%A8%E5%92%8C%E5%88%86%E5%8C%BA%E8%A1%A8/"/>
    <id>http://yoursite.com/2018/11/20/Sparkè¯»å–mongoDBæ•°æ®å†™å…¥Hiveæ™®é€šè¡¨å’Œåˆ†åŒºè¡¨/</id>
    <published>2018-11-19T16:00:00.000Z</published>
    <updated>2019-05-20T14:34:59.451Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 20 2019 22:37:10 GMT+0800 (GMT+08:00) --><a id="more"></a><h3 id="ç‰ˆæœ¬ï¼š"><a href="#ç‰ˆæœ¬ï¼š" class="headerlink" title="ç‰ˆæœ¬ï¼š"></a>ç‰ˆæœ¬ï¼š</h3><p>spark 2.2.0<br>hive 1.1.0<br>scala 2.11.8<br>hadoop-2.6.0-cdh5.7.0<br>jdk 1.8<br>MongoDB 3.6.4</p><h3 id="ä¸€-åŸå§‹æ•°æ®åŠHiveè¡¨"><a href="#ä¸€-åŸå§‹æ•°æ®åŠHiveè¡¨" class="headerlink" title="ä¸€ åŸå§‹æ•°æ®åŠHiveè¡¨"></a>ä¸€ åŸå§‹æ•°æ®åŠHiveè¡¨</h3><h5 id="MongoDBæ•°æ®æ ¼å¼"><a href="#MongoDBæ•°æ®æ ¼å¼" class="headerlink" title="MongoDBæ•°æ®æ ¼å¼"></a>MongoDBæ•°æ®æ ¼å¼</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;_id&quot; : ObjectId(&quot;5af65d86222b639e0c2212f3&quot;),</span><br><span class="line">    &quot;id&quot; : &quot;1&quot;,</span><br><span class="line">    &quot;name&quot; : &quot;lisi&quot;,</span><br><span class="line">    &quot;age&quot; : &quot;18&quot;,</span><br><span class="line">    &quot;deptno&quot; : &quot;01&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="Hiveæ™®é€šè¡¨"><a href="#Hiveæ™®é€šè¡¨" class="headerlink" title="Hiveæ™®é€šè¡¨"></a>Hiveæ™®é€šè¡¨</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create table mg_hive_test(</span><br><span class="line">id string,</span><br><span class="line">name string,</span><br><span class="line">age string,</span><br><span class="line">deptno string</span><br><span class="line">)row format delimited fields terminated by &apos;\t&apos;;</span><br></pre></td></tr></table></figure><h5 id="Hiveåˆ†åŒºè¡¨"><a href="#Hiveåˆ†åŒºè¡¨" class="headerlink" title="Hiveåˆ†åŒºè¡¨"></a>Hiveåˆ†åŒºè¡¨</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create table  mg_hive_external(</span><br><span class="line">id string,</span><br><span class="line">name string,</span><br><span class="line">age string</span><br><span class="line">)</span><br><span class="line">partitioned by (deptno string)</span><br><span class="line">row format delimited fields terminated by &apos;\t&apos;;</span><br></pre></td></tr></table></figure><h3 id="äºŒ-IDEA-Maven-Java"><a href="#äºŒ-IDEA-Maven-Java" class="headerlink" title="äºŒ IDEA+Maven+Java"></a>äºŒ IDEA+Maven+Java</h3><h5 id="ä¾èµ–"><a href="#ä¾èµ–" class="headerlink" title="ä¾èµ–"></a>ä¾èµ–</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;spark-sql_2.11&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;spark-hive_2.11&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.mongodb&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;mongo-java-driver&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;3.6.3&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.mongodb.spark&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;mongo-spark-connector_2.11&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;2.2.2&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h5 id="ä»£ç "><a href="#ä»£ç " class="headerlink" title="ä»£ç "></a>ä»£ç </h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line">package com.huawei.mongo;/*</span><br><span class="line"> * @Author: Create by Achun</span><br><span class="line"> *@Time: 2018/6/2 21:00</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line"></span><br><span class="line">import com.mongodb.spark.MongoSpark;</span><br><span class="line"></span><br><span class="line">import org.apache.spark.SparkConf;</span><br><span class="line">import org.apache.spark.api.java.JavaRDD;</span><br><span class="line">import org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line">import org.apache.spark.api.java.function.Function;</span><br><span class="line">import org.apache.spark.sql.Dataset;</span><br><span class="line">import org.apache.spark.sql.Row;</span><br><span class="line">import org.apache.spark.sql.RowFactory;</span><br><span class="line">import org.apache.spark.sql.SparkSession;</span><br><span class="line">import org.apache.spark.sql.hive.HiveContext;</span><br><span class="line">import org.apache.spark.sql.types.DataTypes;</span><br><span class="line">import org.apache.spark.sql.types.StructField;</span><br><span class="line">import org.apache.spark.sql.types.StructType;</span><br><span class="line">import org.bson.Document;</span><br><span class="line"></span><br><span class="line">import java.io.File;</span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.List;</span><br><span class="line"></span><br><span class="line">public class sparkreadmgtohive &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        //spark 2.x</span><br><span class="line">        String warehouseLocation = new File(&quot;spark-warehouse&quot;).getAbsolutePath();</span><br><span class="line">        SparkSession spark = SparkSession.builder()</span><br><span class="line">                .master(&quot;local[2]&quot;)</span><br><span class="line">                .appName(&quot;SparkReadMgToHive&quot;)</span><br><span class="line">                .config(&quot;spark.sql.warehouse.dir&quot;, warehouseLocation)</span><br><span class="line">                .config(&quot;spark.mongodb.input.uri&quot;, &quot;mongodb://127.0.0.1:27017/test.mgtest&quot;)</span><br><span class="line">                .enableHiveSupport()</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        JavaSparkContext sc = new JavaSparkContext(spark.sparkContext());</span><br><span class="line"></span><br><span class="line">        //spark 1.x</span><br><span class="line">//        JavaSparkContext sc = new JavaSparkContext(conf);</span><br><span class="line">//        sc.addJar(&quot;/Users/mac/zhangchun/jar/mongo-spark-connector_2.11-2.2.2.jar&quot;);</span><br><span class="line">//        sc.addJar(&quot;/Users/mac/zhangchun/jar/mongo-java-driver-3.6.3.jar&quot;);</span><br><span class="line">//        SparkConf conf = new SparkConf().setMaster(&quot;local[2]&quot;).setAppName(&quot;SparkReadMgToHive&quot;);</span><br><span class="line">//        conf.set(&quot;spark.mongodb.input.uri&quot;, &quot;mongodb://127.0.0.1:27017/test.mgtest&quot;);</span><br><span class="line">//        conf.set(&quot;spark. serializer&quot;,&quot;org.apache.spark.serializer.KryoSerialzier&quot;);</span><br><span class="line">//        HiveContext sqlContext = new HiveContext(sc);</span><br><span class="line">//        //create df from mongo</span><br><span class="line">//        Dataset&lt;Row&gt; df = MongoSpark.read(sqlContext).load().toDF();</span><br><span class="line">//        df.select(&quot;id&quot;,&quot;name&quot;,&quot;name&quot;).show();</span><br><span class="line"></span><br><span class="line">        String querysql= &quot;select id,name,age,deptno,DateTime,Job from mgtable b&quot;;</span><br><span class="line">        String opType =&quot;P&quot;;</span><br><span class="line"></span><br><span class="line">        SQLUtils sqlUtils = new SQLUtils();</span><br><span class="line">        List&lt;String&gt; column = sqlUtils.getColumns(querysql);</span><br><span class="line"></span><br><span class="line">        //create rdd from mongo</span><br><span class="line">        JavaRDD&lt;Document&gt; rdd = MongoSpark.load(sc);</span><br><span class="line">        //å°†Documentè½¬æˆObject</span><br><span class="line">        JavaRDD&lt;Object&gt; Ordd = rdd.map(new Function&lt;Document, Object&gt;() &#123;</span><br><span class="line">            public Object call(Document document)&#123;</span><br><span class="line">                List list = new ArrayList();</span><br><span class="line">                for (int i = 0; i &lt; column.size(); i++) &#123;</span><br><span class="line">                    list.add(String.valueOf(document.get(column.get(i))));</span><br><span class="line">                &#125;</span><br><span class="line">                return list;</span><br><span class="line"></span><br><span class="line">//                return list.toString().replace(&quot;[&quot;,&quot;&quot;).replace(&quot;]&quot;,&quot;&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        System.out.println(Ordd.first());</span><br><span class="line">        //é€šè¿‡ç¼–ç¨‹æ–¹å¼å°†RDDè½¬æˆDF</span><br><span class="line">        List ls= new ArrayList();</span><br><span class="line">        for (int i = 0; i &lt; column.size(); i++) &#123;</span><br><span class="line">            ls.add(column.get(i));</span><br><span class="line">        &#125;</span><br><span class="line">        String schemaString = ls.toString().replace(&quot;[&quot;,&quot;&quot;).replace(&quot;]&quot;,&quot;&quot;).replace(&quot; &quot;,&quot;&quot;);</span><br><span class="line">        System.out.println(schemaString);</span><br><span class="line"></span><br><span class="line">        List&lt;StructField&gt; fields = new ArrayList&lt;StructField&gt;();</span><br><span class="line">        for (String fieldName : schemaString.split(&quot;,&quot;)) &#123;</span><br><span class="line">            StructField field = DataTypes.createStructField(fieldName, DataTypes.StringType, true);</span><br><span class="line">            fields.add(field);</span><br><span class="line">        &#125;</span><br><span class="line">        StructType schema = DataTypes.createStructType(fields);</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;Row&gt; rowRDD = Ordd.map((Function&lt;Object, Row&gt;) record -&gt; &#123;</span><br><span class="line">            List fileds = (List) record;</span><br><span class="line">//            String[] attributes = record.toString().split(&quot;,&quot;);</span><br><span class="line">            return RowFactory.create(fileds.toArray());</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(rowRDD,schema);</span><br><span class="line"></span><br><span class="line">        //å°†DFå†™å…¥åˆ°Hiveä¸­</span><br><span class="line">        //é€‰æ‹©Hiveæ•°æ®åº“</span><br><span class="line">        spark.sql(&quot;use datalake&quot;);</span><br><span class="line">        //æ³¨å†Œä¸´æ—¶è¡¨</span><br><span class="line">        df.registerTempTable(&quot;mgtable&quot;);</span><br><span class="line"></span><br><span class="line">        if (&quot;O&quot;.equals(opType.trim())) &#123;</span><br><span class="line">            System.out.println(&quot;æ•°æ®æ’å…¥åˆ°Hive ordinary table&quot;);</span><br><span class="line">            Long t1 = System.currentTimeMillis();</span><br><span class="line">            spark.sql(&quot;insert into mgtohive_2 &quot; + querysql + &quot; &quot; + &quot;where b.id not in (select id from mgtohive_2)&quot;);</span><br><span class="line">            Long t2 = System.currentTimeMillis();</span><br><span class="line">            System.out.println(&quot;å…±è€—æ—¶ï¼š&quot; + (t2 - t1) / 60000 + &quot;åˆ†é’Ÿ&quot;);</span><br><span class="line">        &#125;else if (&quot;P&quot;.equals(opType.trim())) &#123;</span><br><span class="line"></span><br><span class="line">        System.out.println(&quot;æ•°æ®æ’å…¥åˆ°Hive  dynamic partition table&quot;);</span><br><span class="line">        Long t3 = System.currentTimeMillis();</span><br><span class="line">        //å¿…é¡»è®¾ç½®ä»¥ä¸‹å‚æ•° å¦åˆ™æŠ¥é”™</span><br><span class="line">        spark.sql(&quot;set hive.exec.dynamic.partition.mode=nonstrict&quot;);</span><br><span class="line">        //deptonä¸ºåˆ†åŒºå­—æ®µ   selectè¯­å¥æœ€åä¸€ä¸ªå­—æ®µå¿…é¡»æ˜¯deptno</span><br><span class="line">        spark.sql(&quot;insert into mg_hive_external partition(deptno) select id,name,age,deptno from mgtable b where b.id not in (select id from mg_hive_external)&quot;);</span><br><span class="line">        Long t4 = System.currentTimeMillis();</span><br><span class="line">        System.out.println(&quot;å…±è€—æ—¶ï¼š&quot;+(t4 -t3)/60000+ &quot;åˆ†é’Ÿ&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="å·¥å…·ç±»"><a href="#å·¥å…·ç±»" class="headerlink" title="å·¥å…·ç±»"></a>å·¥å…·ç±»</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">package com.huawei.mongo;/*</span><br><span class="line"> * @Author: Create by Achun</span><br><span class="line"> *@Time: 2018/6/3 23:20</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line"></span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.List;</span><br><span class="line"></span><br><span class="line">public class SQLUtils &#123;</span><br><span class="line"></span><br><span class="line">    public List&lt;String&gt; getColumns(String querysql)&#123;</span><br><span class="line">        List&lt;String&gt; column = new ArrayList&lt;String&gt;();</span><br><span class="line">        String tmp = querysql.substring(querysql.indexOf(&quot;select&quot;) + 6,</span><br><span class="line">                querysql.indexOf(&quot;from&quot;)).trim();</span><br><span class="line">        if (tmp.indexOf(&quot;*&quot;) == -1)&#123;</span><br><span class="line">            String cols[] = tmp.split(&quot;,&quot;);</span><br><span class="line">            for (String c:cols)&#123;</span><br><span class="line">                column.add(c);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return column;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String getTBname(String querysql)&#123;</span><br><span class="line">        String tmp = querysql.substring(querysql.indexOf(&quot;from&quot;)+4).trim();</span><br><span class="line">        int sx = tmp.indexOf(&quot; &quot;);</span><br><span class="line">        if(sx == -1)&#123;</span><br><span class="line">            return tmp;</span><br><span class="line">        &#125;else &#123;</span><br><span class="line">            return tmp.substring(0,sx);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ä¸‰-é”™è¯¯è§£å†³åŠæ³•"><a href="#ä¸‰-é”™è¯¯è§£å†³åŠæ³•" class="headerlink" title="ä¸‰ é”™è¯¯è§£å†³åŠæ³•"></a>ä¸‰ é”™è¯¯è§£å†³åŠæ³•</h3><p>1 IDEAä¼šè·å–ä¸åˆ°Hiveçš„æ•°æ®åº“å’Œè¡¨ï¼Œå°†hive-site.xmlæ”¾å…¥resourcesæ–‡ä»¶ä¸­ã€‚å¹¶ä¸”å°†resourcesè®¾ç½®æˆé…ç½®æ–‡ä»¶(è®¾ç½®æˆåŠŸæ–‡ä»¶å¤¹æ˜¯è“è‰²å¦åˆ™æ˜¯ç°è‰²)<br>fileâ€“&gt;Project Structureâ€“&gt;Modulesâ€“&gt;Source<br><img src="/assets/blogImg/1120_1.png" alt="enter description here"><br>2 ä¸Šé¢é”™è¯¯å¤„ç†å®Œåå¦‚æœæŠ¥JDOç±»å‹çš„é”™è¯¯ï¼Œé‚£ä¹ˆæ£€æŸ¥HIVE_HOME/libä¸‹æ—¶å€™å¦mysqlé©±åŠ¨ï¼Œå¦‚æœç¡®å®šæœ‰ï¼Œé‚£ä¹ˆå°±æ˜¯IDEAè·å–ä¸åˆ°ã€‚è§£å†³æ–¹æ³•å¦‚ä¸‹ï¼š</p><p>å°†mysqlé©±åŠ¨æ‹·è´åˆ°jdk1.8.0_171.jdk/Contents/Home/jre/lib/extè·¯å¾„ä¸‹(jdk/jre/lib/ext)<br>åœ¨IDEAé¡¹ç›®External Librariesä¸‹çš„&lt;1.8&gt;é‡Œé¢æ·»åŠ mysqlé©±åŠ¨<br><img src="/assets/blogImg/1120_2.png" alt="enter description here"></p><h3 id="å››-æ³¨æ„ç‚¹"><a href="#å››-æ³¨æ„ç‚¹" class="headerlink" title="å›› æ³¨æ„ç‚¹"></a>å›› æ³¨æ„ç‚¹</h3><p>ç”±äºå°†MongoDBæ•°æ®è¡¨æ³¨å†Œæˆäº†ä¸´æ—¶è¡¨å’ŒHiveè¡¨è¿›è¡Œäº†å…³è”ï¼Œæ‰€ä»¥è¦å°†MongoDBä¸­çš„idå­—æ®µè®¾ç½®æˆç´¢å¼•å­—æ®µï¼Œå¦åˆ™æ€§èƒ½ä¼šå¾ˆæ…¢ã€‚<br>MongoDBè®¾ç½®ç´¢å¼•æ–¹æ³•ï¼š<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.getCollection(&apos;mgtest&apos;).ensureIndex(&#123;&quot;id&quot; : &quot;1&quot;&#125;),&#123;&quot;background&quot;:true&#125;</span><br></pre></td></tr></table></figure><p></p><p>æŸ¥çœ‹ç´¢å¼•ï¼š<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">db.getCollection(&apos;mgtest&apos;).getIndexes()</span><br><span class="line">MongoSparkç½‘å€ï¼šhttps://docs.mongodb.com/spark-connector/current/java-api/</span><br></pre></td></tr></table></figure><p></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 20 2019 22:37:10 GMT+0800 (GMT+08:00) --&gt;
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>æœ€å…¨çš„Flinkéƒ¨ç½²åŠå¼€å‘æ¡ˆä¾‹(KafkaSource+SinkToMySQL)</title>
    <link href="http://yoursite.com/2018/11/10/%E6%9C%80%E5%85%A8%E7%9A%84Flink%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%BC%80%E5%8F%91%E6%A1%88%E4%BE%8B(KafkaSource+SinkToMySQL)/"/>
    <id>http://yoursite.com/2018/11/10/æœ€å…¨çš„Flinkéƒ¨ç½²åŠå¼€å‘æ¡ˆä¾‹(KafkaSource+SinkToMySQL)/</id>
    <published>2018-11-09T16:00:00.000Z</published>
    <updated>2019-05-03T11:57:01.078Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --><h5 id="1-ä¸‹è½½Flinkå®‰è£…åŒ…"><a href="#1-ä¸‹è½½Flinkå®‰è£…åŒ…" class="headerlink" title="1.ä¸‹è½½Flinkå®‰è£…åŒ…"></a>1.ä¸‹è½½Flinkå®‰è£…åŒ…</h5><p>flinkä¸‹è½½åœ°å€</p><p><a href="https://archive.apache.org/dist/flink/flink-1.5.0/" target="_blank" rel="noopener">https://archive.apache.org/dist/flink/flink-1.5.0/</a></p><p>å› ä¸ºä¾‹å­ä¸éœ€è¦hadoopï¼Œä¸‹è½½flink-1.5.0-bin-scala_2.11.tgzå³å¯</p><p>ä¸Šä¼ è‡³æœºå™¨çš„/optç›®å½•ä¸‹<br><a id="more"></a></p><h5 id="2-è§£å‹"><a href="#2-è§£å‹" class="headerlink" title="2.è§£å‹"></a>2.è§£å‹</h5><p>tar -zxf flink-1.5.0-bin-scala_2.11.tgz -C ../opt/</p><h5 id="3-é…ç½®masterèŠ‚ç‚¹"><a href="#3-é…ç½®masterèŠ‚ç‚¹" class="headerlink" title="3.é…ç½®masterèŠ‚ç‚¹"></a>3.é…ç½®masterèŠ‚ç‚¹</h5><p>é€‰æ‹©ä¸€ä¸ª masterèŠ‚ç‚¹(JobManager)ç„¶ååœ¨conf/flink-conf.yamlä¸­è®¾ç½®jobmanager.rpc.address é…ç½®é¡¹ä¸ºè¯¥èŠ‚ç‚¹çš„IP æˆ–è€…ä¸»æœºåã€‚ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹æœ‰æœ‰ä¸€æ ·çš„jobmanager.rpc.address é…ç½®ã€‚</p><p>jobmanager.rpc.address: node1</p><p>(é…ç½®ç«¯å£å¦‚æœè¢«å ç”¨ä¹Ÿè¦æ”¹ å¦‚é»˜è®¤8080å·²ç»è¢«sparkå ç”¨ï¼Œæ”¹æˆäº†8088)</p><p>rest.port: 8088</p><p>æœ¬æ¬¡å®‰è£… masterèŠ‚ç‚¹ä¸ºnode1ï¼Œå› ä¸ºå•æœºï¼ŒslaveèŠ‚ç‚¹ä¹Ÿä¸ºnode1</p><h5 id="4-é…ç½®slaves"><a href="#4-é…ç½®slaves" class="headerlink" title="4.é…ç½®slaves"></a>4.é…ç½®slaves</h5><p>å°†æ‰€æœ‰çš„ worker èŠ‚ç‚¹ ï¼ˆTaskManagerï¼‰çš„IP æˆ–è€…ä¸»æœºåï¼ˆä¸€è¡Œä¸€ä¸ªï¼‰å¡«å…¥conf/slaves æ–‡ä»¶ä¸­ã€‚</p><h5 id="5-å¯åŠ¨flinké›†ç¾¤"><a href="#5-å¯åŠ¨flinké›†ç¾¤" class="headerlink" title="5.å¯åŠ¨flinké›†ç¾¤"></a>5.å¯åŠ¨flinké›†ç¾¤</h5><p>bin/start-cluster.sh</p><p>æ‰“å¼€ <a href="http://node1:8088" target="_blank" rel="noopener">http://node1:8088</a> æŸ¥çœ‹webé¡µé¢<br><img src="/assets/blogImg/1110_1.png" alt="enter description here"><br>Task Managersä»£è¡¨å½“å‰çš„flinkåªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œæ¯ä¸ªtaskè¿˜æœ‰ä¸¤ä¸ªslots</p><h5 id="6-æµ‹è¯•"><a href="#6-æµ‹è¯•" class="headerlink" title="6.æµ‹è¯•"></a>6.æµ‹è¯•</h5><p><strong>ä¾èµ–</strong><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&lt;groupId&gt;com.rz.flinkdemo&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;Flink-programe&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</span><br><span class="line"></span><br><span class="line">&lt;properties&gt;</span><br><span class="line">    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;</span><br><span class="line">    &lt;scala.binary.version&gt;2.11&lt;/scala.binary.version&gt;</span><br><span class="line">    &lt;flink.version&gt;1.5.0&lt;/flink.version&gt;</span><br><span class="line">&lt;/properties&gt;</span><br><span class="line">&lt;dependencies&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;flink-streaming-java_$&#123;scala.binary.version&#125;&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;flink-streaming-scala_$&#123;scala.binary.version&#125;&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;flink-cep_2.11&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;1.5.0&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">&lt;/dependencies&gt;</span><br></pre></td></tr></table></figure><p></p><h5 id="7-Socketæµ‹è¯•ä»£ç "><a href="#7-Socketæµ‹è¯•ä»£ç " class="headerlink" title="7.Socketæµ‹è¯•ä»£ç "></a>7.Socketæµ‹è¯•ä»£ç </h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">public class SocketWindowWordCount &#123;    public static void main(String[] args) throws Exception &#123;        // the port to connect to</span><br><span class="line">        final int port;        final String hostName;        try &#123;            final ParameterTool params = ParameterTool.fromArgs(args);</span><br><span class="line">            port = params.getInt(&quot;port&quot;);</span><br><span class="line">            hostName = params.get(&quot;hostname&quot;);</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            System.err.println(&quot;No port or hostname specified. Please run &apos;SocketWindowWordCount --port &lt;port&gt; --hostname &lt;hostname&gt;&apos;&quot;);            return;</span><br><span class="line">        &#125;        // get the execution environment</span><br><span class="line">        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();        // get input data by connecting to the socket</span><br><span class="line">        DataStream&lt;String&gt; text = env.socketTextStream(hostName, port, &quot;\n&quot;);        // parse the data, group it, window it, and aggregate the counts</span><br><span class="line">        DataStream&lt;WordWithCount&gt; windowCounts = text</span><br><span class="line">                .flatMap(new FlatMapFunction&lt;String, WordWithCount&gt;() &#123;                    public void flatMap(String value, Collector&lt;WordWithCount&gt; out) &#123;                        for (String word : value.split(&quot;\\s&quot;)) &#123;</span><br><span class="line">                            out.collect(new WordWithCount(word, 1L));</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;)</span><br><span class="line">                .keyBy(&quot;word&quot;)</span><br><span class="line">                .timeWindow(Time.seconds(5), Time.seconds(1))</span><br><span class="line">                .reduce(new ReduceFunction&lt;WordWithCount&gt;() &#123;                    public WordWithCount reduce(WordWithCount a, WordWithCount b) &#123;                        return new WordWithCount(a.word, a.count + b.count);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);        // print the results with a single thread, rather than in parallel</span><br><span class="line">        windowCounts.print().setParallelism(1);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        env.execute(&quot;Socket Window WordCount&quot;);</span><br><span class="line">    &#125;    // Data type for words with count</span><br><span class="line">    public static class WordWithCount &#123;        public String word;        public long count;        public WordWithCount() &#123;&#125;        public WordWithCount(String word, long count) &#123;            this.word = word;            this.count = count;</span><br><span class="line">        &#125;        @Override</span><br><span class="line">        public String toString() &#123;            return word + &quot; : &quot; + count;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ‰“åŒ…mvn clean install (å¦‚æœæ‰“åŒ…è¿‡ç¨‹ä¸­æŠ¥é”™java.lang.OutOfMemoryError)</p><p>åœ¨å‘½ä»¤è¡Œset MAVEN_OPTS= -Xms128m -Xmx512m</p><p>ç»§ç»­æ‰§è¡Œmvn clean install</p><p>ç”ŸæˆFlinkTest.jar<br><img src="/assets/blogImg/1110_2.png" alt="enter description here"><br>æ‰¾åˆ°æ‰“æˆçš„jarï¼Œå¹¶uploadï¼Œå¼€å§‹ä¸Šä¼ <br><img src="/assets/blogImg/1110_3.png" alt="enter description here"><br>è¿è¡Œå‚æ•°ä»‹ç»<br><img src="/assets/blogImg/1110_4.png" alt="enter description here"><br><img src="/assets/blogImg/1110_5.png" alt="enter description here"><br><img src="/assets/blogImg/1110_6.png" alt="enter description here"><br>æäº¤ç»“æŸä¹‹åå»overviewç•Œé¢çœ‹ï¼Œå¯ä»¥çœ‹åˆ°ï¼Œå¯ç”¨çš„slotså˜æˆäº†ä¸€ä¸ªï¼Œå› ä¸ºæˆ‘ä»¬çš„socketç¨‹åºå ç”¨äº†ä¸€ä¸ªï¼Œæ­£åœ¨runningçš„jobå˜æˆäº†ä¸€ä¸ª</p><p>å‘é€æ•°æ®<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop000 flink-1.5.0]# nc -l 8099</span><br><span class="line">aaa bbb</span><br><span class="line">aaa ccc</span><br><span class="line">aaa bbb</span><br><span class="line">bbb ccc</span><br></pre></td></tr></table></figure><p></p><p><img src="/assets/blogImg/1110_7.png" alt="enter description here"><br>ç‚¹å¼€runningçš„jobï¼Œä½ å¯ä»¥çœ‹è§æ¥æ”¶çš„å­—èŠ‚æ•°ç­‰ä¿¡æ¯</p><p>åˆ°logç›®å½•ä¸‹å¯ä»¥æ¸…æ¥šçš„çœ‹è§è¾“å‡º<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost log]# tail -f flink-root-taskexecutor-2-localhost.out</span><br><span class="line">aaa : 1</span><br><span class="line">ccc : 1</span><br><span class="line">ccc : 1</span><br><span class="line">bbb : 1</span><br><span class="line">ccc : 1</span><br><span class="line">bbb : 1</span><br><span class="line">bbb : 1</span><br><span class="line">ccc : 1</span><br><span class="line">bbb : 1</span><br><span class="line">ccc : 1</span><br></pre></td></tr></table></figure><p></p><p>é™¤äº†å¯ä»¥åœ¨ç•Œé¢æäº¤ï¼Œè¿˜å¯ä»¥å°†jarä¸Šä¼ çš„linuxä¸­è¿›è¡Œæäº¤ä»»åŠ¡</p><p>è¿è¡Œflinkä¸Šä¼ çš„jar<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flink run -c com.rz.flinkdemo.SocketWindowWordCount jars/FlinkTest.jar --port 8099 --hostname node1</span><br></pre></td></tr></table></figure><p></p><p>å…¶ä»–æ­¥éª¤ä¸€è‡´ã€‚</p><h5 id="8-ä½¿ç”¨kafkaä½œä¸ºsource"><a href="#8-ä½¿ç”¨kafkaä½œä¸ºsource" class="headerlink" title="8.ä½¿ç”¨kafkaä½œä¸ºsource"></a>8.ä½¿ç”¨kafkaä½œä¸ºsource</h5><p>åŠ ä¸Šä¾èµ–<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-connector-kafka-0.10_2.11&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.5.0&lt;/version&gt;&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public class KakfaSource010 &#123;    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        Properties properties = new Properties();</span><br><span class="line">        properties.setProperty(&quot;bootstrap.servers&quot;,&quot;node1:9092&quot;);</span><br><span class="line">        properties.setProperty(&quot;group.id&quot;,&quot;test&quot;);        //DataStream&lt;String&gt; test = env.addSource(new FlinkKafkaConsumer010&lt;String&gt;(&quot;topic&quot;, new SimpleStringSchema(), properties));</span><br><span class="line">        //å¯ä»¥é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æ¥åŒ¹é…åˆé€‚çš„topic</span><br><span class="line">        FlinkKafkaConsumer010&lt;String&gt; kafkaSource = new FlinkKafkaConsumer010&lt;&gt;(java.util.regex.Pattern.compile(&quot;test-[0-9]&quot;), new SimpleStringSchema(), properties);        //é…ç½®ä»æœ€æ–°çš„åœ°æ–¹å¼€å§‹æ¶ˆè´¹</span><br><span class="line">        kafkaSource.setStartFromLatest();        //ä½¿ç”¨addsourceï¼Œå°†kafkaçš„è¾“å…¥è½¬å˜ä¸ºdatastream</span><br><span class="line">        DataStream&lt;String&gt; consume = env.addSource(wordfre);</span><br><span class="line"></span><br><span class="line">        ...        //process  and   sink</span><br><span class="line"></span><br><span class="line">        env.execute(&quot;KakfaSource010&quot;);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="9-ä½¿ç”¨mysqlä½œä¸ºsink"><a href="#9-ä½¿ç”¨mysqlä½œä¸ºsink" class="headerlink" title="9.ä½¿ç”¨mysqlä½œä¸ºsink"></a>9.ä½¿ç”¨mysqlä½œä¸ºsink</h5><p>flinkæœ¬èº«å¹¶æ²¡æœ‰æä¾›datastreamè¾“å‡ºåˆ°mysqlï¼Œéœ€è¦æˆ‘ä»¬è‡ªå·±å»å®ç°</p><p>é¦–å…ˆï¼Œå¯¼å…¥ä¾èµ–<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;mysql&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;5.1.30&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p></p><p>è‡ªå®šä¹‰sinkï¼Œé¦–å…ˆæƒ³åˆ°çš„æ˜¯extends SinkFunctionï¼Œé›†æˆflinkè‡ªå¸¦çš„sinkfunctionï¼Œå†å½“ä¸­å®ç°æ–¹æ³•ï¼Œå®ç°å¦‚ä¸‹<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">public class MysqlSink implements</span><br><span class="line">        SinkFunction&lt;Tuple2&lt;String,String&gt;&gt; &#123;    private static final long serialVersionUID = 1L;    private Connection connection;    private PreparedStatement preparedStatement;</span><br><span class="line">    String username = &quot;mysql.user&quot;;</span><br><span class="line">    String password = &quot;mysql.password&quot;;</span><br><span class="line">    String drivername = &quot;mysql.driver&quot;;</span><br><span class="line">    String dburl = &quot;mysql.url&quot;;    @Override</span><br><span class="line">    public void invoke(Tuple2&lt;String,String&gt; value) throws Exception &#123;</span><br><span class="line">        Class.forName(drivername);</span><br><span class="line">        connection = DriverManager.getConnection(dburl, username, password);</span><br><span class="line">        String sql = &quot;insert into table(name,nickname) values(?,?)&quot;;</span><br><span class="line">        preparedStatement = connection.prepareStatement(sql);</span><br><span class="line">        preparedStatement.setString(1, value.f0);</span><br><span class="line">        preparedStatement.setString(2, value.f1);</span><br><span class="line">        preparedStatement.executeUpdate();        if (preparedStatement != null) &#123;</span><br><span class="line">            preparedStatement.close();</span><br><span class="line">        &#125;        if (connection != null) &#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>è¿™æ ·å®ç°æœ‰ä¸ªé—®é¢˜ï¼Œæ¯ä¸€æ¡æ•°æ®ï¼Œéƒ½è¦æ‰“å¼€mysqlè¿æ¥ï¼Œå†å…³é—­ï¼Œæ¯”è¾ƒè€—æ—¶ï¼Œè¿™ä¸ªå¯ä»¥ä½¿ç”¨flinkä¸­æ¯”è¾ƒå¥½çš„Richæ–¹å¼æ¥å®ç°ï¼Œä»£ç å¦‚ä¸‹<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">public class MysqlSink extends RichSinkFunction&lt;Tuple2&lt;String,String&gt;&gt; &#123;    private Connection connection = null;    private PreparedStatement preparedStatement = null;    private String userName = null;    private String password = null;    private String driverName = null;    private String DBUrl = null;    public MysqlSink() &#123;</span><br><span class="line">        userName = &quot;mysql.username&quot;;</span><br><span class="line">        password = &quot;mysql.password&quot;;</span><br><span class="line">        driverName = &quot;mysql.driverName&quot;;</span><br><span class="line">        DBUrl = &quot;mysql.DBUrl&quot;;</span><br><span class="line">    &#125;    public void invoke(Tuple2&lt;String,String&gt; value) throws Exception &#123;        if(connection==null)&#123;</span><br><span class="line">            Class.forName(driverName);</span><br><span class="line">            connection = DriverManager.getConnection(DBUrl, userName, password);</span><br><span class="line">        &#125;</span><br><span class="line">        String sql =&quot;insert into table(name,nickname) values(?,?)&quot;;</span><br><span class="line">        preparedStatement = connection.prepareStatement(sql);</span><br><span class="line"></span><br><span class="line">        preparedStatement.setString(1,value.f0);</span><br><span class="line">        preparedStatement.setString(2,value.f1);</span><br><span class="line"></span><br><span class="line">        preparedStatement.executeUpdate();//è¿”å›æˆåŠŸçš„è¯å°±æ˜¯ä¸€ä¸ªï¼Œå¦åˆ™å°±æ˜¯0</span><br><span class="line">    &#125;    @Override</span><br><span class="line">    public void open(Configuration parameters) throws Exception &#123;</span><br><span class="line">        Class.forName(driverName);</span><br><span class="line">        connection = DriverManager.getConnection(DBUrl, userName, password);</span><br><span class="line">    &#125;    @Override</span><br><span class="line">    public void close() throws Exception &#123;        if(preparedStatement!=null)&#123;</span><br><span class="line">            preparedStatement.close();</span><br><span class="line">        &#125;        if(connection!=null)&#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>Richæ–¹å¼çš„ä¼˜ç‚¹åœ¨äºï¼Œæœ‰ä¸ªopenå’Œcloseæ–¹æ³•ï¼Œåœ¨åˆå§‹åŒ–çš„æ—¶å€™å»ºç«‹ä¸€æ¬¡è¿æ¥ï¼Œä¹‹åä¸€ç›´ä½¿ç”¨è¿™ä¸ªè¿æ¥å³å¯ï¼Œç¼©çŸ­å»ºç«‹å’Œå…³é—­è¿æ¥çš„æ—¶é—´ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨è¿æ¥æ± å®ç°ï¼Œè¿™é‡Œåªæ˜¯æä¾›è¿™æ ·ä¸€ç§æ€è·¯ã€‚</p><p>ä½¿ç”¨è¿™ä¸ªmysqlsinkä¹Ÿéå¸¸ç®€å•<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">//ç›´æ¥addsinkï¼Œå³å¯è¾“å‡ºåˆ°è‡ªå®šä¹‰çš„mysqlä¸­ï¼Œä¹Ÿå¯ä»¥å°†mysqlçš„å­—æ®µç­‰å†™æˆå¯é…ç½®çš„ï¼Œæ›´åŠ æ–¹ä¾¿å’Œé€šç”¨proceDataStream.addSink(new MysqlSink());</span><br></pre></td></tr></table></figure><p></p><h5 id="10-æ€»ç»“"><a href="#10-æ€»ç»“" class="headerlink" title="10.æ€»ç»“"></a>10.æ€»ç»“</h5><p>æœ¬æ¬¡çš„ç¬”è®°åšäº†ç®€å•çš„éƒ¨ç½²ã€æµ‹è¯•ã€kafkademoï¼Œä»¥åŠè‡ªå®šä¹‰å®ç°mysqlsinkçš„ä¸€äº›å†…å®¹ï¼Œå…¶ä¸­æ¯”è¾ƒé‡è¦çš„æ˜¯Richçš„ä½¿ç”¨ï¼Œå¸Œæœ›å¤§å®¶èƒ½æœ‰æ‰€æ”¶è·ã€‚</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --&gt;&lt;h5 id=&quot;1-ä¸‹è½½Flinkå®‰è£…åŒ…&quot;&gt;&lt;a href=&quot;#1-ä¸‹è½½Flinkå®‰è£…åŒ…&quot; class=&quot;headerlink&quot; title=&quot;1.ä¸‹è½½Flinkå®‰è£…åŒ…&quot;&gt;&lt;/a&gt;1.ä¸‹è½½Flinkå®‰è£…åŒ…&lt;/h5&gt;&lt;p&gt;flinkä¸‹è½½åœ°å€&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://archive.apache.org/dist/flink/flink-1.5.0/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://archive.apache.org/dist/flink/flink-1.5.0/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;å› ä¸ºä¾‹å­ä¸éœ€è¦hadoopï¼Œä¸‹è½½flink-1.5.0-bin-scala_2.11.tgzå³å¯&lt;/p&gt;&lt;p&gt;ä¸Šä¼ è‡³æœºå™¨çš„/optç›®å½•ä¸‹&lt;br&gt;
    
    </summary>
    
      <category term="Flink" scheme="http://yoursite.com/categories/Flink/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>06ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®ä¹‹ KafkaOffsetMonitorç›‘æ§å·¥å…·çš„æ­å»º</title>
    <link href="http://yoursite.com/2018/09/05/06%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE%E4%B9%8B%20KafkaOffsetMonitor%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E7%9A%84%E6%90%AD%E5%BB%BA/"/>
    <id>http://yoursite.com/2018/09/05/06ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®ä¹‹ KafkaOffsetMonitorç›‘æ§å·¥å…·çš„æ­å»º/</id>
    <published>2018-09-04T16:00:00.000Z</published>
    <updated>2019-05-29T12:35:21.593Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed May 29 2019 20:36:04 GMT+0800 (GMT+08:00) --><h3 id="1-ä¸‹è½½"><a href="#1-ä¸‹è½½" class="headerlink" title="1.ä¸‹è½½"></a>1.ä¸‹è½½</h3><p>åœ¨window7 æ‰‹å·¥ä¸‹è½½å¥½ä¸‹é¢çš„é“¾æ¥<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/quantifind/KafkaOffsetMonitor/releases/tag/v0.2.1</span><br></pre></td></tr></table></figure><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopnn-01 app]# mkdir kafkaoffsetmonitor</span><br><span class="line">[root@sht-sgmhadoopnn-01 app]# cd kafkaoffsetmonitor</span><br><span class="line">#ä½¿ç”¨rzå‘½ä»¤ä¸Šä¼ </span><br><span class="line">[root@sht-sgmhadoopnn-01 kafkaoffsetmonitor]# rz</span><br><span class="line">rz waiting to receive.</span><br><span class="line">Starting zmodem transfer.  Press Ctrl+C to cancel.</span><br><span class="line">Transferring KafkaOffsetMonitor-assembly-0.2.1.jar...</span><br><span class="line">  100%   51696 KB    12924 KB/sec    00:00:04       0 Errors </span><br><span class="line">You have mail in /var/spool/mail/root</span><br><span class="line">[root@sht-sgmhadoopnn-01 kafkaoffsetmonitor]#</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="2-æ–°å»ºä¸€ä¸ªkafkaMonitor-shæ–‡ä»¶ï¼Œæ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼š"><a href="#2-æ–°å»ºä¸€ä¸ªkafkaMonitor-shæ–‡ä»¶ï¼Œæ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼š" class="headerlink" title="2.æ–°å»ºä¸€ä¸ªkafkaMonitor.shæ–‡ä»¶ï¼Œæ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼š"></a>2.æ–°å»ºä¸€ä¸ªkafkaMonitor.shæ–‡ä»¶ï¼Œæ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼š</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopnn-01 kafkaoffsetmonitor]# vi kafkaoffsetmonitor.sh</span><br><span class="line">! /bin/bash</span><br><span class="line">java -cp KafkaOffsetMonitor-assembly-0.2.1.jar \</span><br><span class="line">com.quantifind.kafka.offsetapp.OffsetGetterWeb \</span><br><span class="line">--zk 172.16.101.58:2181,172.16.101.59:2181,172.16.101.60:2181/kafka \</span><br><span class="line">--port 8089 \</span><br><span class="line">--refresh 5.seconds \</span><br><span class="line">--retain 7.days</span><br><span class="line">[root@sht-sgmhadoopnn-01 kafkaoffsetmonitor]# chmod +x *.sh</span><br><span class="line">[root@sht-sgmhadoopnn-01 kafkaoffsetmonitor]#</span><br></pre></td></tr></table></figure><p>å‚æ•°è¯´æ˜ï¼š<br>â€“zk è¿™é‡Œå†™çš„åœ°å€å’Œç«¯å£ï¼Œæ˜¯zookeeperé›†ç¾¤çš„å„ä¸ªåœ°å€å’Œç«¯å£ã€‚åº”å’Œkafka/binæ–‡ä»¶å¤¹ä¸­çš„zookeeper.propertiesä¸­çš„host.nameå’ŒclientPortä¸€è‡´ã€‚<br>â€“port è¿™ä¸ªæ˜¯æœ¬è½¯ä»¶KafkaOffsetMonitorçš„ç«¯å£ã€‚æ³¨æ„ä¸è¦ä½¿ç”¨é‚£äº›è‘—åçš„ç«¯å£å·ï¼Œä¾‹å¦‚80,8080ç­‰ã€‚æˆ‘é‡‡ç”¨äº†8089.<br>â€“refresh è¿™ä¸ªæ˜¯è½¯ä»¶åˆ·æ–°é—´éš”æ—¶é—´ï¼Œä¸è¦å¤ªçŸ­ä¹Ÿä¸è¦å¤ªé•¿ã€‚<br>â€“retain è¿™ä¸ªæ˜¯æ•°æ®åœ¨æ•°æ®åº“ä¸­ä¿å­˜çš„æ—¶é—´ã€‚</p><h3 id="3-åå°å¯åŠ¨"><a href="#3-åå°å¯åŠ¨" class="headerlink" title="3.åå°å¯åŠ¨"></a>3.åå°å¯åŠ¨</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"> 1[root@sht-sgmhadoopnn-01 kafkaoffsetmonitor]# nohup ./kafkaoffsetmonitor.sh &amp;</span><br><span class="line"> 2serving resources from: jar:file:/root/learnproject/app/kafkaoffsetmonitor/KafkaOffsetMonitor-assembly-0.2.1.jar!/offsetapp</span><br><span class="line"> 3SLF4J: Failed to load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.</span><br><span class="line"> 4SLF4J: Defaulting to no-operation (NOP) logger implementation</span><br><span class="line"> 5SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.</span><br><span class="line"> 6log4j:WARN No appenders could be found for logger (org.I0Itec.zkclient.ZkConnection).</span><br><span class="line"> 7log4j:WARN Please initialize the log4j system properly.</span><br><span class="line"> 8log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.</span><br><span class="line"> 9log4j:WARN No appenders could be found for logger (org.I0Itec.zkclient.ZkEventThread).</span><br><span class="line">10log4j:WARN Please initialize the log4j system properly.</span><br><span class="line">11log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.</span><br><span class="line">122016-12-25 22:00:24.252:INFO:oejs.Server:jetty-7.x.y-SNAPSHOT</span><br><span class="line">132016-12-25 22:00:24.319:INFO:oejsh.ContextHandler:started o.e.j.s.ServletContextHandler&#123;/,jar:file:/root/learnproject/app/kafkaoffsetmonitor/KafkaOffsetMonitor-assembly-0.2.1.jar!/offsetapp&#125;</span><br><span class="line">142016-12-25 22:00:24.328:INFO:oejs.AbstractConnector:Started SocketConnector@0.0.0.0:8089</span><br></pre></td></tr></table></figure><h3 id="4-IEæµè§ˆå™¨æ‰“å¼€"><a href="#4-IEæµè§ˆå™¨æ‰“å¼€" class="headerlink" title="4.IEæµè§ˆå™¨æ‰“å¼€"></a>4.IEæµè§ˆå™¨æ‰“å¼€</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://172.16.101.55:8089</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed May 29 2019 20:36:04 GMT+0800 (GMT+08:00) --&gt;&lt;h3 id=&quot;1-ä¸‹è½½&quot;&gt;&lt;a href=&quot;#1-ä¸‹è½½&quot; class=&quot;headerlink&quot; title=&quot;1.ä¸‹è½½&quot;&gt;&lt;/a&gt;1.ä¸‹è½½&lt;/h3&gt;&lt;p&gt;åœ¨window7 æ‰‹å·¥ä¸‹è½½å¥½ä¸‹é¢çš„é“¾æ¥&lt;br&gt;&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/quantifind/KafkaOffsetMonitor/releases/tag/v0.2.1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@sht-sgmhadoopnn-01 app]# mkdir kafkaoffsetmonitor&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@sht-sgmhadoopnn-01 app]# cd kafkaoffsetmonitor&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;#ä½¿ç”¨rzå‘½ä»¤ä¸Šä¼ &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@sht-sgmhadoopnn-01 kafkaoffsetmonitor]# rz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;rz waiting to receive.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Starting zmodem transfer.  Press Ctrl+C to cancel.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Transferring KafkaOffsetMonitor-assembly-0.2.1.jar...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  100%   51696 KB    12924 KB/sec    00:00:04       0 Errors &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;You have mail in /var/spool/mail/root&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@sht-sgmhadoopnn-01 kafkaoffsetmonitor]#&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®" scheme="http://yoursite.com/categories/%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®" scheme="http://yoursite.com/tags/%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE/"/>
    
  </entry>
  
  <entry>
    <title>05ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®ä¹‹Kafka 0.10.1.0 Clusterçš„æ­å»ºå’ŒTopicç®€å•æ“ä½œå®éªŒ</title>
    <link href="http://yoursite.com/2018/09/04/05%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE%E4%B9%8BKafka%200.10.1.0%20Cluster%E7%9A%84%E6%90%AD%E5%BB%BA%E5%92%8CTopic%E7%AE%80%E5%8D%95%E6%93%8D%E4%BD%9C%E5%AE%9E%E9%AA%8C/"/>
    <id>http://yoursite.com/2018/09/04/05ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®ä¹‹Kafka 0.10.1.0 Clusterçš„æ­å»ºå’ŒTopicç®€å•æ“ä½œå®éªŒ/</id>
    <published>2018-09-03T16:00:00.000Z</published>
    <updated>2019-05-29T12:32:04.677Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed May 29 2019 20:36:04 GMT+0800 (GMT+08:00) --><p>ã€kafka clusteræœºå™¨ã€‘:<br>æœºå™¨åç§° ç”¨æˆ·åç§°<br>sht-sgmhadoopdn-01/02/03 root<br>ã€å®‰è£…ç›®å½•ã€‘: /root/learnproject/app<br><a id="more"></a></p><h4 id="1-å°†scalaæ–‡ä»¶å¤¹åŒæ­¥åˆ°é›†ç¾¤å…¶ä»–æœºå™¨-scala-2-11ç‰ˆæœ¬ï¼Œå¯å•ç‹¬ä¸‹è½½è§£å‹"><a href="#1-å°†scalaæ–‡ä»¶å¤¹åŒæ­¥åˆ°é›†ç¾¤å…¶ä»–æœºå™¨-scala-2-11ç‰ˆæœ¬ï¼Œå¯å•ç‹¬ä¸‹è½½è§£å‹" class="headerlink" title="1.å°†scalaæ–‡ä»¶å¤¹åŒæ­¥åˆ°é›†ç¾¤å…¶ä»–æœºå™¨(scala 2.11ç‰ˆæœ¬ï¼Œå¯å•ç‹¬ä¸‹è½½è§£å‹)"></a>1.å°†scalaæ–‡ä»¶å¤¹åŒæ­¥åˆ°é›†ç¾¤å…¶ä»–æœºå™¨(scala 2.11ç‰ˆæœ¬ï¼Œå¯å•ç‹¬ä¸‹è½½è§£å‹)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopnn-01 app]# scp -r scala root@sht-sgmhadoopdn-01:/root/learnproject/app/</span><br><span class="line">[root@sht-sgmhadoopnn-01 app]# scp -r scala root@sht-sgmhadoopdn-02:/root/learnproject/app/</span><br><span class="line">[root@sht-sgmhadoopnn-01 app]# scp -r scala root@sht-sgmhadoopdn-03:/root/learnproject/app/</span><br><span class="line"></span><br><span class="line">#ç¯å¢ƒå˜é‡</span><br><span class="line">[root@sht-sgmhadoopdn-01 app]# vi /etc/profile</span><br><span class="line">export SCALA_HOME=/root/learnproject/app/scala</span><br><span class="line">export PATH=$SCALA_HOME/bin:$HADOOP_HOME/bin:$MAVEN_HOME/bin:$JAVA_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line">[root@sht-sgmhadoopdn-02 app]# vi /etc/profile</span><br><span class="line">export SCALA_HOME=/root/learnproject/app/scala</span><br><span class="line">export PATH=$SCALA_HOME/bin:$HADOOP_HOME/bin:$MAVEN_HOME/bin:$JAVA_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line">[root@sht-sgmhadoopdn-02 app]# vi /etc/profile</span><br><span class="line">export SCALA_HOME=/root/learnproject/app/scala</span><br><span class="line">export PATH=$SCALA_HOME/bin:$HADOOP_HOME/bin:$MAVEN_HOME/bin:$JAVA_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@sht-sgmhadoopdn-01 app]# source /etc/profile</span><br><span class="line">[root@sht-sgmhadoopdn-02 app]# source /etc/profile</span><br><span class="line">[root@sht-sgmhadoopdn-03 app]# source /etc/profile</span><br></pre></td></tr></table></figure><h4 id="2-ä¸‹è½½åŸºäºScala-2-11çš„kafkaç‰ˆæœ¬ä¸º0-10-1-0"><a href="#2-ä¸‹è½½åŸºäºScala-2-11çš„kafkaç‰ˆæœ¬ä¸º0-10-1-0" class="headerlink" title="2.ä¸‹è½½åŸºäºScala 2.11çš„kafkaç‰ˆæœ¬ä¸º0.10.1.0"></a>2.ä¸‹è½½åŸºäºScala 2.11çš„kafkaç‰ˆæœ¬ä¸º0.10.1.0</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopdn-01 app]# pwd</span><br><span class="line">/root/learnproject/app</span><br><span class="line">[root@sht-sgmhadoopdn-01 app]# wget http://www-eu.apache.org/dist/kafka/0.10.1.0/kafka_2.11-0.10.1.0.tgz</span><br><span class="line">[root@sht-sgmhadoopdn-01 app]# tar xzvf kafka_2.11-0.10.1.0.tgz </span><br><span class="line">[root@sht-sgmhadoopdn-01 app]# mv kafka_2.11-0.10.1.0 kafka</span><br></pre></td></tr></table></figure><h4 id="3-åˆ›å»ºlogsç›®å½•å’Œä¿®æ”¹server-properties-å‰æzookeeper-clusteréƒ¨ç½²å¥½ï¼Œè§â€œ03ã€åœ¨çº¿æ—¥å¿—åˆ†æã€‘ä¹‹hadoop-2-7-3ç¼–è¯‘å’Œæ­å»ºé›†ç¾¤ç¯å¢ƒ-HDFS-HA-Yarn-HA-â€"><a href="#3-åˆ›å»ºlogsç›®å½•å’Œä¿®æ”¹server-properties-å‰æzookeeper-clusteréƒ¨ç½²å¥½ï¼Œè§â€œ03ã€åœ¨çº¿æ—¥å¿—åˆ†æã€‘ä¹‹hadoop-2-7-3ç¼–è¯‘å’Œæ­å»ºé›†ç¾¤ç¯å¢ƒ-HDFS-HA-Yarn-HA-â€" class="headerlink" title="3.åˆ›å»ºlogsç›®å½•å’Œä¿®æ”¹server.properties(å‰æzookeeper clusteréƒ¨ç½²å¥½ï¼Œè§â€œ03ã€åœ¨çº¿æ—¥å¿—åˆ†æã€‘ä¹‹hadoop-2.7.3ç¼–è¯‘å’Œæ­å»ºé›†ç¾¤ç¯å¢ƒ(HDFS HA,Yarn HA)â€ )"></a>3.åˆ›å»ºlogsç›®å½•å’Œä¿®æ”¹server.properties(å‰æzookeeper clusteréƒ¨ç½²å¥½ï¼Œè§â€œ03ã€åœ¨çº¿æ—¥å¿—åˆ†æã€‘ä¹‹hadoop-2.7.3ç¼–è¯‘å’Œæ­å»ºé›†ç¾¤ç¯å¢ƒ(HDFS HA,Yarn HA)â€ )</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopdn-01 app]# cd kafka</span><br><span class="line">[root@sht-sgmhadoopdn-01 kafka]# mkdir logs</span><br><span class="line">[root@sht-sgmhadoopdn-01 kafka]# cd config/</span><br><span class="line">[root@sht-sgmhadoopdn-01 config]# vi server.properties</span><br><span class="line">broker.id=1</span><br><span class="line">port=9092</span><br><span class="line">host.name=172.16.101.58</span><br><span class="line">log.dirs=/root/learnproject/app/kafka/logs</span><br><span class="line">zookeeper.connect=172.16.101.58:2181,172.16.101.59:2181,172.16.101.60:2181/kafka</span><br></pre></td></tr></table></figure><h4 id="4-åŒæ­¥åˆ°02-03æœåŠ¡å™¨ï¼Œæ›´æ”¹broker-id-åŠhost-name"><a href="#4-åŒæ­¥åˆ°02-03æœåŠ¡å™¨ï¼Œæ›´æ”¹broker-id-åŠhost-name" class="headerlink" title="4.åŒæ­¥åˆ°02/03æœåŠ¡å™¨ï¼Œæ›´æ”¹broker.id åŠhost.name"></a>4.åŒæ­¥åˆ°02/03æœåŠ¡å™¨ï¼Œæ›´æ”¹broker.id åŠhost.name</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopdn-01 app]# scp -r kafka sht-sgmhadoopdn-03:/root/learnproject/app/</span><br><span class="line">[root@sht-sgmhadoopdn-01 app]# scp -r kafka sht-sgmhadoopdn-03:/root/learnproject/app/</span><br><span class="line"></span><br><span class="line">[root@sht-sgmhadoopdn-02 config]# vi server.properties </span><br><span class="line">broker.id=2</span><br><span class="line">port=9092</span><br><span class="line">host.name=172.16.101.59</span><br><span class="line"></span><br><span class="line">[root@sht-sgmhadoopdn-03 config]# vi server.properties </span><br><span class="line">broker.id=3</span><br><span class="line">port=9092</span><br><span class="line">host.name=172.16.101.60</span><br></pre></td></tr></table></figure><h4 id="5-ç¯å¢ƒå˜é‡"><a href="#5-ç¯å¢ƒå˜é‡" class="headerlink" title="5.ç¯å¢ƒå˜é‡"></a>5.ç¯å¢ƒå˜é‡</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopdn-01 kafka]# vi /etc/profile</span><br><span class="line">export KAFKA_HOME=/root/learnproject/app/kafka</span><br><span class="line">export PATH=$KAFKA_HOME/bin:$SCALA_HOME/bin:$ZOOKEEPER_HOME/bin:$HADOOP_HOME/bin:$JAVA_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line">[root@sht-sgmhadoopdn-01 kafka]# scp /etc/profile sht-sgmhadoopdn-02:/etc/profile</span><br><span class="line">[root@sht-sgmhadoopdn-01 kafka]# scp /etc/profile sht-sgmhadoopdn-03:/etc/profile</span><br><span class="line">[root@sht-sgmhadoopdn-01 kafka]#</span><br><span class="line"></span><br><span class="line">[root@sht-sgmhadoopdn-01 kafka]# source /etc/profile</span><br><span class="line">[root@sht-sgmhadoopdn-02 kafka]# source /etc/profile</span><br><span class="line">[root@sht-sgmhadoopdn-03 kafka]# source /etc/profile</span><br></pre></td></tr></table></figure><h4 id="6-å¯åŠ¨-åœæ­¢"><a href="#6-å¯åŠ¨-åœæ­¢" class="headerlink" title="6.å¯åŠ¨/åœæ­¢"></a>6.å¯åŠ¨/åœæ­¢</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopdn-01 kafka]# nohup kafka-server-start.sh config/server.properties &amp;</span><br><span class="line">[root@sht-sgmhadoopdn-02 kafka]# nohup kafka-server-start.sh config/server.properties &amp;</span><br><span class="line">[root@sht-sgmhadoopdn-03 kafka]# nohup kafka-server-start.sh config/server.properties &amp;</span><br><span class="line"></span><br><span class="line">###åœæ­¢</span><br><span class="line">bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure><h4 id="7-topicç›¸å…³çš„æ“ä½œ"><a href="#7-topicç›¸å…³çš„æ“ä½œ" class="headerlink" title="7.topicç›¸å…³çš„æ“ä½œ"></a>7.topicç›¸å…³çš„æ“ä½œ</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">a.åˆ›å»ºtopicï¼Œå¦‚èƒ½æˆåŠŸåˆ›å»ºtopicåˆ™è¡¨ç¤ºé›†ç¾¤å®‰è£…å®Œæˆï¼Œä¹Ÿå¯ä»¥ç”¨jpså‘½ä»¤æŸ¥çœ‹kafkaè¿›ç¨‹æ˜¯å¦å­˜åœ¨ã€‚</span><br><span class="line">[root@sht-sgmhadoopdn-01 kafka]# bin/kafka-topics.sh --create --zookeeper 172.16.101.58:2181,172.16.101.59:2181,172.16.101.60:2181/kafka --replication-factor 3 --partitions 1 --topic test</span><br><span class="line"></span><br><span class="line">b.é€šè¿‡listå‘½ä»¤æŸ¥çœ‹åˆ›å»ºçš„topic:</span><br><span class="line">[root@sht-sgmhadoopdn-01 kafka]# bin/kafka-topics.sh --list --zookeeper 172.16.101.58:2181,172.16.101.59:2181,172.16.101.60:2181/kafka</span><br><span class="line"></span><br><span class="line">c.æŸ¥çœ‹åˆ›å»ºçš„Topic</span><br><span class="line">[root@sht-sgmhadoopdn-01 kafka]# bin/kafka-topics.sh --describe --zookeeper 172.16.101.58:2181,172.16.101.59:2181,172.16.101.60:2181/kafka --topic test</span><br><span class="line">Topic:test      PartitionCount:1        ReplicationFactor:3     Configs:</span><br><span class="line">        Topic: test     Partition: 0    Leader: 3       Replicas: 3,1,2 Isr: 3,1,2</span><br><span class="line">[root@sht-sgmhadoopdn-01 kafka]# </span><br><span class="line">ç¬¬ä¸€è¡Œåˆ—å‡ºäº†è¿™ä¸ªtopicçš„æ€»ä½“æƒ…å†µï¼Œå¦‚topicåç§°ï¼Œåˆ†åŒºæ•°é‡ï¼Œå‰¯æœ¬æ•°é‡ç­‰ã€‚</span><br><span class="line">ç¬¬äºŒè¡Œå¼€å§‹ï¼Œæ¯ä¸€è¡Œåˆ—å‡ºäº†ä¸€ä¸ªåˆ†åŒºçš„ä¿¡æ¯ï¼Œå¦‚å®ƒæ˜¯ç¬¬å‡ ä¸ªåˆ†åŒºï¼Œè¿™ä¸ªåˆ†åŒºçš„leaderæ˜¯å“ªä¸ªbrokerï¼Œå‰¯æœ¬ä½äºå“ªäº›brokerï¼Œæœ‰å“ªäº›å‰¯æœ¬å¤„ç†åŒæ­¥çŠ¶æ€ã€‚</span><br><span class="line"></span><br><span class="line">Partitionï¼š åˆ†åŒº</span><br><span class="line">Leader ï¼š   è´Ÿè´£è¯»å†™æŒ‡å®šåˆ†åŒºçš„èŠ‚ç‚¹</span><br><span class="line">Replicas ï¼š å¤åˆ¶è¯¥åˆ†åŒºlogçš„èŠ‚ç‚¹åˆ—è¡¨</span><br><span class="line">Isr ï¼š      â€œin-syncâ€ replicasï¼Œå½“å‰æ´»è·ƒçš„å‰¯æœ¬åˆ—è¡¨ï¼ˆæ˜¯ä¸€ä¸ªå­é›†ï¼‰ï¼Œå¹¶ä¸”å¯èƒ½æˆä¸ºLeader</span><br><span class="line">æˆ‘ä»¬å¯ä»¥é€šè¿‡Kafkaè‡ªå¸¦çš„bin/kafka-console-producer.shå’Œbin/kafka-console-consumer.shè„šæœ¬ï¼Œæ¥éªŒè¯æ¼”ç¤ºå¦‚æœå‘å¸ƒæ¶ˆæ¯ã€æ¶ˆè´¹æ¶ˆæ¯ã€‚</span><br><span class="line"></span><br><span class="line">d.åˆ é™¤topic</span><br><span class="line">[root@sht-sgmhadoopdn-01 kafka]# bin/kafka-topics.sh  --delete --zookeeper  172.16.101.58:2181,172.16.101.59:2181,172.16.101.60:2181/kafka  --topic test</span><br><span class="line"></span><br><span class="line">e.ä¿®æ”¹topic</span><br><span class="line">ä½¿ç”¨â€”-alertåŸåˆ™ä¸Šå¯ä»¥ä¿®æ”¹ä»»ä½•é…ç½®ï¼Œä»¥ä¸‹åˆ—å‡ºäº†ä¸€äº›å¸¸ç”¨çš„ä¿®æ”¹é€‰é¡¹ï¼š</span><br><span class="line">ï¼ˆ1ï¼‰æ”¹å˜åˆ†åŒºæ•°é‡</span><br><span class="line">[root@sht-sgmhadoopdn-02 kafka]#bin/kafka-topics.sh --alter  --zookeeper 172.16.101.58:2181,172.16.101.59:2181,172.16.101.60:2181/kafka --topic test --partitions 3</span><br><span class="line">[root@sht-sgmhadoopdn-02 kafka]# bin/kafka-topics.sh --describe --zookeeper 172.16.101.58:2181,172.16.101.59:2181,172.16.101.60:2181/kafka --topic test</span><br><span class="line">Topic:test      PartitionCount:3        ReplicationFactor:3     Configs:</span><br><span class="line">        Topic: test     Partition: 0    Leader: 3       Replicas: 3,1,2 Isr: 3,1,2</span><br><span class="line">        Topic: test     Partition: 1    Leader: 1       Replicas: 1,2,3 Isr: 1,2,3</span><br><span class="line">        Topic: test     Partition: 2    Leader: 2       Replicas: 2,3,1 Isr: 2,3,1</span><br><span class="line">[root@sht-sgmhadoopdn-02 kafka]#</span><br><span class="line"></span><br><span class="line">ï¼ˆ2ï¼‰å¢åŠ ã€ä¿®æ”¹æˆ–è€…åˆ é™¤ä¸€ä¸ªé…ç½®å‚æ•°</span><br><span class="line"> bin/kafka-topics.sh â€”alter --zookeeper 192.168.172.98:2181/kafka  --topic my_topic_name --config key=value</span><br><span class="line"> bin/kafka-topics.sh â€”alter --zookeeper 192.168.172.98:2181/kafka  --topic my_topic_name --deleteConfig key</span><br></pre></td></tr></table></figure><h4 id="8-æ¨¡æ‹Ÿå®éªŒ1"><a href="#8-æ¨¡æ‹Ÿå®éªŒ1" class="headerlink" title="8.æ¨¡æ‹Ÿå®éªŒ1"></a>8.æ¨¡æ‹Ÿå®éªŒ1</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">åœ¨ä¸€ä¸ªç»ˆç«¯ï¼Œå¯åŠ¨Producerï¼Œå¹¶å‘æˆ‘ä»¬ä¸Šé¢åˆ›å»ºçš„åç§°ä¸ºmy-replicated-topic5çš„Topicä¸­ç”Ÿäº§æ¶ˆæ¯ï¼Œæ‰§è¡Œå¦‚ä¸‹è„šæœ¬ï¼š</span><br><span class="line">[root@sht-sgmhadoopdn-01 kafka]# bin/kafka-console-producer.sh --broker-list 172.16.101.58:9092,172.16.101.59:9092,172.16.101.60:9092 --topic test</span><br><span class="line"></span><br><span class="line">åœ¨å¦ä¸€ä¸ªç»ˆç«¯ï¼Œå¯åŠ¨Consumerï¼Œå¹¶è®¢é˜…æˆ‘ä»¬ä¸Šé¢åˆ›å»ºçš„åç§°ä¸ºmy-replicated-topic5çš„Topicä¸­ç”Ÿäº§çš„æ¶ˆæ¯ï¼Œæ‰§è¡Œå¦‚ä¸‹è„šæœ¬ï¼š</span><br><span class="line">[root@sht-sgmhadoopdn-02 kafka]# bin/kafka-console-consumer.sh --zookeeper 172.16.101.58:2181,172.16.101.59:2181,172.16.101.60:2181/kafka --from-beginning --topic test</span><br><span class="line"></span><br><span class="line">å¯ä»¥åœ¨Producerç»ˆç«¯ä¸Šè¾“å…¥å­—ç¬¦ä¸²æ¶ˆæ¯è¡Œï¼Œå°±å¯ä»¥åœ¨Consumerç»ˆç«¯ä¸Šçœ‹åˆ°æ¶ˆè´¹è€…æ¶ˆè´¹çš„æ¶ˆæ¯å†…å®¹ã€‚</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed May 29 2019 20:36:04 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;ã€kafka clusteræœºå™¨ã€‘:&lt;br&gt;æœºå™¨åç§° ç”¨æˆ·åç§°&lt;br&gt;sht-sgmhadoopdn-01/02/03 root&lt;br&gt;ã€å®‰è£…ç›®å½•ã€‘: /root/learnproject/app&lt;br&gt;
    
    </summary>
    
      <category term="ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®" scheme="http://yoursite.com/categories/%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®" scheme="http://yoursite.com/tags/%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE/"/>
    
  </entry>
  
  <entry>
    <title>04ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®ä¹‹Flume Agentçš„3å°æ”¶é›†+1å°èšåˆåˆ°hdfsçš„æ­å»º</title>
    <link href="http://yoursite.com/2018/09/03/04%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE%E4%B9%8BFlume%20Agent%E7%9A%843%E5%8F%B0%E6%94%B6%E9%9B%86+1%E5%8F%B0%E8%81%9A%E5%90%88%E5%88%B0hdfs%E7%9A%84%E6%90%AD%E5%BB%BA/"/>
    <id>http://yoursite.com/2018/09/03/04ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®ä¹‹Flume Agentçš„3å°æ”¶é›†+1å°èšåˆåˆ°hdfsçš„æ­å»º/</id>
    <published>2018-09-02T16:00:00.000Z</published>
    <updated>2019-05-28T13:29:50.441Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue May 28 2019 21:30:51 GMT+0800 (GMT+08:00) --><p>ã€logæ”¶é›†ã€‘:<br>æœºå™¨åç§° æœåŠ¡åç§° ç”¨æˆ·<br>flume-agent-01: namenode hdfs<br>flume-agent-02: datanode hdfs<br>flume-agent-03: datanode hdfs</p><p>ã€logèšåˆã€‘:<br>æœºå™¨åç§° ç”¨æˆ·<br>sht-sgmhadoopcm-01(172.16.101.54) root</p><p>ã€sinkåˆ°hdfsã€‘:<br>hdfs://172.16.101.56:8020/testwjp/</p><a id="more"></a><h5 id="1-ä¸‹è½½apache-flume-1-7-0-bin-tar-gz"><a href="#1-ä¸‹è½½apache-flume-1-7-0-bin-tar-gz" class="headerlink" title="1.ä¸‹è½½apache-flume-1.7.0-bin.tar.gz"></a>1.ä¸‹è½½apache-flume-1.7.0-bin.tar.gz</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[hdfs@flume-agent-01 tmp]$ wget http://www-eu.apache.org/dist/flume/1.7.0/apache-flume-1.7.0-bin.tar.gz</span><br><span class="line">--2017-01-04 20:40:10--  http://www-eu.apache.org/dist/flume/1.7.0/apache-flume-1.7.0-bin.tar.gz</span><br><span class="line">Resolving www-eu.apache.org... 88.198.26.2, 2a01:4f8:130:2192::2</span><br><span class="line">Connecting to www-eu.apache.org|88.198.26.2|:80... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 55711670 (53M) [application/x-gzip]</span><br><span class="line">Saving to: â€œapache-flume-1.7.0-bin.tar.gzâ€</span><br><span class="line"></span><br><span class="line">100%[===============================================================================================================================================================================================&gt;] 55,711,670   473K/s   in 74s    </span><br><span class="line"></span><br><span class="line">2017-01-04 20:41:25 (733 KB/s) - â€œapache-flume-1.7.0-bin.tar.gzâ€ saved [55711670/55711670]</span><br></pre></td></tr></table></figure><h5 id="2-è§£å‹é‡å‘½å"><a href="#2-è§£å‹é‡å‘½å" class="headerlink" title="2.è§£å‹é‡å‘½å"></a>2.è§£å‹é‡å‘½å</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hdfs@flume-agent-01 tmp]$ </span><br><span class="line">[hdfs@flume-agent-01 tmp]$ tar -xzvf apache-flume-1.7.0-bin.tar.gz </span><br><span class="line">[hdfs@flume-agent-01 tmp]$ mv apache-flume-1.7.0-bin flume-ng</span><br><span class="line">[hdfs@flume-agent-01 tmp]$ cd flume-ng/conf</span><br></pre></td></tr></table></figure><h5 id="3-æ‹·è´flumeç¯å¢ƒé…ç½®å’Œagenté…ç½®æ–‡ä»¶"><a href="#3-æ‹·è´flumeç¯å¢ƒé…ç½®å’Œagenté…ç½®æ–‡ä»¶" class="headerlink" title="3.æ‹·è´flumeç¯å¢ƒé…ç½®å’Œagenté…ç½®æ–‡ä»¶"></a>3.æ‹·è´flumeç¯å¢ƒé…ç½®å’Œagenté…ç½®æ–‡ä»¶</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hdfs@flume-agent-01 tmp]$ cp flume-env.sh.template flume-env.sh</span><br><span class="line">[hdfs@flume-agent-01 tmp]$ cp flume-conf.properties.template exec_memory_avro.properties</span><br></pre></td></tr></table></figure><h5 id="4-æ·»åŠ hdfsç”¨æˆ·çš„ç¯å¢ƒå˜é‡æ–‡ä»¶"><a href="#4-æ·»åŠ hdfsç”¨æˆ·çš„ç¯å¢ƒå˜é‡æ–‡ä»¶" class="headerlink" title="4.æ·»åŠ hdfsç”¨æˆ·çš„ç¯å¢ƒå˜é‡æ–‡ä»¶"></a>4.æ·»åŠ hdfsç”¨æˆ·çš„ç¯å¢ƒå˜é‡æ–‡ä»¶</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[hdfs@flume-agent-01 tmp]$ cd</span><br><span class="line">[hdfs@flume-agent-01 ~]$ ls -la</span><br><span class="line">total 24</span><br><span class="line">drwxr-xr-x   3 hdfs hadoop 4096 Jul  8 14:05 .</span><br><span class="line">drwxr-xr-x. 35 root root   4096 Dec 10  2015 ..</span><br><span class="line">-rw-------   1 hdfs hdfs   4471 Jul  8 17:22 .bash_history</span><br><span class="line">drwxrwxrwt   2 hdfs hadoop 4096 Nov 19  2014 cache</span><br><span class="line">-rw-------   1 hdfs hdfs   3131 Jul  8 14:05 .viminfo</span><br><span class="line">[hdfs@flume-agent-01 ~]$ cp /etc/skel/.* ./</span><br><span class="line">cp: omitting directory `/etc/skel/.&apos;</span><br><span class="line">cp: omitting directory `/etc/skel/..&apos;</span><br><span class="line">[hdfs@flume-agent-01 ~]$ ls -la</span><br><span class="line">total 36</span><br><span class="line">drwxr-xr-x   3 hdfs hadoop 4096 Jan  4 20:49 .</span><br><span class="line">drwxr-xr-x. 35 root root   4096 Dec 10  2015 ..</span><br><span class="line">-rw-------   1 hdfs hdfs   4471 Jul  8 17:22 .bash_history</span><br><span class="line">-rw-r--r--   1 hdfs hdfs     18 Jan  4 20:49 .bash_logout</span><br><span class="line">-rw-r--r--   1 hdfs hdfs    176 Jan  4 20:49 .bash_profile</span><br><span class="line">-rw-r--r--   1 hdfs hdfs    124 Jan  4 20:49 .bashrc</span><br><span class="line">drwxrwxrwt   2 hdfs hadoop 4096 Nov 19  2014 cache</span><br><span class="line">-rw-------   1 hdfs hdfs   3131 Jul  8 14:05 .viminfo</span><br></pre></td></tr></table></figure><h5 id="5-æ·»åŠ flumeçš„ç¯å¢ƒå˜é‡"><a href="#5-æ·»åŠ flumeçš„ç¯å¢ƒå˜é‡" class="headerlink" title="5.æ·»åŠ flumeçš„ç¯å¢ƒå˜é‡"></a>5.æ·»åŠ flumeçš„ç¯å¢ƒå˜é‡</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hdfs@flume-agent-01 ~]$ vi .bash_profile</span><br><span class="line"></span><br><span class="line">export FLUME_HOME=/tmp/flume-ng</span><br><span class="line">export FLUME_CONF_DIR=$FLUME_HOME/conf</span><br><span class="line">export PATH=$PATH:$FLUME_HOME/bin</span><br><span class="line">[hdfs@flume-agent-01 ~]$ . .bash_profile</span><br></pre></td></tr></table></figure><h5 id="6-ä¿®æ”¹flumeç¯å¢ƒé…ç½®æ–‡ä»¶"><a href="#6-ä¿®æ”¹flumeç¯å¢ƒé…ç½®æ–‡ä»¶" class="headerlink" title="6.ä¿®æ”¹flumeç¯å¢ƒé…ç½®æ–‡ä»¶"></a>6.ä¿®æ”¹flumeç¯å¢ƒé…ç½®æ–‡ä»¶</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hdfs@flume-agent-01 conf]$ vi flume-env.sh</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.7.0_25</span><br></pre></td></tr></table></figure><h5 id="7-å°†åŸºäºFlume-ng-Exec-Sourceå¼€å‘è‡ªå®šä¹‰æ’ä»¶AdvancedExecSourceçš„AdvancedExecSource-jaråŒ…ä¸Šä¼ åˆ°-FLUME-HOME-lib"><a href="#7-å°†åŸºäºFlume-ng-Exec-Sourceå¼€å‘è‡ªå®šä¹‰æ’ä»¶AdvancedExecSourceçš„AdvancedExecSource-jaråŒ…ä¸Šä¼ åˆ°-FLUME-HOME-lib" class="headerlink" title="7.å°†åŸºäºFlume-ng Exec Sourceå¼€å‘è‡ªå®šä¹‰æ’ä»¶AdvancedExecSourceçš„AdvancedExecSource.jaråŒ…ä¸Šä¼ åˆ°$FLUME_HOME/lib/"></a>7.å°†åŸºäºFlume-ng Exec Sourceå¼€å‘è‡ªå®šä¹‰æ’ä»¶AdvancedExecSourceçš„AdvancedExecSource.jaråŒ…ä¸Šä¼ åˆ°$FLUME_HOME/lib/</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://blog.itpub.net/30089851/viewspace-2131995/</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hdfs@LogshedNameNodeLogcollector lib]$ pwd</span><br><span class="line">/tmp/flume-ng/lib</span><br><span class="line">[hdfs@LogshedNameNodeLogcollector lib]$ ll AdvancedExecSource.jar </span><br><span class="line">-rw-r--r-- 1 hdfs hdfs 10618 Jan  5 23:50 AdvancedExecSource.jar</span><br><span class="line">[hdfs@LogshedNameNodeLogcollector lib]$</span><br></pre></td></tr></table></figure><h5 id="8-ä¿®æ”¹flumeçš„agenté…ç½®æ–‡ä»¶"><a href="#8-ä¿®æ”¹flumeçš„agenté…ç½®æ–‡ä»¶" class="headerlink" title="8.ä¿®æ”¹flumeçš„agenté…ç½®æ–‡ä»¶"></a>8.ä¿®æ”¹flumeçš„agenté…ç½®æ–‡ä»¶</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[hdfs@flume-agent-01 conf]$ vi exec_memory_avro.properties</span><br><span class="line">#Name the components on this agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line">#Describe/configure the custom exec source</span><br><span class="line">a1.sources.r1.type = com.onlinelog.analysis.AdvancedExecSource</span><br><span class="line">a1.sources.r1.command = tail -f /var/log/hadoop-hdfs/hadoop-cmf-hdfs1-NAMENODE-flume-agent-01.log.out</span><br><span class="line">a1.sources.r1.hostname = flume-agent-01</span><br><span class="line">a1.sources.r1.servicename = namenode</span><br><span class="line"></span><br><span class="line">#Describe the sink</span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = 172.16.101.54</span><br><span class="line">a1.sinks.k1.port = 4545</span><br><span class="line"></span><br><span class="line">#Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.keep-alive = 60 </span><br><span class="line">a1.channels.c1.capacity = 1000000</span><br><span class="line">a1.channels.c1.transactionCapacity = 2000</span><br><span class="line"></span><br><span class="line">#Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure><h5 id="9-å°†flume-agent-01çš„flume-ngæ‰“åŒ…-scpåˆ°flume-agent-02-03-å’Œ-sht-sgmhadoopcm-01-172-16-101-54"><a href="#9-å°†flume-agent-01çš„flume-ngæ‰“åŒ…-scpåˆ°flume-agent-02-03-å’Œ-sht-sgmhadoopcm-01-172-16-101-54" class="headerlink" title="9.å°†flume-agent-01çš„flume-ngæ‰“åŒ…,scpåˆ°flume-agent-02/03 å’Œ sht-sgmhadoopcm-01(172.16.101.54)"></a>9.å°†flume-agent-01çš„flume-ngæ‰“åŒ…,scpåˆ°flume-agent-02/03 å’Œ sht-sgmhadoopcm-01(172.16.101.54)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hdfs@flume-agent-01 tmp]$ zip -r flume-ng.zip flume-ng/*</span><br><span class="line"></span><br><span class="line">[jpwu@flume-agent-01 ~]$ scp /tmp/flume-ng.zip flume-agent-02:/tmp/</span><br><span class="line">[jpwu@flume-agent-01 ~]$ scp /tmp/flume-ng.zip flume-agent-03:/tmp/</span><br><span class="line">[jpwu@flume-agent-01 ~]$ scp /tmp/flume-ng.zip sht-sgmhadoopcm-01:/tmp/</span><br></pre></td></tr></table></figure><h5 id="10-åœ¨flume-agent-02é…ç½®hdfsç”¨æˆ·ç¯å¢ƒå˜é‡å’Œè§£å‹ï¼Œä¿®æ”¹agenté…ç½®æ–‡ä»¶"><a href="#10-åœ¨flume-agent-02é…ç½®hdfsç”¨æˆ·ç¯å¢ƒå˜é‡å’Œè§£å‹ï¼Œä¿®æ”¹agenté…ç½®æ–‡ä»¶" class="headerlink" title="10.åœ¨flume-agent-02é…ç½®hdfsç”¨æˆ·ç¯å¢ƒå˜é‡å’Œè§£å‹ï¼Œä¿®æ”¹agenté…ç½®æ–‡ä»¶"></a>10.åœ¨flume-agent-02é…ç½®hdfsç”¨æˆ·ç¯å¢ƒå˜é‡å’Œè§£å‹ï¼Œä¿®æ”¹agenté…ç½®æ–‡ä»¶</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[hdfs@flume-agent-02 ~]$ cp /etc/skel/.* ./</span><br><span class="line">cp: omitting directory `/etc/skel/.&apos;</span><br><span class="line">cp: omitting directory `/etc/skel/..&apos;</span><br><span class="line">[hdfs@flume-agent-02 ~]$ vi .bash_profile</span><br><span class="line">export FLUME_HOME=/tmp/flume-ng</span><br><span class="line">export FLUME_CONF_DIR=$FLUME_HOME/conf</span><br><span class="line">export PATH=$PATH:$FLUME_HOME/bin</span><br><span class="line">[hdfs@flume-agent-02 ~]$ . .bash_profile</span><br><span class="line"></span><br><span class="line">[hdfs@flume-agent-02 tmp]$ unzip flume-ng.zip</span><br><span class="line">[hdfs@flume-agent-02 tmp]$ cd flume-ng/conf</span><br><span class="line"></span><br><span class="line">##ä¿®æ”¹ä»¥ä¸‹å‚æ•°å³å¯</span><br><span class="line">[hdfs@flume-agent-02 conf]$ vi exec_memory_avro.properties</span><br><span class="line">a1.sources.r1.command = tail -f /var/log/hadoop-hdfs/hadoop-cmf-hdfs1-DATANODE-flume-agent-02.log.out</span><br><span class="line">a1.sources.r1.hostname = flume-agent-02</span><br><span class="line">a1.sources.r1.servicename = datanode</span><br><span class="line"></span><br><span class="line">###è¦æ£€æŸ¥flume-env.shçš„JAVA_HOMEç›®å½•æ˜¯å¦å­˜åœ¨</span><br></pre></td></tr></table></figure><h5 id="11-åœ¨flume-agent-03é…ç½®hdfsç”¨æˆ·ç¯å¢ƒå˜é‡å’Œè§£å‹ï¼Œä¿®æ”¹agenté…ç½®æ–‡ä»¶"><a href="#11-åœ¨flume-agent-03é…ç½®hdfsç”¨æˆ·ç¯å¢ƒå˜é‡å’Œè§£å‹ï¼Œä¿®æ”¹agenté…ç½®æ–‡ä»¶" class="headerlink" title="11.åœ¨flume-agent-03é…ç½®hdfsç”¨æˆ·ç¯å¢ƒå˜é‡å’Œè§£å‹ï¼Œä¿®æ”¹agenté…ç½®æ–‡ä»¶"></a>11.åœ¨flume-agent-03é…ç½®hdfsç”¨æˆ·ç¯å¢ƒå˜é‡å’Œè§£å‹ï¼Œä¿®æ”¹agenté…ç½®æ–‡ä»¶</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[hdfs@flume-agent-03 ~]$ cp /etc/skel/.* ./</span><br><span class="line">cp: omitting directory `/etc/skel/.&apos;</span><br><span class="line">cp: omitting directory `/etc/skel/..&apos;</span><br><span class="line">[hdfs@flume-agent-03 ~]$ vi .bash_profile</span><br><span class="line">export FLUME_HOME=/tmp/flume-ng</span><br><span class="line">export FLUME_CONF_DIR=$FLUME_HOME/conf</span><br><span class="line">export PATH=$PATH:$FLUME_HOME/bin</span><br><span class="line">[hdfs@flume-agent-03 ~]$ . .bash_profile</span><br><span class="line"></span><br><span class="line">[hdfs@flume-agent-03 tmp]$ unzip flume-ng.zip</span><br><span class="line">[hdfs@flume-agent-03 tmp]$ cd flume-ng/conf</span><br><span class="line"></span><br><span class="line">##ä¿®æ”¹ä»¥ä¸‹å‚æ•°å³å¯</span><br><span class="line">[hdfs@flume-agent-03 conf]$ vi exec_memory_avro.properties</span><br><span class="line">a1.sources.r1.command = tail -f /var/log/hadoop-hdfs/hadoop-cmf-hdfs1-DATANODE-flume-agent-03.log.out</span><br><span class="line">a1.sources.r1.hostname = flume-agent-03</span><br><span class="line">a1.sources.r1.servicename = datanode</span><br><span class="line"></span><br><span class="line">###è¦æ£€æŸ¥flume-env.shçš„JAVA_HOMEç›®å½•æ˜¯å¦å­˜åœ¨</span><br></pre></td></tr></table></figure><h5 id="12-èšåˆç«¯-sht-sgmhadoopcm-01ï¼Œé…ç½®rootç”¨æˆ·ç¯å¢ƒå˜é‡å’Œè§£å‹ï¼Œä¿®æ”¹agenté…ç½®æ–‡ä»¶"><a href="#12-èšåˆç«¯-sht-sgmhadoopcm-01ï¼Œé…ç½®rootç”¨æˆ·ç¯å¢ƒå˜é‡å’Œè§£å‹ï¼Œä¿®æ”¹agenté…ç½®æ–‡ä»¶" class="headerlink" title="12.èšåˆç«¯ sht-sgmhadoopcm-01ï¼Œé…ç½®rootç”¨æˆ·ç¯å¢ƒå˜é‡å’Œè§£å‹ï¼Œä¿®æ”¹agenté…ç½®æ–‡ä»¶"></a>12.èšåˆç«¯ sht-sgmhadoopcm-01ï¼Œé…ç½®rootç”¨æˆ·ç¯å¢ƒå˜é‡å’Œè§£å‹ï¼Œä¿®æ”¹agenté…ç½®æ–‡ä»¶</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopcm-01 tmp]# vi /etc/profile</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.7.0_67-cloudera</span><br><span class="line">export FLUME_HOME=/tmp/flume-ng</span><br><span class="line">export FLUME_CONF_DIR=$FLUME_HOME/conf</span><br><span class="line"></span><br><span class="line">export PATH=$FLUME_HOME/bin:$JAVA_HOME/bin:$PATH</span><br><span class="line">[root@sht-sgmhadoopcm-01 tmp]# source /etc/profile</span><br><span class="line">[root@sht-sgmhadoopcm-01 tmp]#</span><br><span class="line"></span><br><span class="line">[root@sht-sgmhadoopcm-01 tmp]# unzip flume-ng.zip</span><br><span class="line">[root@sht-sgmhadoopcm-01 tmp]# cd flume-ng/conf</span><br><span class="line"></span><br><span class="line">[root@sht-sgmhadoopcm-01 conf]# vi flume-env.sh</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.7.0_67-cloudera</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">###æµ‹è¯•: å…ˆèšåˆ, sinkåˆ°hdfsç«¯</span><br><span class="line">[root@sht-sgmhadoopcm-01 conf]# vi avro_memory_hdfs.properties</span><br><span class="line">#Name the components on this agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line">#Describe/configure the source</span><br><span class="line">a1.sources.r1.type = avro</span><br><span class="line">a1.sources.r1.bind = 172.16.101.54</span><br><span class="line">a1.sources.r1.port = 4545</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Describe the sink</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path = hdfs://172.16.101.56:8020/testwjp/</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = logs</span><br><span class="line">a1.sinks.k1.hdfs.inUsePrefix = .</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.hdfs.rollInterval = 0</span><br><span class="line">###roll 16 m = 16777216 bytes</span><br><span class="line">a1.sinks.k1.hdfs.rollSize = 1048576</span><br><span class="line">a1.sinks.k1.hdfs.rollCount = 0</span><br><span class="line">a1.sinks.k1.hdfs.batchSize = 6000</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.hdfs.writeFormat = text</span><br><span class="line">a1.sinks.k1.hdfs.fileType = DataStream</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.keep-alive = 90 </span><br><span class="line">a1.channels.c1.capacity = 1000000</span><br><span class="line">a1.channels.c1.transactionCapacity = 6000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure><h5 id="13-åå°å¯åŠ¨"><a href="#13-åå°å¯åŠ¨" class="headerlink" title="13.åå°å¯åŠ¨"></a>13.åå°å¯åŠ¨</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopcm-01 flume-ng]# source /etc/profile</span><br><span class="line">[hdfs@flume-agent-01 flume-ng]$ . ~/.bash_profile </span><br><span class="line">[hdfs@flume-agent-02 flume-ng]$ . ~/.bash_profile </span><br><span class="line">[hdfs@flume-agent-03 flume-ng]$ . ~/.bash_profile</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@sht-sgmhadoopnn-01 flume-ng]# nohup  flume-ng agent -c conf -f /tmp/flume-ng/conf/avro_memory_hdfs.properties -n a1 -Dflume.root.logger=INFO,console &amp;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[hdfs@flume-agent-01 flume-ng]$ nohup  flume-ng agent -c /tmp/flume-ng/conf -f /tmp/flume-ng/conf/exec_memory_avro.properties -n a1 -Dflume.root.logger=INFO,console &amp;</span><br><span class="line">[hdfs@flume-agent-01 flume-ng]$ nohup  flume-ng agent -c /tmp/flume-ng/conf -f /tmp/flume-ng/conf/exec_memory_avro.properties -n a1 -Dflume.root.logger=INFO,console &amp;</span><br><span class="line">[hdfs@flume-agent-01 flume-ng]$ nohup  flume-ng agent -c /tmp/flume-ng/conf -f /tmp/flume-ng/conf/exec_memory_avro.properties -n a1 -Dflume.root.logger=INFO,console &amp;</span><br></pre></td></tr></table></figure><h5 id="14-æ ¡éªŒï¼šå°†é›†ç¾¤çš„æ—¥å¿—ä¸‹è½½åˆ°æœ¬åœ°ï¼Œæ‰“å¼€æŸ¥çœ‹å³å¯-ç•¥"><a href="#14-æ ¡éªŒï¼šå°†é›†ç¾¤çš„æ—¥å¿—ä¸‹è½½åˆ°æœ¬åœ°ï¼Œæ‰“å¼€æŸ¥çœ‹å³å¯-ç•¥" class="headerlink" title="14.æ ¡éªŒï¼šå°†é›†ç¾¤çš„æ—¥å¿—ä¸‹è½½åˆ°æœ¬åœ°ï¼Œæ‰“å¼€æŸ¥çœ‹å³å¯(ç•¥)"></a>14.æ ¡éªŒï¼šå°†é›†ç¾¤çš„æ—¥å¿—ä¸‹è½½åˆ°æœ¬åœ°ï¼Œæ‰“å¼€æŸ¥çœ‹å³å¯(ç•¥)</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ã€å¤‡æ³¨ã€‘: </span><br><span class="line">1.é”™è¯¯1 flume-ngå®‰è£…çš„æœºå™¨ä¸Šæ²¡æœ‰hadoopç¯å¢ƒï¼Œæ‰€ä»¥å‡å¦‚sinkåˆ°hdfsè¯ï¼Œéœ€è¦ç”¨åˆ°hdfsçš„jaråŒ…</span><br><span class="line">[ERROR - org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run(PollingPropertiesFileConfigurationProvider.java:146)] Failed to start agent </span><br><span class="line">because dependencies were not found in classpath. Error follows.</span><br><span class="line">java.lang.NoClassDefFoundError: org/apache/hadoop/io/SequenceFile$CompressionType</span><br><span class="line"></span><br><span class="line">åªéœ€åœ¨å…¶ä»–å®‰è£…hadoopæœºå™¨ä¸Šæœç´¢ä»¥ä¸‹5ä¸ªjaråŒ…ï¼Œæ‹·è´åˆ°$FLUME_HOME/libç›®å½•å³å¯ã€‚</span><br><span class="line">æœç´¢æ–¹æ³•: find $HADOOP_HOME/ -name commons-configuration*.jar</span><br><span class="line"></span><br><span class="line">commons-configuration-1.6.jar</span><br><span class="line">hadoop-auth-2.7.3.jar</span><br><span class="line">hadoop-common-2.7.3.jar</span><br><span class="line">hadoop-hdfs-2.7.3.jar</span><br><span class="line">hadoop-mapreduce-client-core-2.7.3.jar</span><br><span class="line">protobuf-java-2.5.0.jar</span><br><span class="line">htrace-core-3.1.0-incubating.jar</span><br><span class="line">commons-io-2.4.jar</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2.é”™è¯¯2 æ— æ³•åŠ è½½è‡ªå®šä¹‰æ’ä»¶çš„ç±» Unable to load source type: com.onlinelog.analysis.AdvancedExecSource</span><br><span class="line">2017-01-06 21:10:48,278 (conf-file-poller-0) [ERROR - org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run(PollingPropertiesFileConfigurationProvider.java:142)] Failed to load configuration data. Exception follows.</span><br><span class="line">org.apache.flume.FlumeException: Unable to load source type: com.onlinelog.analysis.AdvancedExecSource, class: com.onlinelog.analysis.AdvancedExecSource</span><br><span class="line"></span><br><span class="line">æ‰§è¡Œhdfsæˆ–è€…rootç”¨æˆ·çš„ç¯å¢ƒå˜é‡å³å¯</span><br><span class="line">[root@sht-sgmhadoopcm-01 flume-ng]# source /etc/profile</span><br><span class="line">[hdfs@flume-agent-01 flume-ng]$ . ~/.bash_profile </span><br><span class="line">[hdfs@flume-agent-02 flume-ng]$ . ~/.bash_profile </span><br><span class="line">[hdfs@flume-agent-03 flume-ng]$ . ~/.bash_profile</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue May 28 2019 21:30:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;ã€logæ”¶é›†ã€‘:&lt;br&gt;æœºå™¨åç§° æœåŠ¡åç§° ç”¨æˆ·&lt;br&gt;flume-agent-01: namenode hdfs&lt;br&gt;flume-agent-02: datanode hdfs&lt;br&gt;flume-agent-03: datanode hdfs&lt;/p&gt;&lt;p&gt;ã€logèšåˆã€‘:&lt;br&gt;æœºå™¨åç§° ç”¨æˆ·&lt;br&gt;sht-sgmhadoopcm-01(172.16.101.54) root&lt;/p&gt;&lt;p&gt;ã€sinkåˆ°hdfsã€‘:&lt;br&gt;hdfs://172.16.101.56:8020/testwjp/&lt;/p&gt;
    
    </summary>
    
      <category term="ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®" scheme="http://yoursite.com/categories/%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®" scheme="http://yoursite.com/tags/%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE/"/>
    
  </entry>
  
  <entry>
    <title>03ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®ä¹‹hadoop-2.7.3ç¼–è¯‘å’Œæ­å»ºé›†ç¾¤ç¯å¢ƒ(HDFS HA,Yarn HA)</title>
    <link href="http://yoursite.com/2018/09/03/03%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE%E4%B9%8Bhadoop-2.7.3%E7%BC%96%E8%AF%91%E5%92%8C%E6%90%AD%E5%BB%BA%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83(HDFS%20HA,Yarn%20HA)/"/>
    <id>http://yoursite.com/2018/09/03/03ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®ä¹‹hadoop-2.7.3ç¼–è¯‘å’Œæ­å»ºé›†ç¾¤ç¯å¢ƒ(HDFS HA,Yarn HA)/</id>
    <published>2018-09-02T16:00:00.000Z</published>
    <updated>2019-05-26T13:15:20.076Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun May 26 2019 21:16:06 GMT+0800 (GMT+08:00) --><a id="more"></a><h3 id="1-ä¸‹è½½hadoop2-7-3æœ€æ–°æºç "><a href="#1-ä¸‹è½½hadoop2-7-3æœ€æ–°æºç " class="headerlink" title="1.ä¸‹è½½hadoop2.7.3æœ€æ–°æºç "></a>1.ä¸‹è½½hadoop2.7.3æœ€æ–°æºç </h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopnn-01 ~]# mkdir -p learnproject/compilesoft</span><br><span class="line">[root@sht-sgmhadoopnn-01 ~]# cd learnproject/compilesoft</span><br><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]# wget http://www-eu.apache.org/dist/hadoop/common/hadoop-2.7.3/hadoop-2.7.3-src.tar.gz</span><br><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]# tar -xzvf hadoop-2.7.3-src.tar.gz</span><br><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]# cd hadoop-2.7.3-src</span><br><span class="line">[root@sht-sgmhadoopnn-01 hadoop-2.7.3-src]# cat BUILDING.txt </span><br><span class="line">Build instructions for Hadoop</span><br><span class="line">----------------------------------------------------------------------------------</span><br><span class="line">Requirements:</span><br><span class="line">* Unix System</span><br><span class="line">* JDK 1.7+</span><br><span class="line">* Maven 3.0 or later</span><br><span class="line">* Findbugs 1.3.9 (if running findbugs)</span><br><span class="line">* ProtocolBuffer 2.5.0</span><br><span class="line">* CMake 2.6 or newer (if compiling native code), must be 3.0 or newer on Mac</span><br><span class="line">* Zlib devel (if compiling native code)</span><br><span class="line">* openssl devel ( if compiling native hadoop-pipes and to get the best HDFS encryption performance )</span><br><span class="line">* Linux FUSE (Filesystem in Userspace) version 2.6 or above ( if compiling fuse_dfs )</span><br><span class="line">* Internet connection for first build (to fetch all Maven and Hadoop dependencies)</span><br><span class="line">----------------------------------------------------------------------------------</span><br><span class="line">Installing required packages for clean install of Ubuntu 14.04 LTS Desktop:</span><br><span class="line">* Oracle JDK 1.7 (preferred)</span><br><span class="line">  $ sudo apt-get purge openjdk*</span><br><span class="line">  $ sudo apt-get install software-properties-common</span><br><span class="line">  $ sudo add-apt-repository ppa:webupd8team/java</span><br><span class="line">  $ sudo apt-get update</span><br><span class="line">  $ sudo apt-get install oracle-java7-installer</span><br><span class="line">* Maven</span><br><span class="line">  $ sudo apt-get -y install maven</span><br><span class="line">* Native libraries</span><br><span class="line">  $ sudo apt-get -y install build-essential autoconf automake libtool cmake zlib1g-dev pkg-config libssl-dev</span><br><span class="line">* ProtocolBuffer 2.5.0 (required)</span><br><span class="line">  $ sudo apt-get -y install libprotobuf-dev protobuf-compiler</span><br><span class="line">Optional packages:</span><br><span class="line">* Snappy compression</span><br><span class="line">  $ sudo apt-get install snappy libsnappy-dev</span><br><span class="line">* Bzip2</span><br><span class="line">  $ sudo apt-get install bzip2 libbz2-dev</span><br><span class="line">* Jansson (C Library for JSON)</span><br><span class="line">  $ sudo apt-get install libjansson-dev</span><br><span class="line">* Linux FUSE</span><br><span class="line">  $ sudo apt-get install fuse libfuse-dev</span><br></pre></td></tr></table></figure><h3 id="2-å®‰è£…ä¾èµ–åŒ…"><a href="#2-å®‰è£…ä¾èµ–åŒ…" class="headerlink" title="2.å®‰è£…ä¾èµ–åŒ…"></a>2.å®‰è£…ä¾èµ–åŒ…</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]# yum install svn autoconf automake libtool cmake ncurses-devel openssl-devel gcc*</span><br></pre></td></tr></table></figure><h3 id="3-å®‰è£…jdk"><a href="#3-å®‰è£…jdk" class="headerlink" title="3.å®‰è£…jdk"></a>3.å®‰è£…jdk</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]# vi /etc/profile</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.7.0_67-cloudera</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]# source /etc/profile</span><br><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]# java -version</span><br><span class="line">java version &quot;1.7.0_67&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.7.0_67-b01)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 24.65-b04, mixed mode)</span><br><span class="line">You have mail in /var/spool/mail/root</span><br><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]#</span><br></pre></td></tr></table></figure><h3 id="4-å®‰è£…maven"><a href="#4-å®‰è£…maven" class="headerlink" title="4.å®‰è£…maven"></a>4.å®‰è£…maven</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopnn-01compilesoft]# wget http://ftp.cuhk.edu.hk/pub/packages/apache.org/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz -O apache-maven-3.3.9-bin.tar.gz</span><br><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]# tar xvf apache-maven-3.3.9-bin.tar.gz</span><br><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]# vi /etc/profile</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.7.0_67-cloudera</span><br><span class="line">export MAVEN_HOME=/root/learnproject/compilesoft/apache-maven-3.3.9</span><br><span class="line">#åœ¨ç¼–è¯‘è¿‡ç¨‹ä¸­ä¸ºäº†é˜²æ­¢Javaå†…å­˜æº¢å‡ºï¼Œéœ€è¦åŠ å…¥ä»¥ä¸‹ç¯å¢ƒå˜é‡</span><br><span class="line">export MAVEN_OPTS=&quot;-Xmx2048m -XX:MaxPermSize=512m&quot;</span><br><span class="line">export PATH=$MAVEN_HOME/bin:$JAVA_HOME/bin:$PATH</span><br><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]# source /etc/profile</span><br><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]# mvn -version</span><br><span class="line">Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-11T00:41:47+08:00)</span><br><span class="line">Maven home: /root/learnproject/compilesoft/apache-maven-3.3.9</span><br><span class="line">Java version: 1.7.0_67, vendor: Oracle Corporation</span><br><span class="line">Java home: /usr/java/jdk1.7.0_67-cloudera/jre</span><br><span class="line">Default locale: en_US, platform encoding: UTF-8</span><br><span class="line">OS name: &quot;linux&quot;, version: &quot;2.6.32-431.el6.x86_64&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot;</span><br><span class="line">You have new mail in /var/spool/mail/root</span><br><span class="line">[root@sht-sgmhadoopnn-01 apache-maven-3.3.9]#</span><br></pre></td></tr></table></figure><h3 id="5-ç¼–è¯‘å®‰è£…protobuf"><a href="#5-ç¼–è¯‘å®‰è£…protobuf" class="headerlink" title="5.ç¼–è¯‘å®‰è£…protobuf"></a>5.ç¼–è¯‘å®‰è£…protobuf</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopnn-01compilesoft]# wget ftp://ftp.netbsd.org/pub/pkgsrc/distfiles/protobuf-2.5.0.tar.gz -O protobuf-2.5.0.tar.gz</span><br><span class="line">[root@hadoop-01 compilesoft]# tar -zxvf protobuf-2.5.0.tar.gz</span><br><span class="line">[root@hadoop-01 compilesoft]# cd protobuf-2.5.0/</span><br><span class="line">[root@hadoop-01 protobuf-2.5.0]# ./configure </span><br><span class="line">[root@hadoop-01 protobuf-2.5.0]# make</span><br><span class="line">[root@hadoop-01 protobuf-2.5.0]# make install</span><br><span class="line">#æŸ¥çœ‹protobufç‰ˆæœ¬ä»¥æµ‹è¯•æ˜¯å¦å®‰è£…æˆåŠŸ</span><br><span class="line">[root@hadoop-01 protobuf-2.5.0]# protoc --version</span><br><span class="line">protoc: error while loading shared libraries: libprotobuf.so.8: cannot open shared object file: No such file or directory</span><br><span class="line">[root@hadoop-01 protobuf-2.5.0]# export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib</span><br><span class="line">[root@hadoop-01 protobuf-2.5.0]# protoc --version</span><br><span class="line">libprotoc 2.5.0</span><br><span class="line">[root@hadoop-01 protobuf-2.5.0]#</span><br></pre></td></tr></table></figure><h3 id="6-å®‰è£…snappy"><a href="#6-å®‰è£…snappy" class="headerlink" title="6.å®‰è£…snappy"></a>6.å®‰è£…snappy</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]# wget http://pkgs.fedoraproject.org/repo/pkgs/snappy/snappy-1.1.1.tar.gz/8887e3b7253b22a31f5486bca3cbc1c2/snappy-1.1.1.tar.gz</span><br><span class="line">#ç”¨rootç”¨æˆ·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤</span><br><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]#tar -zxvf snappy-1.1.1.tar.gz</span><br><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]# cd snappy-1.1.1/</span><br><span class="line">[root@sht-sgmhadoopnn-01 snappy-1.1.1]# ./configure</span><br><span class="line">[root@sht-sgmhadoopnn-01 snappy-1.1.1]# make</span><br><span class="line">[root@sht-sgmhadoopnn-01 snappy-1.1.1]# make install</span><br><span class="line">#æŸ¥çœ‹snappyåº“æ–‡ä»¶</span><br><span class="line">[root@sht-sgmhadoopnn-01 snappy-1.1.1]# ls -lh /usr/local/lib |grep snappy</span><br><span class="line">-rw-r--r--  1 root root 229K Jun 21 15:46 libsnappy.a</span><br><span class="line">-rwxr-xr-x  1 root root  953 Jun 21 15:46 libsnappy.la</span><br><span class="line">lrwxrwxrwx  1 root root   18 Jun 21 15:46 libsnappy.so -&gt; libsnappy.so.1.2.0</span><br><span class="line">lrwxrwxrwx  1 root root   18 Jun 21 15:46 libsnappy.so.1 -&gt; libsnappy.so.1.2.0</span><br><span class="line">-rwxr-xr-x  1 root root 145K Jun 21 15:46 libsnappy.so.1.2.0</span><br><span class="line">[root@sht-sgmhadoopnn-01 snappy-1.1.1]#</span><br></pre></td></tr></table></figure><h3 id="7-ç¼–è¯‘"><a href="#7-ç¼–è¯‘" class="headerlink" title="7.ç¼–è¯‘"></a>7.ç¼–è¯‘</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopnn-01 compilesoft]# cd hadoop-2.7.3-src</span><br><span class="line">mvn clean package -Pdist,native -DskipTests -Dtar</span><br><span class="line">æˆ–</span><br><span class="line">mvn package -Pdist,native -DskipTests -Dtar</span><br><span class="line">[root@sht-sgmhadoopnn-01 hadoop-2.7.3-src]# mvn clean package â€“Pdist,native â€“DskipTests â€“Dtar</span><br><span class="line">[INFO] Executing tasks</span><br><span class="line">main:</span><br><span class="line">     [exec] $ tar cf hadoop-2.7.3.tar hadoop-2.7.3</span><br><span class="line">     [exec] $ gzip -f hadoop-2.7.3.tar</span><br><span class="line">     [exec] </span><br><span class="line">     [exec] Hadoop dist tar available at: /root/learnproject/compilesoft/hadoop-2.7.3-src/hadoop-dist/target/hadoop-2.7.3.tar.gz</span><br><span class="line">     [exec] </span><br><span class="line">[INFO] Executed tasks</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-javadoc-plugin:2.8.1:jar (module-javadocs) @ hadoop-dist ---</span><br><span class="line">[INFO] Building jar: /root/learnproject/compilesoft/hadoop-2.7.3-src/hadoop-dist/target/hadoop-dist-2.7.3-javadoc.jar</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Reactor Summary:</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] Apache Hadoop Main ................................. SUCCESS [ 14.707 s]</span><br><span class="line">[INFO] Apache Hadoop Build Tools .......................... SUCCESS [  6.832 s]</span><br><span class="line">[INFO] Apache Hadoop Project POM .......................... SUCCESS [ 12.989 s]</span><br><span class="line">[INFO] Apache Hadoop Annotations .......................... SUCCESS [ 14.258 s]</span><br><span class="line">[INFO] Apache Hadoop Assemblies ........................... SUCCESS [  0.411 s]</span><br><span class="line">[INFO] Apache Hadoop Project Dist POM ..................... SUCCESS [  4.814 s]</span><br><span class="line">[INFO] Apache Hadoop Maven Plugins ........................ SUCCESS [ 23.566 s]</span><br><span class="line">[INFO] Apache Hadoop MiniKDC .............................. SUCCESS [02:31 min]</span><br><span class="line">[INFO] Apache Hadoop Auth ................................. SUCCESS [ 29.587 s]</span><br><span class="line">[INFO] Apache Hadoop Auth Examples ........................ SUCCESS [ 13.954 s]</span><br><span class="line">[INFO] Apache Hadoop Common ............................... SUCCESS [03:03 min]</span><br><span class="line">[INFO] Apache Hadoop NFS .................................. SUCCESS [  9.285 s]</span><br><span class="line">[INFO] Apache Hadoop KMS .................................. SUCCESS [ 45.068 s]</span><br><span class="line">[INFO] Apache Hadoop Common Project ....................... SUCCESS [  0.049 s]</span><br><span class="line">[INFO] Apache Hadoop HDFS ................................. SUCCESS [03:49 min]</span><br><span class="line">[INFO] Apache Hadoop HttpFS ............................... SUCCESS [01:08 min]</span><br><span class="line">[INFO] Apache Hadoop HDFS BookKeeper Journal .............. SUCCESS [ 28.935 s]</span><br><span class="line">[INFO] Apache Hadoop HDFS-NFS ............................. SUCCESS [  4.599 s]</span><br><span class="line">[INFO] Apache Hadoop HDFS Project ......................... SUCCESS [  0.044 s]</span><br><span class="line">[INFO] hadoop-yarn ........................................ SUCCESS [  0.043 s]</span><br><span class="line">[INFO] hadoop-yarn-api .................................... SUCCESS [02:49 min]</span><br><span class="line">[INFO] hadoop-yarn-common ................................. SUCCESS [ 40.792 s]</span><br><span class="line">[INFO] hadoop-yarn-server ................................. SUCCESS [  0.041 s]</span><br><span class="line">[INFO] hadoop-yarn-server-common .......................... SUCCESS [ 15.750 s]</span><br><span class="line">[INFO] hadoop-yarn-server-nodemanager ..................... SUCCESS [ 25.311 s]</span><br><span class="line">[INFO] hadoop-yarn-server-web-proxy ....................... SUCCESS [  6.415 s]</span><br><span class="line">[INFO] hadoop-yarn-server-applicationhistoryservice ....... SUCCESS [ 12.274 s]</span><br><span class="line">[INFO] hadoop-yarn-server-resourcemanager ................. SUCCESS [ 27.555 s]</span><br><span class="line">[INFO] hadoop-yarn-server-tests ........................... SUCCESS [  7.751 s]</span><br><span class="line">[INFO] hadoop-yarn-client ................................. SUCCESS [ 11.347 s]</span><br><span class="line">[INFO] hadoop-yarn-server-sharedcachemanager .............. SUCCESS [  5.612 s]</span><br><span class="line">[INFO] hadoop-yarn-applications ........................... SUCCESS [  0.038 s]</span><br><span class="line">[INFO] hadoop-yarn-applications-distributedshell .......... SUCCESS [  4.029 s]</span><br><span class="line">[INFO] hadoop-yarn-applications-unmanaged-am-launcher ..... SUCCESS [  2.611 s]</span><br><span class="line">[INFO] hadoop-yarn-site ................................... SUCCESS [  0.077 s]</span><br><span class="line">[INFO] hadoop-yarn-registry ............................... SUCCESS [  8.045 s]</span><br><span class="line">[INFO] hadoop-yarn-project ................................ SUCCESS [  5.456 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client ............................ SUCCESS [  0.226 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client-core ....................... SUCCESS [ 28.462 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client-common ..................... SUCCESS [ 25.872 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client-shuffle .................... SUCCESS [  6.697 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client-app ........................ SUCCESS [ 14.121 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client-hs ......................... SUCCESS [  9.328 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client-jobclient .................. SUCCESS [ 23.801 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client-hs-plugins ................. SUCCESS [  2.412 s]</span><br><span class="line">[INFO] Apache Hadoop MapReduce Examples ................... SUCCESS [  8.876 s]</span><br><span class="line">[INFO] hadoop-mapreduce ................................... SUCCESS [  4.237 s]</span><br><span class="line">[INFO] Apache Hadoop MapReduce Streaming .................. SUCCESS [ 14.285 s]</span><br><span class="line">[INFO] Apache Hadoop Distributed Copy ..................... SUCCESS [ 19.759 s]</span><br><span class="line">[INFO] Apache Hadoop Archives ............................. SUCCESS [  3.069 s]</span><br><span class="line">[INFO] Apache Hadoop Rumen ................................ SUCCESS [  7.446 s]</span><br><span class="line">[INFO] Apache Hadoop Gridmix .............................. SUCCESS [  5.765 s]</span><br><span class="line">[INFO] Apache Hadoop Data Join ............................ SUCCESS [  3.752 s]</span><br><span class="line">[INFO] Apache Hadoop Ant Tasks ............................ SUCCESS [  2.771 s]</span><br><span class="line">[INFO] Apache Hadoop Extras ............................... SUCCESS [  5.612 s]</span><br><span class="line">[INFO] Apache Hadoop Pipes ................................ SUCCESS [ 10.332 s]</span><br><span class="line">[INFO] Apache Hadoop OpenStack support .................... SUCCESS [  7.131 s]</span><br><span class="line">[INFO] Apache Hadoop Amazon Web Services support .......... SUCCESS [01:32 min]</span><br><span class="line">[INFO] Apache Hadoop Azure support ........................ SUCCESS [ 10.622 s]</span><br><span class="line">[INFO] Apache Hadoop Client ............................... SUCCESS [ 12.540 s]</span><br><span class="line">[INFO] Apache Hadoop Mini-Cluster ......................... SUCCESS [  1.142 s]</span><br><span class="line">[INFO] Apache Hadoop Scheduler Load Simulator ............. SUCCESS [  7.354 s]</span><br><span class="line">[INFO] Apache Hadoop Tools Dist ........................... SUCCESS [ 12.269 s]</span><br><span class="line">[INFO] Apache Hadoop Tools ................................ SUCCESS [  0.035 s]</span><br><span class="line">[INFO] Apache Hadoop Distribution ......................... SUCCESS [ 58.051 s]</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 26:29 min</span><br><span class="line">[INFO] Finished at: 2016-12-24T21:07:09+08:00</span><br><span class="line">[INFO] Final Memory: 214M/740M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">You have mail in /var/spool/mail/root</span><br><span class="line">[root@sht-sgmhadoopnn-01 hadoop-2.7.3-src]# </span><br><span class="line">[root@sht-sgmhadoopnn-01 hadoop-2.7.3-src]# cp /root/learnproject/compilesoft/hadoop-2.7.3-src/hadoop-dist/target/hadoop-2.7.3.tar.gz ../../</span><br><span class="line">You have mail in /var/spool/mail/root</span><br><span class="line">[root@sht-sgmhadoopnn-01 hadoop-2.7.3-src]# cd ../../</span><br><span class="line">[root@sht-sgmhadoopnn-01 learnproject]# ll</span><br><span class="line">total 193152</span><br><span class="line">drwxr-xr-x 5 root root      4096 Dec 24 20:24 compilesoft</span><br><span class="line">-rw-r--r-- 1 root root 197782815 Dec 24 21:16 hadoop-2.7.3.tar.gz</span><br><span class="line">[root@sht-sgmhadoopnn-01 learnproject]#</span><br></pre></td></tr></table></figure><h3 id="8-æ­å»ºHDFS-HA-YARN-HAé›†ç¾¤ï¼ˆ5ä¸ªèŠ‚ç‚¹ï¼‰"><a href="#8-æ­å»ºHDFS-HA-YARN-HAé›†ç¾¤ï¼ˆ5ä¸ªèŠ‚ç‚¹ï¼‰" class="headerlink" title="8.æ­å»ºHDFS HA,YARN HAé›†ç¾¤ï¼ˆ5ä¸ªèŠ‚ç‚¹ï¼‰"></a>8.æ­å»ºHDFS HA,YARN HAé›†ç¾¤ï¼ˆ5ä¸ªèŠ‚ç‚¹ï¼‰</h3><p>å‚è€ƒ:<br><a href="http://blog.itpub.net/30089851/viewspace-1994585/" target="_blank" rel="noopener">http://blog.itpub.net/30089851/viewspace-1994585/</a><br><a href="https://github.com/Hackeruncle/Hadoop" target="_blank" rel="noopener">https://github.com/Hackeruncle/Hadoop</a></p><h3 id="9-æ­å»ºé›†ç¾¤-éªŒè¯ç‰ˆæœ¬å’Œæ”¯æŒçš„å‹ç¼©ä¿¡æ¯"><a href="#9-æ­å»ºé›†ç¾¤-éªŒè¯ç‰ˆæœ¬å’Œæ”¯æŒçš„å‹ç¼©ä¿¡æ¯" class="headerlink" title="9.æ­å»ºé›†ç¾¤,éªŒè¯ç‰ˆæœ¬å’Œæ”¯æŒçš„å‹ç¼©ä¿¡æ¯"></a>9.æ­å»ºé›†ç¾¤,éªŒè¯ç‰ˆæœ¬å’Œæ”¯æŒçš„å‹ç¼©ä¿¡æ¯</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@sht-sgmhadoopnn-01 app]# hadoop version</span><br><span class="line">Hadoop 2.7.3</span><br><span class="line">Subversion Unknown -r Unknown</span><br><span class="line">Compiled by root on 2016-12-24T12:45Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From source with checksum 2e4ce5f957ea4db193bce3734ff29ff4</span><br><span class="line">This command was run using /root/learnproject/app/hadoop/share/hadoop/common/hadoop-common-2.7.3.jar</span><br><span class="line">[root@sht-sgmhadoopnn-01 app]# hadoop checknative</span><br><span class="line">16/12/25 15:55:43 INFO bzip2.Bzip2Factory: Successfully loaded &amp; initialized native-bzip2 library system-native</span><br><span class="line">16/12/25 15:55:43 INFO zlib.ZlibFactory: Successfully loaded &amp; initialized native-zlib library</span><br><span class="line">Native library checking:</span><br><span class="line">hadoop:  true /root/learnproject/app/hadoop/lib/native/libhadoop.so.1.0.0</span><br><span class="line">zlib:    true /lib64/libz.so.1</span><br><span class="line">snappy:  true /usr/local/lib/libsnappy.so.1</span><br><span class="line">lz4:     true revision:99</span><br><span class="line">bzip2:   true /lib64/libbz2.so.1</span><br><span class="line">openssl: true /usr/lib64/libcrypto.so</span><br><span class="line">[root@sht-sgmhadoopnn-01 app]# file /root/learnproject/app/hadoop/lib/native/libhadoop.so.1.0.0</span><br><span class="line">/root/learnproject/app/hadoop/lib/native/libhadoop.so.1.0.0: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, not stripped</span><br><span class="line">[root@sht-sgmhadoopnn-01 app]#</span><br></pre></td></tr></table></figure><p>[å‚è€ƒ]</p><ul><li><a href="http://happyshome.cn/blog/deploy/centos/hadoop2.7.2.html" target="_blank" rel="noopener">http://happyshome.cn/blog/deploy/centos/hadoop2.7.2.html</a></li><li><a href="http://blog.csdn.net/haohaixingyun/article/details/52800048" target="_blank" rel="noopener">http://blog.csdn.net/haohaixingyun/article/details/52800048</a></li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Sun May 26 2019 21:16:06 GMT+0800 (GMT+08:00) --&gt;
    
    </summary>
    
      <category term="ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®" scheme="http://yoursite.com/categories/%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®" scheme="http://yoursite.com/tags/%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE/"/>
    
  </entry>
  
  <entry>
    <title>02ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®ä¹‹Flume-1.7.0æºç ç¼–è¯‘å¯¼å…¥eclipse</title>
    <link href="http://yoursite.com/2018/08/28/02%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE%E4%B9%8BFlume-1.7.0%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AF%BC%E5%85%A5eclipse/"/>
    <id>http://yoursite.com/2018/08/28/02ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®ä¹‹Flume-1.7.0æºç ç¼–è¯‘å¯¼å…¥eclipse/</id>
    <published>2018-08-27T16:00:00.000Z</published>
    <updated>2019-05-25T13:04:01.670Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat May 25 2019 21:07:00 GMT+0800 (GMT+08:00) --><a id="more"></a><h3 id="ã€å‰æã€‘"><a href="#ã€å‰æã€‘" class="headerlink" title="ã€å‰æã€‘:"></a>ã€å‰æã€‘:</h3><p>1.windows 7 å®‰è£…maven-3.3.9<br>å…¶ä¸­åœ¨conf/setting.xmlæ–‡ä»¶æ·»åŠ <br>D:\software\apache-maven-3.3.9\repository<br><a href="http://blog.csdn.net/defonds/article/details/41957287" target="_blank" rel="noopener">http://blog.csdn.net/defonds/article/details/41957287</a><br>2.windows 7 å®‰è£…eclipse 64ä½(ç™¾åº¦ä¸‹è½½ï¼Œè§£å‹å³å¯)<br>3.eclipseå®‰è£…mavenæ’ä»¶ï¼Œé€‰æ‹©ç¬¬äºŒç§æ–¹å¼link<br><a href="http://blog.csdn.net/lfsfxy9/article/details/9397937" target="_blank" rel="noopener">http://blog.csdn.net/lfsfxy9/article/details/9397937</a><br>å…¶ä¸­ eclipse-maven3-plugin.7z è¿™ä¸ªåŒ…å¯ä»¥åŠ ç¾¤258669058æ‰¾æˆ‘ï¼Œåˆ†äº«ç»™ä½ </p><h3 id="ã€flume-ng-1-7-0æºç çš„ç¼–è¯‘å¯¼å…¥eclipseã€‘"><a href="#ã€flume-ng-1-7-0æºç çš„ç¼–è¯‘å¯¼å…¥eclipseã€‘" class="headerlink" title="ã€flume-ng 1.7.0æºç çš„ç¼–è¯‘å¯¼å…¥eclipseã€‘:"></a>ã€flume-ng 1.7.0æºç çš„ç¼–è¯‘å¯¼å…¥eclipseã€‘:</h3><h4 id="1-ä¸‹è½½å®˜ç½‘çš„æºç -ä¸è¦ä¸‹è½½GitHubä¸Šæºç ï¼Œå› ä¸ºè¿™æ—¶pomæ–‡ä»¶ä¸­ç‰ˆæœ¬ä¸º1-8-0ï¼Œç¼–è¯‘ä¼šæœ‰é—®é¢˜"><a href="#1-ä¸‹è½½å®˜ç½‘çš„æºç -ä¸è¦ä¸‹è½½GitHubä¸Šæºç ï¼Œå› ä¸ºè¿™æ—¶pomæ–‡ä»¶ä¸­ç‰ˆæœ¬ä¸º1-8-0ï¼Œç¼–è¯‘ä¼šæœ‰é—®é¢˜" class="headerlink" title="1.ä¸‹è½½å®˜ç½‘çš„æºç (ä¸è¦ä¸‹è½½GitHubä¸Šæºç ï¼Œå› ä¸ºè¿™æ—¶pomæ–‡ä»¶ä¸­ç‰ˆæœ¬ä¸º1.8.0ï¼Œç¼–è¯‘ä¼šæœ‰é—®é¢˜)"></a>1.ä¸‹è½½å®˜ç½‘çš„æºç (ä¸è¦ä¸‹è½½GitHubä¸Šæºç ï¼Œå› ä¸ºè¿™æ—¶pomæ–‡ä»¶ä¸­ç‰ˆæœ¬ä¸º1.8.0ï¼Œç¼–è¯‘ä¼šæœ‰é—®é¢˜)</h4><p><a href="http://archive.apache.org/dist/flume/1.7.0/" target="_blank" rel="noopener">http://archive.apache.org/dist/flume/1.7.0/</a><br>a.ä¸‹è½½apache-flume-1.7.0-src.tar.gz<br>b.è§£å‹é‡å‘½åä¸ºflume-1.7.0</p><h4 id="2-ä¿®æ”¹pom-xml-å¤§æ¦‚åœ¨621è¡Œï¼Œå°†è‡ªå¸¦çš„repositoryæ³¨é‡Šæ‰ï¼Œæ·»åŠ ä»¥ä¸‹çš„"><a href="#2-ä¿®æ”¹pom-xml-å¤§æ¦‚åœ¨621è¡Œï¼Œå°†è‡ªå¸¦çš„repositoryæ³¨é‡Šæ‰ï¼Œæ·»åŠ ä»¥ä¸‹çš„" class="headerlink" title="2.ä¿®æ”¹pom.xml (å¤§æ¦‚åœ¨621è¡Œï¼Œå°†è‡ªå¸¦çš„repositoryæ³¨é‡Šæ‰ï¼Œæ·»åŠ ä»¥ä¸‹çš„)"></a>2.ä¿®æ”¹pom.xml (å¤§æ¦‚åœ¨621è¡Œï¼Œå°†è‡ªå¸¦çš„repositoryæ³¨é‡Šæ‰ï¼Œæ·»åŠ ä»¥ä¸‹çš„)</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;repository&gt;</span><br><span class="line">       &lt;id&gt;maven.tempo-db.com&lt;/id&gt;</span><br><span class="line">       &lt;url&gt;http://maven.oschina.net/service/local/repositories/sonatype-public-grid/content/&lt;/url&gt;</span><br><span class="line"> &lt;/repository&gt;</span><br></pre></td></tr></table></figure><p><img src="/assets/blogImg/0828_1.png" alt="enter description here"></p><h4 id="3-æ‰“å¼€cmd-ç¼–è¯‘"><a href="#3-æ‰“å¼€cmd-ç¼–è¯‘" class="headerlink" title="3.æ‰“å¼€cmd,ç¼–è¯‘"></a>3.æ‰“å¼€cmd,ç¼–è¯‘</h4><p>cd /d D:[WORK]\Training\05Hadoop\Compile\flume-1.7.0<br>mvn compile<br><img src="/assets/blogImg/0828_2.png" alt="enter description here"></p><h4 id="4-æ‰“å¼€eclipse-å•å‡»Windowâ€“-gt-Perferencesâ€“-gt-å·¦ä¾§çš„Mavenâ€“-gt-User-Settings"><a href="#4-æ‰“å¼€eclipse-å•å‡»Windowâ€“-gt-Perferencesâ€“-gt-å·¦ä¾§çš„Mavenâ€“-gt-User-Settings" class="headerlink" title="4.æ‰“å¼€eclipse,å•å‡»Windowâ€“&gt;Perferencesâ€“&gt;å·¦ä¾§çš„Mavenâ€“&gt;User Settings"></a>4.æ‰“å¼€eclipse,å•å‡»Windowâ€“&gt;Perferencesâ€“&gt;å·¦ä¾§çš„Mavenâ€“&gt;User Settings</h4><p>ç„¶åè®¾ç½®è‡ªå·±çš„mvnçš„setting.xmlè·¯å¾„å’ŒLocal Repository<br>(æœ€å¥½ä½¿ç”¨Maven3.3.xç‰ˆæœ¬ä»¥ä¸Šï¼Œæˆ‘æ˜¯3.3.9)<br><img src="/assets/blogImg/0828_3.png" alt="enter description here"></p><h4 id="5-å…³é—­eclipseçš„-Projectâ€“-gt-Buid-Automatically"><a href="#5-å…³é—­eclipseçš„-Projectâ€“-gt-Buid-Automatically" class="headerlink" title="5.å…³é—­eclipseçš„ Projectâ€“&gt;Buid Automatically"></a>5.å…³é—­eclipseçš„ Projectâ€“&gt;Buid Automatically</h4><p><img src="/assets/blogImg/0828_4.png" alt="enter description here"></p><h4 id="6-å…³é—­eclipseçš„Download-repository-index-updates-on-startup"><a href="#6-å…³é—­eclipseçš„Download-repository-index-updates-on-startup" class="headerlink" title="6.å…³é—­eclipseçš„Download repository index updates on startup"></a>6.å…³é—­eclipseçš„Download repository index updates on startup</h4><p><img src="/assets/blogImg/0828_5.png" alt="enter description here"></p><h4 id="7-å¯¼å…¥flume1-7-0æºç "><a href="#7-å¯¼å…¥flume1-7-0æºç " class="headerlink" title="7.å¯¼å…¥flume1.7.0æºç "></a>7.å¯¼å…¥flume1.7.0æºç </h4><p>a.Fileâ€“&gt;Importâ€“&gt;Mavenâ€“&gt;Existing Maven Projectsâ€“&gt;Next<br>b.é€‰æ‹©ç›®å½•â€“&gt; Finish</p><h4 id="8-æ£€æŸ¥æºç ï¼Œæ²¡æœ‰æŠ›ä»»ä½•é”™è¯¯"><a href="#8-æ£€æŸ¥æºç ï¼Œæ²¡æœ‰æŠ›ä»»ä½•é”™è¯¯" class="headerlink" title="8.æ£€æŸ¥æºç ï¼Œæ²¡æœ‰æŠ›ä»»ä½•é”™è¯¯"></a>8.æ£€æŸ¥æºç ï¼Œæ²¡æœ‰æŠ›ä»»ä½•é”™è¯¯</h4><p><img src="/assets/blogImg/0828_6.png" alt="enter description here"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Sat May 25 2019 21:07:00 GMT+0800 (GMT+08:00) --&gt;
    
    </summary>
    
      <category term="ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®" scheme="http://yoursite.com/categories/%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®" scheme="http://yoursite.com/tags/%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE/"/>
    
  </entry>
  
  <entry>
    <title>è¿™æ˜¯ä¸€ç¯‡çƒ­è…¾è…¾çš„é¢ç»</title>
    <link href="http://yoursite.com/2018/08/27/%E8%BF%99%E6%98%AF%E4%B8%80%E7%AF%87%E7%83%AD%E8%85%BE%E8%85%BE%E7%9A%84%E9%9D%A2%E7%BB%8F/"/>
    <id>http://yoursite.com/2018/08/27/è¿™æ˜¯ä¸€ç¯‡çƒ­è…¾è…¾çš„é¢ç»/</id>
    <published>2018-08-26T16:00:00.000Z</published>
    <updated>2019-05-19T14:24:12.651Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun May 19 2019 22:24:17 GMT+0800 (GMT+08:00) --><p>ä¼Ÿæ¢¦ï¼š<br>1.ä¸»è¦è¿˜æ˜¯é¡¹ç›®ï¼Ÿ<br>åŸºæœ¬ä¸Šæ²¡é—®ä»€ä¹ˆæŠ€æœ¯ï¼Œæˆ‘å°±è¯´äº†ä¸€éé¡¹ç›®æµç¨‹ï¼Œ<br>ç„¶åè¯´å‡ ä¸ªä¼˜åŒ–ç‚¹ï¼Œæ¯”å¦‚ä¸Šæ¬¡è®²çš„è¡€æ¡ˆï¼Œæˆ‘ä¹Ÿé¡ºå¸¦æäº†ä¸€ä¸‹ã€‚<br>2.åœ¨å¤§æ•°æ®ä¸­ï¼Œæœ‰æ²¡æœ‰ä»€ä¹ˆæ˜¯ä¸è¶³çš„ï¼Œé‡åˆ°è¿‡ä»€ä¹ˆé—®é¢˜ï¼Ÿ<br><a id="more"></a></p><p>å¾®ç›Ÿï¼š<br>1.SparkStreamingå¤„ç†å®Œä¸€æ‰¹æ¬¡çš„æ•°æ®ï¼Œå†™åç§»é‡ä¹‹å‰æŒ‚äº†ï¼Œæ•°æ®æ€ä¹ˆä¿è¯ä¸é‡ï¼Ÿ<br>2.Maxwellçš„åº•å±‚åŸç†ï¼Ÿ<br>3.æ‰‹å†™Springï¼Ÿ<br>4.éå†äºŒå‰æ ‘ï¼Ÿ<br>5.ç”¨è¿‡ä»€ä¹ˆç®—æ³•ï¼Ÿ<br>6.å¤šçº¿ç¨‹æ–¹é¢ï¼Œæ€ä¹ˆå®ç°ä¸€ä¸ªä¸»çº¿ç¨‹ï¼Œç­‰å¾…å…¶ä»–å­çº¿ç¨‹å®Œæˆåå†è¿è¡Œï¼Ÿ<br>7.Maxwellå’ŒCannalçš„æ¯”è¾ƒï¼Ÿ<br>8.directæ¯”è¾ƒreceiverçš„ä¼˜åŠ¿ï¼Ÿ<br>9.åŸæ¥æ˜¯æŠŠæ•°æ®ä¼ å…¥åˆ°Hiveï¼Œä¹‹åæ”¹äº†æ¶æ„ï¼Œæ€ä¹ˆæŠŠHiveçš„æ•°æ®å¯¼å…¥åˆ°Hbaseï¼Ÿ<br>10.ä¸ºä»€ä¹ˆç”¨Kafkaè‡ªå·±å­˜å‚¨offsetæ¥æ›¿ä»£checkpointï¼Œæ€ä¹ˆé˜²æ­¢äº†æ•°æ®åŒä»½è½åœ°ï¼Œæ•°æ®åŒä»½æ˜¯æŒ‡ä»€ä¹ˆï¼Ÿ<br>11.å•ä¾‹ç”¨è¿‡å—ï¼Ÿ</p><p>å¹³å®‰ï¼š<br>1.é—®é¡¹ç›®ï¼Œæµç¨‹ï¼Œä¸šåŠ¡ï¼Ÿ<br>2.æ•°æ®é‡ï¼Œå¢é‡ï¼Ÿ<br>3.å‡ ä¸ªäººå¼€å‘çš„ï¼Œä»£ç é‡å¤šå°‘ï¼Ÿ<br>4.ä½ ä¸»è¦åšä»€ä¹ˆçš„ï¼Ÿ<br>5.ä»€ä¹ˆåœºæ™¯ï¼Œç”¨SparkSqlåˆ†æä»€ä¹ˆä¸œè¥¿ï¼Ÿ</p><p>æ€»ç»“ï¼š<br>åŸºæœ¬ä¸Šéƒ½æ˜¯å›´ç»•é¡¹ç›®æ¥é¢ï¼Œç¬¬ä¸€å®¶é—®çš„æ¯”è¾ƒå°‘ï¼Œè€Œä¸”éƒ½æ˜¯å…³äºé¡¹ç›®ï¼›å¾®ç›Ÿçš„é¢è¯•å®˜åšçš„é¡¹ç›®ï¼Œ<br>è·Ÿç®€å†ä¸Šçš„é¡¹ç›®ï¼Œæ¶æ„ä¸ŠåŸºæœ¬ä¸€æ ·ï¼Œæ‰€ä»¥é—®çš„æ¯”è¾ƒæ·±ï¼Œé—®æˆ‘Maxwellçš„åº•å±‚åŸç†ï¼Œå¯¹æ¯”Cannalæœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Œ<br>ä¸ºä»€ä¹ˆé€‰æ‹©å®ƒï¼Œè¿™ä¸ªæˆ‘æ²¡å›ç­”ä¸Šæ¥ï¼Œåæ¥è®©æ‰‹å†™Springï¼Œç®—æ³•ï¼Œåæ¥å°±è®©æˆ‘èµ°äº†ï¼›<br>å¹³å®‰ä¹Ÿæ˜¯åŸºæœ¬å›´ç»•é¡¹ç›®ï¼Œä¸šåŠ¡ï¼Œæ•°æ®é‡ï¼Œæ²¡é—®ä»€ä¹ˆæŠ€æœ¯ï¼Œè€Œä¸”æˆ‘è¯´äº†å…³äºä¼˜åŒ–çš„ç‚¹(é¢è¯•å®˜è¯´ä¸è¦è¯´ç½‘ä¸Šéƒ½æœ‰çš„ä¸œè¥¿)ã€‚</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Sun May 19 2019 22:24:17 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;ä¼Ÿæ¢¦ï¼š&lt;br&gt;1.ä¸»è¦è¿˜æ˜¯é¡¹ç›®ï¼Ÿ&lt;br&gt;åŸºæœ¬ä¸Šæ²¡é—®ä»€ä¹ˆæŠ€æœ¯ï¼Œæˆ‘å°±è¯´äº†ä¸€éé¡¹ç›®æµç¨‹ï¼Œ&lt;br&gt;ç„¶åè¯´å‡ ä¸ªä¼˜åŒ–ç‚¹ï¼Œæ¯”å¦‚ä¸Šæ¬¡è®²çš„è¡€æ¡ˆï¼Œæˆ‘ä¹Ÿé¡ºå¸¦æäº†ä¸€ä¸‹ã€‚&lt;br&gt;2.åœ¨å¤§æ•°æ®ä¸­ï¼Œæœ‰æ²¡æœ‰ä»€ä¹ˆæ˜¯ä¸è¶³çš„ï¼Œé‡åˆ°è¿‡ä»€ä¹ˆé—®é¢˜ï¼Ÿ&lt;br&gt;
    
    </summary>
    
      <category term="é¢è¯•é¢˜" scheme="http://yoursite.com/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
    
      <category term="å¤§æ•°æ®é¢è¯•é¢˜" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>01ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®ä¹‹é¡¹ç›®æ¦‚è¿°</title>
    <link href="http://yoursite.com/2018/08/27/01%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE%E4%B9%8B%E9%A1%B9%E7%9B%AE%E6%A6%82%E8%BF%B0/"/>
    <id>http://yoursite.com/2018/08/27/01ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®ä¹‹é¡¹ç›®æ¦‚è¿°/</id>
    <published>2018-08-26T16:00:00.000Z</published>
    <updated>2019-05-25T13:09:16.933Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat May 25 2019 21:10:04 GMT+0800 (GMT+08:00) --><h3 id="1-å‰æœŸåŸºæœ¬æ¶æ„å›¾"><a href="#1-å‰æœŸåŸºæœ¬æ¶æ„å›¾" class="headerlink" title="1.å‰æœŸåŸºæœ¬æ¶æ„å›¾"></a>1.å‰æœŸåŸºæœ¬æ¶æ„å›¾</h3><p><img src="/assets/blogImg/0827_1.png" alt="enter description here"></p><h3 id="2-æœ€ç»ˆåŸºæœ¬æ¶æ„å›¾"><a href="#2-æœ€ç»ˆåŸºæœ¬æ¶æ„å›¾" class="headerlink" title="2.æœ€ç»ˆåŸºæœ¬æ¶æ„å›¾"></a>2.æœ€ç»ˆåŸºæœ¬æ¶æ„å›¾</h3><p><img src="/assets/blogImg/0827_2.png" alt="enter description here"><br><a id="more"></a></p><h3 id="3-ç‰ˆæœ¬"><a href="#3-ç‰ˆæœ¬" class="headerlink" title="3.ç‰ˆæœ¬"></a>3.ç‰ˆæœ¬</h3><table><thead><tr><th>ç»„ä»¶</th><th>ç‰ˆæœ¬</th></tr></thead><tbody><tr><td>Flume:</td><td>1.7</td></tr><tr><td>Hadoop:</td><td>2.7.3</td></tr><tr><td>Scala:</td><td>2.11</td></tr><tr><td>Kafka:</td><td>0.10.1.0</td></tr><tr><td>Spark:</td><td>2.0.2</td></tr><tr><td>InfluxDB:</td><td>1.2.0</td></tr><tr><td>Grafana:</td><td>4.1.1</td></tr><tr><td>maven:</td><td>3.3.9</td></tr></tbody></table><h3 id="4-ä¸»è¦ç›®çš„"><a href="#4-ä¸»è¦ç›®çš„" class="headerlink" title="4.ä¸»è¦ç›®çš„"></a>4.ä¸»è¦ç›®çš„</h3><p>ä¸»è¦æ˜¯æƒ³åŸºäºExec Sourceå¼€å‘è‡ªå®šä¹‰æ’ä»¶AdvancedExecSourceï¼Œå°†æœºå™¨åç§° å’Œ æœåŠ¡åç§° æ·»åŠ åˆ°cdh æœåŠ¡çš„è§’è‰²logæ•°æ®çš„æ¯ä¸€è¡Œå‰é¢ï¼Œåˆ™æ ¼å¼ä¸ºï¼šæœºå™¨åç§° æœåŠ¡åç§° å¹´æœˆæ—¥ æ—¶åˆ†ç§’.æ¯«ç§’ æ—¥å¿—çº§åˆ« æ—¥å¿—ä¿¡æ¯ ï¼›<br>ç„¶ååœ¨åé¢çš„spark streaming å®æ—¶è®¡ç®—æˆ‘ä»¬æ‰€éœ€æ±‚ï¼šæ¯”å¦‚ç»Ÿè®¡æ¯å°æœºå™¨çš„æœåŠ¡çš„æ¯ç§’å‡ºç°çš„erroræ¬¡æ•° ã€ç»Ÿè®¡æ¯5ç§’çš„warnï¼Œerroræ¬¡æ•°ç­‰ç­‰ï¼›<br>æ¥å®æ—¶å¯è§†åŒ–å±•ç¤ºå’Œé‚®ä»¶çŸ­ä¿¡ã€å¾®ä¿¡ä¼ä¸šå·é€šçŸ¥ã€‚</p><p>å…¶å®ä¸»è¦æˆ‘ä»¬ç°åœ¨çš„å¾ˆå¤šç›‘æ§æœåŠ¡åŸºæœ¬è¾¾ä¸åˆ°ç§’çº§çš„é€šçŸ¥ï¼Œéƒ½ä¸º5åˆ†é’Ÿç­‰ç­‰ï¼Œä¸ºäº†æ–¹ä¾¿æˆ‘ä»¬è‡ªå·±çš„ç»´æŠ¤ï¼›<br>å…¶å®å¯¹ä¸€äº›å³å°†å‡ºç°çš„é—®é¢˜å¯ä»¥æå‰é¢„çŸ¥ï¼›<br>å…¶å®æœ€ä¸»è¦å¯ä»¥æœ‰æ•ˆæ‰©å±•åˆ°å®æ—¶è®¡ç®—æ•°æ®åº“çº§åˆ«æ—¥å¿—ï¼Œæ¯”å¦‚MySQLæ…¢æŸ¥è¯¢æ—¥å¿—ï¼Œnginxï¼Œtomcatï¼Œlinuxçš„ç³»ç»Ÿçº§åˆ«æ—¥å¿—ç­‰ç­‰ã€‚</p><h3 id="5-å¤§æ¦‚æµç¨‹"><a href="#5-å¤§æ¦‚æµç¨‹" class="headerlink" title="5.å¤§æ¦‚æµç¨‹"></a>5.å¤§æ¦‚æµç¨‹</h3><p>1.æ­å»ºhadoop cluster<br>2.eclipse å¯¼å…¥flumeæºä»£ç ï¼ˆwindow7 å®‰è£…mavenï¼Œeclipseï¼Œeclipseä¸mavené›†æˆï¼‰<br>3.å¼€å‘flume-ng è‡ªå®šä¹‰æ’ä»¶<br>4.flume æ”¶é›†ï¼Œæ±‡èšåˆ°hdfs(ä¸»è¦æµ‹è¯•æ˜¯å¦æ±‡èšæˆåŠŸï¼ŒåæœŸä¹Ÿå¯ä»¥åšç¦»çº¿å¤„ç†)<br>5.flume æ”¶é›†ï¼Œæ±‡èšåˆ°kafka<br>6.æ­å»ºkafka monitor<br>7.æ­å»º spark client<br>8.window7è£…iedaå¼€å‘å·¥å…·<br>9.ideaå¼€å‘ spark streaming çš„wc<br>10.è¯»å–kafkaæ—¥å¿—ï¼Œå¼€å‘spark streamingçš„è¿™å—æ—¥å¿—åˆ†æ<br>11.å†™å…¥influxdb<br>12.grafanaå¯è§†åŒ–å±•ç¤º<br>13.é›†æˆé‚®ä»¶</p><p>###è¯´æ˜ï¼š<br>é’ˆå¯¹è‡ªèº«æƒ…å†µï¼Œè‡ªè¡Œé€‰æ‹©ï¼Œæ­¥éª¤å¦‚ä¸Šï¼Œä½†ä¸æ˜¯å›ºå®šçš„ï¼Œæœ‰äº›é¡ºåºæ˜¯å¯ä»¥æ‰“ä¹±çš„ï¼Œä¾‹å¦‚å¼€å‘å·¥å…·çš„å®‰è£…ï¼Œå¯ä»¥ä¸€èµ·æ“ä½œçš„ï¼Œå†å¦‚è¿™å‡ ä¸ªç»„ä»¶çš„ä¸‹è½½ç¼–è¯‘ï¼Œå¦‚æœä¸<br>æƒ³ç¼–è¯‘å¯ä»¥ç›´æ¥ä¸‹taråŒ…çš„ï¼Œè‡ªè¡Œé€‰æ‹©å°±å¥½ï¼Œä½†æ˜¯å»ºè®®è¿˜æ˜¯è‡ªå·±ç¼–è¯‘ï¼Œé‡åˆ°å‘æ‰èƒ½æ›´å¥½çš„è®°ä½è¿™ä¸ªä¸œè¥¿ï¼Œæœ¬èº«è¿™ä¸ªé¡¹ç›®å°±æ˜¯å­¦ä¹ æå‡çš„è¿‡ç¨‹ï¼Œè¦æ˜¯ä»€ä¹ˆéƒ½æ˜¯ç°æˆçš„ï¼Œ<br>é‚£å°±æ²¡ä»€ä¹ˆæ„ä¹‰äº†</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Sat May 25 2019 21:10:04 GMT+0800 (GMT+08:00) --&gt;&lt;h3 id=&quot;1-å‰æœŸåŸºæœ¬æ¶æ„å›¾&quot;&gt;&lt;a href=&quot;#1-å‰æœŸåŸºæœ¬æ¶æ„å›¾&quot; class=&quot;headerlink&quot; title=&quot;1.å‰æœŸåŸºæœ¬æ¶æ„å›¾&quot;&gt;&lt;/a&gt;1.å‰æœŸåŸºæœ¬æ¶æ„å›¾&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/assets/blogImg/0827_1.png&quot; alt=&quot;enter description here&quot;&gt;&lt;/p&gt;&lt;h3 id=&quot;2-æœ€ç»ˆåŸºæœ¬æ¶æ„å›¾&quot;&gt;&lt;a href=&quot;#2-æœ€ç»ˆåŸºæœ¬æ¶æ„å›¾&quot; class=&quot;headerlink&quot; title=&quot;2.æœ€ç»ˆåŸºæœ¬æ¶æ„å›¾&quot;&gt;&lt;/a&gt;2.æœ€ç»ˆåŸºæœ¬æ¶æ„å›¾&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/assets/blogImg/0827_2.png&quot; alt=&quot;enter description here&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®" scheme="http://yoursite.com/categories/%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="ç”Ÿäº§é¢„è­¦å¹³å°é¡¹ç›®" scheme="http://yoursite.com/tags/%E7%94%9F%E4%BA%A7%E9%A2%84%E8%AD%A6%E5%B9%B3%E5%8F%B0%E9%A1%B9%E7%9B%AE/"/>
    
  </entry>
  
  <entry>
    <title>sparkä¸­é…ç½®å¯ç”¨LZOå‹ç¼©</title>
    <link href="http://yoursite.com/2018/08/20/spark%E4%B8%AD%E9%85%8D%E7%BD%AE%E5%90%AF%E7%94%A8LZO%E5%8E%8B%E7%BC%A9/"/>
    <id>http://yoursite.com/2018/08/20/sparkä¸­é…ç½®å¯ç”¨LZOå‹ç¼©/</id>
    <published>2018-08-19T16:00:00.000Z</published>
    <updated>2019-05-19T13:59:58.484Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun May 19 2019 22:03:32 GMT+0800 (GMT+08:00) --><p>Sparkä¸­é…ç½®å¯ç”¨LZOå‹ç¼©ï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š</p><h3 id="ä¸€ã€spark-env-shé…ç½®"><a href="#ä¸€ã€spark-env-shé…ç½®" class="headerlink" title="ä¸€ã€spark-env.shé…ç½®"></a>ä¸€ã€spark-env.shé…ç½®</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/app/hadoop-2.6.0-cdh5.7.0/lib/native</span><br><span class="line">export SPARK_LIBRARY_PATH=$SPARK_LIBRARY_PATH:/app/hadoop-2.6.0-cdh5.7.0/lib/native</span><br><span class="line">export SPARK_CLASSPATH=$SPARK_CLASSPATH:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/yarn/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/yarn/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/hdfs/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/hdfs/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/tools/lib/*:/app/spark-2.2.0-bin-2.6.0-cdh5.7.0/jars/*</span><br></pre></td></tr></table></figure><h3 id="äºŒã€spark-defaults-confé…ç½®"><a href="#äºŒã€spark-defaults-confé…ç½®" class="headerlink" title="äºŒã€spark-defaults.confé…ç½®"></a>äºŒã€spark-defaults.confé…ç½®</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.driver.extraClassPath /app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/hadoop-lzo-0.4.19.jar</span><br><span class="line">spark.executor.extraClassPath /app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/hadoop-lzo-0.4.19.jar</span><br></pre></td></tr></table></figure><p><font color="#FF4500">æ³¨ï¼šæŒ‡å‘ç¼–è¯‘ç”Ÿæˆlzoçš„jaråŒ…</font><br><a id="more"></a></p><h3 id="ä¸‰ã€æµ‹è¯•"><a href="#ä¸‰ã€æµ‹è¯•" class="headerlink" title="ä¸‰ã€æµ‹è¯•"></a>ä¸‰ã€æµ‹è¯•</h3><h4 id="1ã€è¯»å–Lzoæ–‡ä»¶"><a href="#1ã€è¯»å–Lzoæ–‡ä»¶" class="headerlink" title="1ã€è¯»å–Lzoæ–‡ä»¶"></a>1ã€è¯»å–Lzoæ–‡ä»¶</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spark-shell --master local[2]</span><br><span class="line">scala&gt; import com.hadoop.compression.lzo.LzopCodec</span><br><span class="line">scala&gt; val page_views = sc.textFile(&quot;/user/hive/warehouse/page_views_lzo/page_views.dat.lzo&quot;)</span><br></pre></td></tr></table></figure><h4 id="2ã€å†™å‡ºlzoæ–‡ä»¶"><a href="#2ã€å†™å‡ºlzoæ–‡ä»¶" class="headerlink" title="2ã€å†™å‡ºlzoæ–‡ä»¶"></a>2ã€å†™å‡ºlzoæ–‡ä»¶</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">spark-shell --master local[2]</span><br><span class="line">scala&gt; import com.hadoop.compression.lzo.LzopCodec</span><br><span class="line">scala&gt; val lzoTest = sc.parallelize(1 to 10)</span><br><span class="line">scala&gt; lzoTest.saveAsTextFile(&quot;/input/test_lzo&quot;, classOf[LzopCodec])</span><br></pre></td></tr></table></figure><p>ç»“æœï¼š<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@spark220 common]$ hdfs dfs -ls /input/test_lzo</span><br><span class="line">Found 3 items</span><br><span class="line">-rw-r--r--   1 hadoop supergroup          0 2018-03-16 23:24 /input/test_lzo/_SUCCESS</span><br><span class="line">-rw-r--r--   1 hadoop supergroup         60 2018-03-16 23:24 /input/test_lzo/part-00000.lzo</span><br><span class="line">-rw-r--r--   1 hadoop supergroup         61 2018-03-16 23:24 /input/test_lzo/part-00001.lzo</span><br></pre></td></tr></table></figure><p></p><p>è‡³æ­¤é…ç½®ä¸æµ‹è¯•å®Œæˆã€‚</p><h3 id="å››ã€é…ç½®ä¸æµ‹è¯•ä¸­å­˜é—®é¢˜"><a href="#å››ã€é…ç½®ä¸æµ‹è¯•ä¸­å­˜é—®é¢˜" class="headerlink" title="å››ã€é…ç½®ä¸æµ‹è¯•ä¸­å­˜é—®é¢˜"></a>å››ã€é…ç½®ä¸æµ‹è¯•ä¸­å­˜é—®é¢˜</h3><h4 id="1ã€å¼•ç”¨nativeï¼Œç¼ºå°‘LD-LIBRARY-PATH"><a href="#1ã€å¼•ç”¨nativeï¼Œç¼ºå°‘LD-LIBRARY-PATH" class="headerlink" title="1ã€å¼•ç”¨nativeï¼Œç¼ºå°‘LD_LIBRARY_PATH"></a>1ã€å¼•ç”¨nativeï¼Œç¼ºå°‘LD_LIBRARY_PATH</h4><h5 id="1-1ã€é”™è¯¯æç¤ºï¼š"><a href="#1-1ã€é”™è¯¯æç¤ºï¼š" class="headerlink" title="1.1ã€é”™è¯¯æç¤ºï¼š"></a>1.1ã€é”™è¯¯æç¤ºï¼š</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Caused by: java.lang.RuntimeException: native-lzo library not available</span><br><span class="line">  at com.hadoop.compression.lzo.LzopCodec.getDecompressorType(LzopCodec.java:120)</span><br><span class="line">  at org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:178)</span><br><span class="line">  at org.apache.hadoop.mapred.LineRecordReader.(LineRecordReader.java:111)</span><br><span class="line">  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)</span><br><span class="line">  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:246)</span><br><span class="line">  at org.apache.spark.rdd.HadoopRDD$$anon$1.(HadoopRDD.scala:245)</span><br><span class="line">  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:203)</span><br><span class="line">  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:94)</span><br><span class="line">  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)</span><br><span class="line">  at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)</span><br><span class="line">  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)</span><br><span class="line">  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)</span><br><span class="line">  at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)</span><br><span class="line">  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)</span><br><span class="line">  at org.apache.spark.scheduler.Task.run(Task.scala:108)</span><br><span class="line">  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)</span><br><span class="line">  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">  at java.lang.Thread.run(Thread.java:748)</span><br></pre></td></tr></table></figure><h5 id="1-2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-evn-shï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š"><a href="#1-2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-evn-shï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š" class="headerlink" title="1.2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-evn.shï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š"></a>1.2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-evn.shï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/app/hadoop-2.6.0-cdh5.7.0/lib/native</span><br><span class="line">export SPARK_LIBRARY_PATH=$SPARK_LIBRARY_PATH:/app/hadoop-2.6.0-cdh5.7.0/lib/native</span><br><span class="line">export SPARK_CLASSPATH=$SPARK_CLASSPATH:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/yarn/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/yarn/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/hdfs/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/hdfs/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/tools/lib/*:/app/spark-2.2.0-bin-2.6.0-cdh5.7.0/jars/*</span><br></pre></td></tr></table></figure><h4 id="2ã€æ— æ³•æ‰¾åˆ°LzopCodecç±»"><a href="#2ã€æ— æ³•æ‰¾åˆ°LzopCodecç±»" class="headerlink" title="2ã€æ— æ³•æ‰¾åˆ°LzopCodecç±»"></a>2ã€æ— æ³•æ‰¾åˆ°LzopCodecç±»</h4><h5 id="2-1ã€é”™è¯¯æç¤ºï¼š"><a href="#2-1ã€é”™è¯¯æç¤ºï¼š" class="headerlink" title="2.1ã€é”™è¯¯æç¤ºï¼š"></a>2.1ã€é”™è¯¯æç¤ºï¼š</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Caused by: java.lang.IllegalArgumentException: Compression codec com.hadoop.compression.lzo.LzopCodec not found.</span><br><span class="line">    at org.apache.hadoop.io.compress.CompressionCodecFactory.getCodecClasses(CompressionCodecFactory.java:135)</span><br><span class="line">    at org.apache.hadoop.io.compress.CompressionCodecFactory.&lt;init&gt;(CompressionCodecFactory.java:175)</span><br><span class="line">    at org.apache.hadoop.mapred.TextInputFormat.configure(TextInputFormat.java:45)</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: Class com.hadoop.compression.lzo.LzopCodec not found</span><br><span class="line">    at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1980)</span><br><span class="line">    at org.apache.hadoop.io.compress.CompressionCodecFactory.getCodecClasses(CompressionCodecFactory.java:128)</span><br></pre></td></tr></table></figure><h5 id="2-2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-defaults-confï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š"><a href="#2-2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-defaults-confï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š" class="headerlink" title="2.2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-defaults.confï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š"></a>2.2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-defaults.confï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">spark.driver.extraClassPath /app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/hadoop-lzo-0.4.19.jar</span><br><span class="line">spark.executor.extraClassPath /app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/hadoop-lzo-0.4.19.ja</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Sun May 19 2019 22:03:32 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;Sparkä¸­é…ç½®å¯ç”¨LZOå‹ç¼©ï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š&lt;/p&gt;&lt;h3 id=&quot;ä¸€ã€spark-env-shé…ç½®&quot;&gt;&lt;a href=&quot;#ä¸€ã€spark-env-shé…ç½®&quot; class=&quot;headerlink&quot; title=&quot;ä¸€ã€spark-env.shé…ç½®&quot;&gt;&lt;/a&gt;ä¸€ã€spark-env.shé…ç½®&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/app/hadoop-2.6.0-cdh5.7.0/lib/native&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export SPARK_LIBRARY_PATH=$SPARK_LIBRARY_PATH:/app/hadoop-2.6.0-cdh5.7.0/lib/native&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export SPARK_CLASSPATH=$SPARK_CLASSPATH:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/yarn/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/yarn/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/hdfs/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/hdfs/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/tools/lib/*:/app/spark-2.2.0-bin-2.6.0-cdh5.7.0/jars/*&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h3 id=&quot;äºŒã€spark-defaults-confé…ç½®&quot;&gt;&lt;a href=&quot;#äºŒã€spark-defaults-confé…ç½®&quot; class=&quot;headerlink&quot; title=&quot;äºŒã€spark-defaults.confé…ç½®&quot;&gt;&lt;/a&gt;äºŒã€spark-defaults.confé…ç½®&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;spark.driver.extraClassPath /app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/hadoop-lzo-0.4.19.jar&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;spark.executor.extraClassPath /app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/hadoop-lzo-0.4.19.jar&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;font color=&quot;#FF4500&quot;&gt;æ³¨ï¼šæŒ‡å‘ç¼–è¯‘ç”Ÿæˆlzoçš„jaråŒ…&lt;/font&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>HDFSä¹‹åƒåœ¾å›æ”¶ç®±é…ç½®åŠä½¿ç”¨</title>
    <link href="http://yoursite.com/2018/07/18/HDFS%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%B1%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BD%BF%E7%94%A8/"/>
    <id>http://yoursite.com/2018/07/18/HDFSä¹‹åƒåœ¾å›æ”¶ç®±é…ç½®åŠä½¿ç”¨/</id>
    <published>2018-07-17T16:00:00.000Z</published>
    <updated>2019-05-19T13:53:51.770Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun May 19 2019 22:03:32 GMT+0800 (GMT+08:00) --><p>HDFSä¸ºæ¯ä¸ªç”¨æˆ·åˆ›å»ºä¸€ä¸ªå›æ”¶ç«™:<br>ç›®å½•:/user/ç”¨æˆ·/.Trash/Current, ç³»ç»Ÿå›æ”¶ç«™éƒ½æœ‰ä¸€ä¸ªå‘¨æœŸ,å‘¨æœŸè¿‡åhdfsä¼šå½»åº•åˆ é™¤æ¸…ç©º,å‘¨æœŸå†…å¯ä»¥æ¢å¤ã€‚<br><a id="more"></a></p><h4 id="ä¸€ã€HDFSåˆ é™¤æ–‡ä»¶-æ— æ³•æ¢å¤"><a href="#ä¸€ã€HDFSåˆ é™¤æ–‡ä»¶-æ— æ³•æ¢å¤" class="headerlink" title="ä¸€ã€HDFSåˆ é™¤æ–‡ä»¶,æ— æ³•æ¢å¤"></a>ä¸€ã€HDFSåˆ é™¤æ–‡ä»¶,æ— æ³•æ¢å¤</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 opt]$ hdfs dfs -rm /123.log</span><br><span class="line">Deleted /123.log</span><br></pre></td></tr></table></figure><h4 id="äºŒã€-å¯ç”¨å›æ”¶ç«™åŠŸèƒ½"><a href="#äºŒã€-å¯ç”¨å›æ”¶ç«™åŠŸèƒ½" class="headerlink" title="äºŒã€ å¯ç”¨å›æ”¶ç«™åŠŸèƒ½"></a>äºŒã€ å¯ç”¨å›æ”¶ç«™åŠŸèƒ½</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vim core-site.xml</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;!--å¤šé•¿æ—¶é—´åˆ›å»ºCheckPoint NameNodeèŠ‚ç‚¹ä¸Šè¿è¡Œçš„CheckPointer </span><br><span class="line">ä»Currentæ–‡ä»¶å¤¹åˆ›å»ºCheckPoint; é»˜è®¤: 0 ç”±fs.trash.intervalé¡¹æŒ‡å®š --&gt;</span><br><span class="line">&lt;name&gt;fs.trash.checkpoint.interval&lt;/name&gt;</span><br><span class="line">&lt;value&gt;0&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;!--å¤šå°‘åˆ†é’Ÿ.Trashä¸‹çš„CheckPointç›®å½•ä¼šè¢«åˆ é™¤,</span><br><span class="line">è¯¥é…ç½®æœåŠ¡å™¨è®¾ç½®ä¼˜å…ˆçº§å¤§äºå®¢æˆ·ç«¯ï¼Œé»˜è®¤:ä¸å¯ç”¨ --&gt;</span><br><span class="line">    &lt;name&gt;fs.trash.interval&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1440&lt;/value&gt;  -- æ¸…é™¤å‘¨æœŸåˆ†é’Ÿ(24å°æ—¶)</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h5 id="1ã€é‡å¯hdfsæœåŠ¡"><a href="#1ã€é‡å¯hdfsæœåŠ¡" class="headerlink" title="1ã€é‡å¯hdfsæœåŠ¡"></a>1ã€é‡å¯hdfsæœåŠ¡</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 sbin]$ ./stop-dfs.sh</span><br><span class="line">[hadoop@hadoop001 sbin]$ ./start-dfs.sh</span><br></pre></td></tr></table></figure><h5 id="2ã€æµ‹è¯•å›æ”¶ç«™åŠŸèƒ½"><a href="#2ã€æµ‹è¯•å›æ”¶ç«™åŠŸèƒ½" class="headerlink" title="2ã€æµ‹è¯•å›æ”¶ç«™åŠŸèƒ½"></a>2ã€æµ‹è¯•å›æ”¶ç«™åŠŸèƒ½</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 opt]$ hdfs dfs -put 123.log /</span><br><span class="line">[hadoop@hadoop001 opt]$ hdfs dfs -ls /</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        162 2018-05-23 11:30 /123.log</span><br></pre></td></tr></table></figure><h5 id="æ–‡ä»¶åˆ é™¤æˆåŠŸå­˜æ”¾å›æ”¶ç«™è·¯å¾„ä¸‹"><a href="#æ–‡ä»¶åˆ é™¤æˆåŠŸå­˜æ”¾å›æ”¶ç«™è·¯å¾„ä¸‹" class="headerlink" title="æ–‡ä»¶åˆ é™¤æˆåŠŸå­˜æ”¾å›æ”¶ç«™è·¯å¾„ä¸‹"></a>æ–‡ä»¶åˆ é™¤æˆåŠŸå­˜æ”¾å›æ”¶ç«™è·¯å¾„ä¸‹</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 opt]$ hdfs dfs -rm /123.log</span><br><span class="line">18/05/23 11:32:50 INFO fs.TrashPolicyDefault: Moved: &apos;hdfs://192.168.0.129:9000/123.log&apos; to trash at: hdfs://192.168.0.129:9000/user/hadoop/.Trash/Current/123.log</span><br><span class="line">[hadoop@hadoop001 opt]$ hdfs dfs -ls /</span><br><span class="line">Found 1 items</span><br><span class="line">drwx------   - hadoop supergroup          0 2018-05-23 11:32 /user</span><br></pre></td></tr></table></figure><h5 id="æ¢å¤æ–‡ä»¶"><a href="#æ¢å¤æ–‡ä»¶" class="headerlink" title="æ¢å¤æ–‡ä»¶"></a>æ¢å¤æ–‡ä»¶</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ hdfs dfs -mv /user/hadoop/.Trash/Current/123.log /456.log</span><br><span class="line">[hadoop@hadoop001 ~]$ hdfs dfs -ls /</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        162 2018-05-23 11:30 /456.log</span><br><span class="line">drwx------   - hadoop supergroup          0 2018-05-23 11:32 /user</span><br></pre></td></tr></table></figure><h5 id="åˆ é™¤æ–‡ä»¶è·³è¿‡å›æ”¶ç«™"><a href="#åˆ é™¤æ–‡ä»¶è·³è¿‡å›æ”¶ç«™" class="headerlink" title="åˆ é™¤æ–‡ä»¶è·³è¿‡å›æ”¶ç«™"></a>åˆ é™¤æ–‡ä»¶è·³è¿‡å›æ”¶ç«™</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop000 hadoop]$ hdfs dfs -rm -skipTrash /rz.log1</span><br><span class="line">[hadoop@hadoop001 ~]$ hdfs dfs -rm -skipTrash /456.log</span><br><span class="line">Deleted /456.log</span><br></pre></td></tr></table></figure><p>æºç å‚è€ƒï¼š<br><a href="https://blog.csdn.net/tracymkgld/article/details/17557655" target="_blank" rel="noopener">https://blog.csdn.net/tracymkgld/article/details/17557655</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Sun May 19 2019 22:03:32 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;HDFSä¸ºæ¯ä¸ªç”¨æˆ·åˆ›å»ºä¸€ä¸ªå›æ”¶ç«™:&lt;br&gt;ç›®å½•:/user/ç”¨æˆ·/.Trash/Current, ç³»ç»Ÿå›æ”¶ç«™éƒ½æœ‰ä¸€ä¸ªå‘¨æœŸ,å‘¨æœŸè¿‡åhdfsä¼šå½»åº•åˆ é™¤æ¸…ç©º,å‘¨æœŸå†…å¯ä»¥æ¢å¤ã€‚&lt;br&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Sparkåºåˆ—åŒ–ï¼Œä½ äº†è§£å—</title>
    <link href="http://yoursite.com/2018/07/16/Spark%E5%BA%8F%E5%88%97%E5%8C%96%EF%BC%8C%E4%BD%A0%E4%BA%86%E8%A7%A3%E5%90%97/"/>
    <id>http://yoursite.com/2018/07/16/Sparkåºåˆ—åŒ–ï¼Œä½ äº†è§£å—/</id>
    <published>2018-07-15T16:00:00.000Z</published>
    <updated>2019-05-17T14:24:36.362Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri May 17 2019 22:28:01 GMT+0800 (GMT+08:00) --><p>åºåˆ—åŒ–åœ¨åˆ†å¸ƒå¼åº”ç”¨çš„æ€§èƒ½ä¸­æ‰®æ¼”ç€é‡è¦çš„è§’è‰²ã€‚æ ¼å¼åŒ–å¯¹è±¡ç¼“æ…¢ï¼Œæˆ–è€…æ¶ˆè€—å¤§é‡çš„å­—èŠ‚æ ¼å¼åŒ–ï¼Œä¼šå¤§å¤§é™ä½è®¡ç®—æ€§èƒ½ã€‚é€šå¸¸è¿™æ˜¯åœ¨sparkåº”ç”¨ä¸­ç¬¬ä¸€ä»¶éœ€è¦ä¼˜åŒ–çš„äº‹æƒ…ã€‚Sparkçš„ç›®æ ‡æ˜¯åœ¨ä¾¿åˆ©ä¸æ€§èƒ½ä¸­å–å¾—å¹³è¡¡ï¼Œæ‰€ä»¥æä¾›2ç§åºåˆ—åŒ–çš„é€‰æ‹©ã€‚<br><a id="more"></a></p><h3 id="Java-serialization"><a href="#Java-serialization" class="headerlink" title="Java serialization"></a>Java serialization</h3><p>åœ¨é»˜è®¤æƒ…å†µä¸‹ï¼ŒSparkä¼šä½¿ç”¨Javaçš„ObjectOutputStreamæ¡†æ¶å¯¹å¯¹è±¡è¿›è¡Œåºåˆ—åŒ–ï¼Œå¹¶ä¸”å¯ä»¥ä¸ä»»ä½•å®ç°java.io.Serializableçš„ç±»ä¸€èµ·å·¥ä½œã€‚æ‚¨è¿˜å¯ä»¥é€šè¿‡æ‰©å±•java.io.Externalizableæ¥æ›´ç´§å¯†åœ°æ§åˆ¶åºåˆ—åŒ–çš„æ€§èƒ½ã€‚Javaåºåˆ—åŒ–æ˜¯çµæ´»çš„ï¼Œä½†é€šå¸¸ç›¸å½“æ…¢ï¼Œå¹¶ä¸”ä¼šå¯¼è‡´è®¸å¤šç±»çš„å¤§å‹åºåˆ—åŒ–æ ¼å¼ã€‚</p><h4 id="æµ‹è¯•ä»£ç ï¼š"><a href="#æµ‹è¯•ä»£ç ï¼š" class="headerlink" title="æµ‹è¯•ä»£ç ï¼š"></a>æµ‹è¯•ä»£ç ï¼š</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">package com.hihi.learn.sparkCore</span><br><span class="line"></span><br><span class="line">import org.apache.spark.storage.StorageLevel</span><br><span class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line"></span><br><span class="line">import scala.collection.mutable.ArrayBuffer</span><br><span class="line"></span><br><span class="line">case class Student(id: String, name: String, age: Int, gender: String)</span><br><span class="line"></span><br><span class="line">object SerializationDemo &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val conf = new SparkConf().setMaster(&quot;local[2]&quot;).setAppName(&quot;SerializationDemo&quot;)</span><br><span class="line">    val sc = new SparkContext(conf)</span><br><span class="line"></span><br><span class="line">    val stduentArr = new ArrayBuffer[Student]()</span><br><span class="line">    for (i &lt;- 1 to 1000000) &#123;</span><br><span class="line">      stduentArr += (Student(i + &quot;&quot;, i + &quot;a&quot;, 10, &quot;male&quot;))</span><br><span class="line">    &#125;</span><br><span class="line">    val JavaSerialization = sc.parallelize(stduentArr)</span><br><span class="line">    JavaSerialization.persist(StorageLevel.MEMORY_ONLY_SER).count()</span><br><span class="line"></span><br><span class="line">    while(true) &#123;</span><br><span class="line">      Thread.sleep(10000)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h4 id="æµ‹è¯•ç»“æœï¼š"><a href="#æµ‹è¯•ç»“æœï¼š" class="headerlink" title="æµ‹è¯•ç»“æœï¼š"></a>æµ‹è¯•ç»“æœï¼š</h4><p><img src="/assets/blogImg/716_1.png" alt="enter description here"></p><h3 id="Kryo-serialization"><a href="#Kryo-serialization" class="headerlink" title="Kryo serialization"></a>Kryo serialization</h3><p>Sparkè¿˜å¯ä»¥ä½¿ç”¨Kryoåº“ï¼ˆç‰ˆæœ¬2ï¼‰æ¥æ›´å¿«åœ°åºåˆ—åŒ–å¯¹è±¡ã€‚Kryoæ¯”Javaä¸²è¡ŒåŒ–ï¼ˆé€šå¸¸å¤šè¾¾10å€ï¼‰è¦å¿«å¾—å¤šï¼Œä¹Ÿæ›´ç´§å‡‘ï¼Œä½†æ˜¯ä¸æ”¯æŒæ‰€æœ‰å¯ä¸²è¡ŒåŒ–ç±»å‹ï¼Œå¹¶ä¸”è¦æ±‚æ‚¨æå‰æ³¨å†Œæ‚¨å°†åœ¨ç¨‹åºä¸­ä½¿ç”¨çš„ç±»ï¼Œä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚</p><h4 id="æµ‹è¯•ä»£ç ï¼š-1"><a href="#æµ‹è¯•ä»£ç ï¼š-1" class="headerlink" title="æµ‹è¯•ä»£ç ï¼š"></a>æµ‹è¯•ä»£ç ï¼š</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">package com.hihi.learn.sparkCore</span><br><span class="line"></span><br><span class="line">import org.apache.spark.storage.StorageLevel</span><br><span class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line"></span><br><span class="line">import scala.collection.mutable.ArrayBuffer</span><br><span class="line"></span><br><span class="line">case class Student(id: String, name: String, age: Int, gender: String)</span><br><span class="line"></span><br><span class="line">object SerializationDemo &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val conf = new SparkConf()</span><br><span class="line">      .setMaster(&quot;local[2]&quot;)</span><br><span class="line">      .setAppName(&quot;SerializationDemo&quot;)</span><br><span class="line">      .set(&quot;spark.serializer&quot;,&quot;org.apache.spark.serializer.KryoSerializer&quot;)</span><br><span class="line">    val sc = new SparkContext(conf)</span><br><span class="line"></span><br><span class="line">    val stduentArr = new ArrayBuffer[Student]()</span><br><span class="line">    for (i &lt;- 1 to 1000000) &#123;</span><br><span class="line">      stduentArr += (Student(i + &quot;&quot;, i + &quot;a&quot;, 10, &quot;male&quot;))</span><br><span class="line">    &#125;</span><br><span class="line">    val JavaSerialization = sc.parallelize(stduentArr)</span><br><span class="line">    JavaSerialization.persist(StorageLevel.MEMORY_ONLY_SER).count()</span><br><span class="line"></span><br><span class="line">    while(true) &#123;</span><br><span class="line">      Thread.sleep(10000)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p><img src="/assets/blogImg/716_2.png" alt="enter description here"><br>æµ‹è¯•ç»“æœä¸­å‘ç°ï¼Œä½¿ç”¨ Kryo serialization çš„åºåˆ—åŒ–å¯¹è±¡ æ¯”ä½¿ç”¨ Java serializationçš„åºåˆ—åŒ–å¯¹è±¡è¦å¤§ï¼Œä¸æè¿°çš„ä¸ä¸€æ ·ï¼Œè¿™æ˜¯ä¸ºä»€ä¹ˆå‘¢ï¼Ÿ<br>æŸ¥æ‰¾å®˜ç½‘ï¼Œå‘ç°è¿™ä¹ˆä¸€å¥è¯ Finally, if you donâ€™t register your custom classes, Kryo will still work, but it will have to store the full class name with each object, which is wasteful.ã€‚<br>ä¿®æ”¹ä»£ç ååœ¨æµ‹è¯•ä¸€æ¬¡<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">package com.hihi.learn.sparkCore</span><br><span class="line"></span><br><span class="line">import org.apache.spark.storage.StorageLevel</span><br><span class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line"></span><br><span class="line">import scala.collection.mutable.ArrayBuffer</span><br><span class="line"></span><br><span class="line">case class Student(id: String, name: String, age: Int, gender: String)</span><br><span class="line"></span><br><span class="line">object SerializationDemo &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val conf = new SparkConf()</span><br><span class="line">      .setMaster(&quot;local[2]&quot;)</span><br><span class="line">      .setAppName(&quot;SerializationDemo&quot;)</span><br><span class="line">      .set(&quot;spark.serializer&quot;,&quot;org.apache.spark.serializer.KryoSerializer&quot;)</span><br><span class="line">      .registerKryoClasses(Array(classOf[Student])) // å°†è‡ªå®šä¹‰çš„ç±»æ³¨å†Œåˆ°Kryo</span><br><span class="line">    val sc = new SparkContext(conf)</span><br><span class="line"></span><br><span class="line">    val stduentArr = new ArrayBuffer[Student]()</span><br><span class="line">    for (i &lt;- 1 to 1000000) &#123;</span><br><span class="line">      stduentArr += (Student(i + &quot;&quot;, i + &quot;a&quot;, 10, &quot;male&quot;))</span><br><span class="line">    &#125;</span><br><span class="line">    val JavaSerialization = sc.parallelize(stduentArr)</span><br><span class="line">    JavaSerialization.persist(StorageLevel.MEMORY_ONLY_SER).count()</span><br><span class="line"></span><br><span class="line">    while(true) &#123;</span><br><span class="line">      Thread.sleep(10000)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p></p><h4 id="æµ‹è¯•ç»“æœï¼š-1"><a href="#æµ‹è¯•ç»“æœï¼š-1" class="headerlink" title="æµ‹è¯•ç»“æœï¼š"></a>æµ‹è¯•ç»“æœï¼š</h4><p><img src="/assets/blogImg/716_3.png" alt="enter description here"></p><h3 id="æ€»ç»“ï¼š"><a href="#æ€»ç»“ï¼š" class="headerlink" title="æ€»ç»“ï¼š"></a>æ€»ç»“ï¼š</h3><p>Kryo serialization æ€§èƒ½å’Œåºåˆ—åŒ–å¤§å°éƒ½æ¯”é»˜è®¤æä¾›çš„ Java serialization è¦å¥½ï¼Œä½†æ˜¯ä½¿ç”¨Kryoéœ€è¦å°†è‡ªå®šä¹‰çš„ç±»å…ˆæ³¨å†Œè¿›å»ï¼Œä½¿ç”¨èµ·æ¥æ¯”Java serializationéº»çƒ¦ã€‚è‡ªä»Spark 2.0.0ä»¥æ¥ï¼Œæˆ‘ä»¬åœ¨ä½¿ç”¨ç®€å•ç±»å‹ã€ç®€å•ç±»å‹æ•°ç»„æˆ–å­—ç¬¦ä¸²ç±»å‹çš„ç®€å•ç±»å‹æ¥è°ƒæ•´RDDsæ—¶ï¼Œåœ¨å†…éƒ¨ä½¿ç”¨Kryoåºåˆ—åŒ–å™¨ã€‚<br>é€šè¿‡æŸ¥æ‰¾sparkcontextåˆå§‹åŒ–çš„æºç ï¼Œå¯ä»¥å‘ç°æŸäº›ç±»å‹å·²ç»åœ¨sparkcontextåˆå§‹åŒ–çš„æ—¶å€™è¢«æ³¨å†Œè¿›å»ã€‚<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * Component which configures serialization, compression and encryption for various Spark</span><br><span class="line"> * components, including automatic selection of which [[Serializer]] to use for shuffles.</span><br><span class="line"> */</span><br><span class="line">private[spark] class SerializerManager(</span><br><span class="line">    defaultSerializer: Serializer,</span><br><span class="line">    conf: SparkConf,</span><br><span class="line">    encryptionKey: Option[Array[Byte]]) &#123;</span><br><span class="line"></span><br><span class="line">  def this(defaultSerializer: Serializer, conf: SparkConf) = this(defaultSerializer, conf, None)</span><br><span class="line"></span><br><span class="line">  private[this] val kryoSerializer = new KryoSerializer(conf)</span><br><span class="line"></span><br><span class="line">  private[this] val stringClassTag: ClassTag[String] = implicitly[ClassTag[String]]</span><br><span class="line">  private[this] val primitiveAndPrimitiveArrayClassTags: Set[ClassTag[_]] = &#123;</span><br><span class="line">    val primitiveClassTags = Set[ClassTag[_]](</span><br><span class="line">      ClassTag.Boolean,</span><br><span class="line">      ClassTag.Byte,</span><br><span class="line">      ClassTag.Char,</span><br><span class="line">      ClassTag.Double,</span><br><span class="line">      ClassTag.Float,</span><br><span class="line">      ClassTag.Int,</span><br><span class="line">      ClassTag.Long,</span><br><span class="line">      ClassTag.Null,</span><br><span class="line">      ClassTag.Short</span><br><span class="line">    )</span><br><span class="line">    val arrayClassTags = primitiveClassTags.map(_.wrap)</span><br><span class="line">    primitiveClassTags ++ arrayClassTags</span><br></pre></td></tr></table></figure><p></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Fri May 17 2019 22:28:01 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;åºåˆ—åŒ–åœ¨åˆ†å¸ƒå¼åº”ç”¨çš„æ€§èƒ½ä¸­æ‰®æ¼”ç€é‡è¦çš„è§’è‰²ã€‚æ ¼å¼åŒ–å¯¹è±¡ç¼“æ…¢ï¼Œæˆ–è€…æ¶ˆè€—å¤§é‡çš„å­—èŠ‚æ ¼å¼åŒ–ï¼Œä¼šå¤§å¤§é™ä½è®¡ç®—æ€§èƒ½ã€‚é€šå¸¸è¿™æ˜¯åœ¨sparkåº”ç”¨ä¸­ç¬¬ä¸€ä»¶éœ€è¦ä¼˜åŒ–çš„äº‹æƒ…ã€‚Sparkçš„ç›®æ ‡æ˜¯åœ¨ä¾¿åˆ©ä¸æ€§èƒ½ä¸­å–å¾—å¹³è¡¡ï¼Œæ‰€ä»¥æä¾›2ç§åºåˆ—åŒ–çš„é€‰æ‹©ã€‚&lt;br&gt;
    
    </summary>
    
      <category term="Spark Core" scheme="http://yoursite.com/categories/Spark-Core/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
</feed>
