<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>è‹¥æ³½å¤§æ•°æ® www.ruozedata.com</title>
  
  <subtitle>ruozedata</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-05-13T12:17:53.768Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>ruozedata</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>è‹¥æ³½æ•°æ®-CDH5.16.1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²(å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ)</title>
    <link href="http://yoursite.com/2019/05/13/%E8%8B%A5%E6%B3%BD%E6%95%B0%E6%8D%AE-CDH5.16.1%E9%9B%86%E7%BE%A4%E4%BC%81%E4%B8%9A%E7%9C%9F%E6%AD%A3%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2(%E5%85%A8%E7%BD%91%E6%9C%80%E7%BB%86%EF%BC%8C%E9%85%8D%E5%A5%97%E8%A7%86%E9%A2%91%EF%BC%8C%E7%94%9F%E4%BA%A7%E5%8F%AF%E5%AE%9E%E8%B7%B5)/"/>
    <id>http://yoursite.com/2019/05/13/è‹¥æ³½æ•°æ®-CDH5.16.1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²(å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ)/</id>
    <published>2019-05-12T16:00:00.000Z</published>
    <updated>2019-05-13T12:17:53.768Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 13 2019 20:18:11 GMT+0800 (GMT+08:00) --><h2 id="è‹¥æ³½æ•°æ®"><a href="#è‹¥æ³½æ•°æ®" class="headerlink" title="è‹¥æ³½æ•°æ®"></a><a href="www.ruozedata.com">è‹¥æ³½æ•°æ®</a></h2><h2 id="CDH5-16-1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²-å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ"><a href="#CDH5-16-1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²-å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ" class="headerlink" title="CDH5.16.1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²(å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ)"></a>CDH5.16.1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²(å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ)</h2><p>è§†é¢‘:<a href="https://www.bilibili.com/video/av52167219" target="_blank" rel="noopener">https://www.bilibili.com/video/av52167219</a><br>PS:å»ºè®®å…ˆçœ‹è¯¾ç¨‹è§†é¢‘1-2ç¯‡ï¼Œå†æ ¹æ®è§†é¢‘æˆ–æ–‡æ¡£éƒ¨ç½²ï¼Œ<br>å¦‚æœ‰é—®é¢˜ï¼ŒåŠæ—¶ä¸@è‹¥æ³½æ•°æ®Jå“¥è”ç³»ã€‚</p><a id="more"></a><hr><h2 id="ä¸€-å‡†å¤‡å·¥ä½œ"><a href="#ä¸€-å‡†å¤‡å·¥ä½œ" class="headerlink" title="ä¸€.å‡†å¤‡å·¥ä½œ"></a>ä¸€.å‡†å¤‡å·¥ä½œ</h2><h4 id="1-ç¦»çº¿éƒ¨ç½²ä¸»è¦åˆ†ä¸ºä¸‰å—"><a href="#1-ç¦»çº¿éƒ¨ç½²ä¸»è¦åˆ†ä¸ºä¸‰å—" class="headerlink" title="1.ç¦»çº¿éƒ¨ç½²ä¸»è¦åˆ†ä¸ºä¸‰å—:"></a>1.ç¦»çº¿éƒ¨ç½²ä¸»è¦åˆ†ä¸ºä¸‰å—:</h4><p>a.MySQLç¦»çº¿éƒ¨ç½²<br>b.CMç¦»çº¿éƒ¨ç½²<br>c.Parcelæ–‡ä»¶ç¦»çº¿æºéƒ¨ç½²</p><h4 id="2-è§„åˆ’"><a href="#2-è§„åˆ’" class="headerlink" title="2.è§„åˆ’:"></a>2.è§„åˆ’:</h4><table><thead><tr><th>èŠ‚ç‚¹</th><th>MySQLéƒ¨ç½²ç»„ä»¶</th><th>Parcelæ–‡ä»¶ç¦»çº¿æº</th><th>CMæœåŠ¡è¿›ç¨‹</th><th>å¤§æ•°æ®ç»„ä»¶</th></tr></thead><tbody><tr><td>hadoop001</td><td>MySQL</td><td>Parcel</td><td>Activity Monitor<br></td><td>NN RM DN NM</td></tr><tr><td>hadoop002</td><td></td><td></td><td>Alert Publisher<br>Event Server</td><td>DN NM</td></tr><tr><td>hadoop003</td><td></td><td></td><td>Host Monitor<br>Service Monitor</td><td>DN NM</td></tr></tbody></table><h3 id="3-ä¸‹è½½æº"><a href="#3-ä¸‹è½½æº" class="headerlink" title="3.ä¸‹è½½æº:"></a>3.ä¸‹è½½æº:</h3><ul><li>CM<br><a href="http://archive.cloudera.com/cm5/cm/5/cloudera-manager-centos7-cm5.16.1_x86_64.tar.gz" target="_blank" rel="noopener">cloudera-manager-centos7-cm5.16.1_x86_64.tar.gz</a></li><li>Parcel<br><a href="http://archive.cloudera.com/cdh5/parcels/5.16.1/CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel" target="_blank" rel="noopener">CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel</a><br><a href="http://archive.cloudera.com/cdh5/parcels/5.16.1/CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel.sha1" target="_blank" rel="noopener">CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel.sha1</a><br><a href="http://archive.cloudera.com/cdh5/parcels/5.16.1/manifest.json" target="_blank" rel="noopener">manifest.json</a></li><li><p>JDK<br><a href="https://www.oracle.com/technetwork/java/javase/downloads/java-archive-javase8-2177648.html" target="_blank" rel="noopener">https://www.oracle.com/technetwork/java/javase/downloads/java-archive-javase8-2177648.html</a><br>ä¸‹è½½jdk-8u202-linux-x64.tar.gz</p></li><li><p>MySQL<br><a href="https://dev.mysql.com/downloads/mysql/5.7.html#downloads" target="_blank" rel="noopener">https://dev.mysql.com/downloads/mysql/5.7.html#downloads</a><br>ä¸‹è½½mysql-5.7.26-el7-x86_64.tar.gz</p></li><li><p>MySQL jdbc jar<br><a href="http://central.maven.org/maven2/mysql/mysql-connector-java/5.1.47/mysql-connector-java-5.1.47.jar" target="_blank" rel="noopener">mysql-connector-java-5.1.47.jar</a><br>ä¸‹è½½å®Œæˆåè¦é‡å‘½åå»æ‰ç‰ˆæœ¬å·ï¼Œ<br>mv mysql-connector-java-5.1.47.jar mysql-connector-java.jar</p></li></ul><hr><p>###å‡†å¤‡å¥½ç™¾åº¦äº‘,ä¸‹è½½å®‰è£…åŒ…:<br>é“¾æ¥:<a href="https://pan.baidu.com/s/10s-NaFLfztKuWImZTiBMjA" target="_blank" rel="noopener">https://pan.baidu.com/s/10s-NaFLfztKuWImZTiBMjA</a> å¯†ç :viqp</p><h2 id="äºŒ-é›†ç¾¤èŠ‚ç‚¹åˆå§‹åŒ–"><a href="#äºŒ-é›†ç¾¤èŠ‚ç‚¹åˆå§‹åŒ–" class="headerlink" title="äºŒ.é›†ç¾¤èŠ‚ç‚¹åˆå§‹åŒ–"></a>äºŒ.é›†ç¾¤èŠ‚ç‚¹åˆå§‹åŒ–</h2><h3 id="1-é˜¿é‡Œäº‘ä¸Šæµ·åŒºè´­ä¹°3å°ï¼ŒæŒ‰é‡ä»˜è´¹è™šæ‹Ÿæœº"><a href="#1-é˜¿é‡Œäº‘ä¸Šæµ·åŒºè´­ä¹°3å°ï¼ŒæŒ‰é‡ä»˜è´¹è™šæ‹Ÿæœº" class="headerlink" title="1.é˜¿é‡Œäº‘ä¸Šæµ·åŒºè´­ä¹°3å°ï¼ŒæŒ‰é‡ä»˜è´¹è™šæ‹Ÿæœº"></a>1.é˜¿é‡Œäº‘ä¸Šæµ·åŒºè´­ä¹°3å°ï¼ŒæŒ‰é‡ä»˜è´¹è™šæ‹Ÿæœº</h3><p>CentOS7.2æ“ä½œç³»ç»Ÿï¼Œ2æ ¸8Gæœ€ä½é…ç½®</p><h3 id="2-å½“å‰ç¬”è®°æœ¬æˆ–å°å¼æœºé…ç½®hostsæ–‡ä»¶"><a href="#2-å½“å‰ç¬”è®°æœ¬æˆ–å°å¼æœºé…ç½®hostsæ–‡ä»¶" class="headerlink" title="2.å½“å‰ç¬”è®°æœ¬æˆ–å°å¼æœºé…ç½®hostsæ–‡ä»¶"></a>2.å½“å‰ç¬”è®°æœ¬æˆ–å°å¼æœºé…ç½®hostsæ–‡ä»¶</h3><ul><li>MAC: /etc/hosts</li><li>Window: C:\windows\system32\drivers\etc\hosts</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">å…¬ç½‘åœ°å€: </span><br><span class="line">106.15.234.222 hadoop001  </span><br><span class="line">106.15.235.200 hadoop002  </span><br><span class="line">106.15.234.239 hadoop003</span><br></pre></td></tr></table></figure><h3 id="3-è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„hostsæ–‡ä»¶"><a href="#3-è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„hostsæ–‡ä»¶" class="headerlink" title="3.è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„hostsæ–‡ä»¶"></a>3.è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„hostsæ–‡ä»¶</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ç§æœ‰åœ°é“ã€å†…ç½‘åœ°å€:</span><br><span class="line">echo &quot;172.19.7.96 hadoop001&quot;&gt;&gt; /etc/hosts</span><br><span class="line">echo &quot;172.19.7.98 hadoop002&quot;&gt;&gt; /etc/hosts</span><br><span class="line">echo &quot;172.19.7.97 hadoop003&quot;&gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure><h3 id="4-å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„é˜²ç«å¢™åŠæ¸…ç©ºè§„åˆ™"><a href="#4-å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„é˜²ç«å¢™åŠæ¸…ç©ºè§„åˆ™" class="headerlink" title="4.å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„é˜²ç«å¢™åŠæ¸…ç©ºè§„åˆ™"></a>4.å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„é˜²ç«å¢™åŠæ¸…ç©ºè§„åˆ™</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld </span><br><span class="line">systemctl disable firewalld</span><br><span class="line">iptables -F</span><br></pre></td></tr></table></figure><h3 id="5-å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„selinux"><a href="#5-å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„selinux" class="headerlink" title="5.å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„selinux"></a>5.å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„selinux</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/selinux/config</span><br><span class="line">å°†SELINUX=enforcingæ”¹ä¸ºSELINUX=disabled </span><br><span class="line">è®¾ç½®åéœ€è¦é‡å¯æ‰èƒ½ç”Ÿæ•ˆ</span><br></pre></td></tr></table></figure><h3 id="6-è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„æ—¶åŒºä¸€è‡´åŠæ—¶é’ŸåŒæ­¥"><a href="#6-è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„æ—¶åŒºä¸€è‡´åŠæ—¶é’ŸåŒæ­¥" class="headerlink" title="6.è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„æ—¶åŒºä¸€è‡´åŠæ—¶é’ŸåŒæ­¥"></a>6.è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹çš„æ—¶åŒºä¸€è‡´åŠæ—¶é’ŸåŒæ­¥</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">6.1.æ—¶åŒº</span><br><span class="line">[root@hadoop001 ~]# date</span><br><span class="line">Sat May 11 10:07:53 CST 2019</span><br><span class="line">[root@hadoop001 ~]# timedatectl</span><br><span class="line">      Local time: Sat 2019-05-11 10:10:31 CST</span><br><span class="line">  Universal time: Sat 2019-05-11 02:10:31 UTC</span><br><span class="line">        RTC time: Sat 2019-05-11 10:10:29</span><br><span class="line">       Time zone: Asia/Shanghai (CST, +0800)</span><br><span class="line">     NTP enabled: yes</span><br><span class="line">NTP synchronized: yes</span><br><span class="line"> RTC in local TZ: yes</span><br><span class="line">      DST active: n/a</span><br><span class="line"></span><br><span class="line">#æŸ¥çœ‹å‘½ä»¤å¸®åŠ©ï¼Œå­¦ä¹ è‡³å…³é‡è¦ï¼Œæ— éœ€ç™¾åº¦ï¼Œå¤ªğŸ‘</span><br><span class="line">[root@hadoop001 ~]# timedatectl --help</span><br><span class="line">timedatectl [OPTIONS...] COMMAND ...</span><br><span class="line"></span><br><span class="line">Query or change system time and date settings.</span><br><span class="line"></span><br><span class="line">  -h --help                Show this help message</span><br><span class="line">     --version             Show package version</span><br><span class="line">     --no-pager            Do not pipe output into a pager</span><br><span class="line">     --no-ask-password     Do not prompt for password</span><br><span class="line">  -H --host=[USER@]HOST    Operate on remote host</span><br><span class="line">  -M --machine=CONTAINER   Operate on local container</span><br><span class="line">     --adjust-system-clock Adjust system clock when changing local RTC mode</span><br><span class="line"></span><br><span class="line">Commands:</span><br><span class="line">  status                   Show current time settings</span><br><span class="line">  set-time TIME            Set system time</span><br><span class="line">  set-timezone ZONE        Set system time zone</span><br><span class="line">  list-timezones           Show known time zones</span><br><span class="line">  set-local-rtc BOOL       Control whether RTC is in local time</span><br><span class="line">  set-ntp BOOL             Control whether NTP is enabled</span><br><span class="line"></span><br><span class="line">#æŸ¥çœ‹å“ªäº›æ—¶åŒº</span><br><span class="line">[root@hadoop001 ~]# timedatectl list-timezones</span><br><span class="line">Africa/Abidjan</span><br><span class="line">Africa/Accra</span><br><span class="line">Africa/Addis_Ababa</span><br><span class="line">Africa/Algiers</span><br><span class="line">Africa/Asmara</span><br><span class="line">Africa/Bamako</span><br><span class="line"></span><br><span class="line">#æ‰€æœ‰èŠ‚ç‚¹è®¾ç½®äºšæ´²ä¸Šæµ·æ—¶åŒº </span><br><span class="line">[root@hadoop001 ~]# timedatectl set-timezone Asia/Shanghai</span><br><span class="line">[root@hadoop002 ~]# timedatectl set-timezone Asia/Shanghai</span><br><span class="line">[root@hadoop003 ~]# timedatectl set-timezone Asia/Shanghai</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">6.2.æ—¶é—´</span><br><span class="line">#æ‰€æœ‰èŠ‚ç‚¹å®‰è£…ntp</span><br><span class="line">[root@hadoop001 ~]# yum install -y ntp</span><br><span class="line"></span><br><span class="line">#é€‰å–hadoop001ä¸ºntpçš„ä¸»èŠ‚ç‚¹</span><br><span class="line">[root@hadoop001 ~]# vi /etc/ntp.conf </span><br><span class="line"></span><br><span class="line">#time</span><br><span class="line">server 0.asia.pool.ntp.org</span><br><span class="line">server 1.asia.pool.ntp.org</span><br><span class="line">server 2.asia.pool.ntp.org</span><br><span class="line">server 3.asia.pool.ntp.org</span><br><span class="line">#å½“å¤–éƒ¨æ—¶é—´ä¸å¯ç”¨æ—¶ï¼Œå¯ä½¿ç”¨æœ¬åœ°ç¡¬ä»¶æ—¶é—´</span><br><span class="line">server 127.127.1.0 iburst local clock </span><br><span class="line">#å…è®¸å“ªäº›ç½‘æ®µçš„æœºå™¨æ¥åŒæ­¥æ—¶é—´</span><br><span class="line">restrict 172.19.7.0 mask 255.255.255.0 nomodify notrap</span><br><span class="line"></span><br><span class="line">#å¼€å¯ntpdåŠæŸ¥çœ‹çŠ¶æ€</span><br><span class="line">[root@hadoop001 ~]# systemctl start ntpd</span><br><span class="line">[root@hadoop001 ~]# systemctl status ntpd</span><br><span class="line"> ntpd.service - Network Time Service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/ntpd.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Sat 2019-05-11 10:15:00 CST; 11min ago</span><br><span class="line"> Main PID: 18518 (ntpd)</span><br><span class="line">   CGroup: /system.slice/ntpd.service</span><br><span class="line">           â””â”€18518 /usr/sbin/ntpd -u ntp:ntp -g</span><br><span class="line"></span><br><span class="line">May 11 10:15:00 hadoop001 systemd[1]: Starting Network Time Service...</span><br><span class="line">May 11 10:15:00 hadoop001 ntpd[18518]: proto: precision = 0.088 usec</span><br><span class="line">May 11 10:15:00 hadoop001 ntpd[18518]: 0.0.0.0 c01d 0d kern kernel time sync enabled</span><br><span class="line">May 11 10:15:00 hadoop001 systemd[1]: Started Network Time Service.</span><br><span class="line"></span><br><span class="line">#éªŒè¯</span><br><span class="line">[root@hadoop001 ~]# ntpq -p</span><br><span class="line">     remote           refid      st t when poll reach   delay   offset  jitter</span><br><span class="line">==============================================================================</span><br><span class="line"> LOCAL(0)        .LOCL.          10 l  726   64    0    0.000    0.000   0.000</span><br><span class="line"></span><br><span class="line">#å…¶ä»–ä»èŠ‚ç‚¹åœæ­¢ç¦ç”¨ntpdæœåŠ¡ </span><br><span class="line">[root@hadoop002 ~]# systemctl stop ntpd</span><br><span class="line">[root@hadoop002 ~]# systemctl disable ntpd</span><br><span class="line">Removed symlink /etc/systemd/system/multi-user.target.wants/ntpd.service.</span><br><span class="line">[root@hadoop002 ~]# /usr/sbin/ntpdate hadoop001</span><br><span class="line">11 May 10:29:22 ntpdate[9370]: adjust time server 172.19.7.96 offset 0.000867 sec</span><br><span class="line">#æ¯å¤©å‡Œæ™¨åŒæ­¥hadoop001èŠ‚ç‚¹æ—¶é—´</span><br><span class="line">[root@hadoop002 ~]# crontab -e</span><br><span class="line">00 00 * * * /usr/sbin/ntpdate hadoop001  </span><br><span class="line"></span><br><span class="line">[root@hadoop003 ~]# systemctl stop ntpd</span><br><span class="line">[root@hadoop004 ~]# systemctl disable ntpd</span><br><span class="line">Removed symlink /etc/systemd/system/multi-user.target.wants/ntpd.service.</span><br><span class="line">[root@hadoop005 ~]# /usr/sbin/ntpdate hadoop001</span><br><span class="line">11 May 10:29:22 ntpdate[9370]: adjust time server 172.19.7.96 offset 0.000867 sec</span><br><span class="line">#æ¯å¤©å‡Œæ™¨åŒæ­¥hadoop001èŠ‚ç‚¹æ—¶é—´</span><br><span class="line">[root@hadoop003 ~]# crontab -e</span><br><span class="line">00 00 * * * /usr/sbin/ntpdate hadoop001</span><br></pre></td></tr></table></figure><h3 id="7-éƒ¨ç½²é›†ç¾¤çš„JDK"><a href="#7-éƒ¨ç½²é›†ç¾¤çš„JDK" class="headerlink" title="7.éƒ¨ç½²é›†ç¾¤çš„JDK"></a>7.éƒ¨ç½²é›†ç¾¤çš„JDK</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mkdir /usr/java</span><br><span class="line">tar -xzvf jdk-8u45-linux-x64.tar.gz -C /usr/java/</span><br><span class="line">#åˆ‡è®°å¿…é¡»ä¿®æ­£æ‰€å±ç”¨æˆ·åŠç”¨æˆ·ç»„</span><br><span class="line">chown -R root:root /usr/java/jdk1.8.0_45</span><br><span class="line"></span><br><span class="line">echo &quot;export JAVA_HOME=/usr/java/jdk1.8.0_45&quot; &gt;&gt; /etc/profile</span><br><span class="line">echo &quot;export PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;PATH&#125;&quot; &gt;&gt; /etc/profile</span><br><span class="line">source /etc/profile</span><br><span class="line">which java</span><br></pre></td></tr></table></figure><h3 id="8-hadoop001èŠ‚ç‚¹ç¦»çº¿éƒ¨ç½²MySQL5-7-å‡å¦‚è§‰å¾—å›°éš¾å“Ÿï¼Œå°±è‡ªè¡Œç™¾åº¦RPMéƒ¨ç½²ï¼Œå› ä¸ºè¯¥éƒ¨ç½²æ–‡æ¡£æ˜¯æˆ‘å¸ç”Ÿäº§æ–‡æ¡£"><a href="#8-hadoop001èŠ‚ç‚¹ç¦»çº¿éƒ¨ç½²MySQL5-7-å‡å¦‚è§‰å¾—å›°éš¾å“Ÿï¼Œå°±è‡ªè¡Œç™¾åº¦RPMéƒ¨ç½²ï¼Œå› ä¸ºè¯¥éƒ¨ç½²æ–‡æ¡£æ˜¯æˆ‘å¸ç”Ÿäº§æ–‡æ¡£" class="headerlink" title="8.hadoop001èŠ‚ç‚¹ç¦»çº¿éƒ¨ç½²MySQL5.7(å‡å¦‚è§‰å¾—å›°éš¾å“Ÿï¼Œå°±è‡ªè¡Œç™¾åº¦RPMéƒ¨ç½²ï¼Œå› ä¸ºè¯¥éƒ¨ç½²æ–‡æ¡£æ˜¯æˆ‘å¸ç”Ÿäº§æ–‡æ¡£)"></a>8.hadoop001èŠ‚ç‚¹ç¦»çº¿éƒ¨ç½²MySQL5.7(å‡å¦‚è§‰å¾—å›°éš¾å“Ÿï¼Œå°±è‡ªè¡Œç™¾åº¦RPMéƒ¨ç½²ï¼Œå› ä¸ºè¯¥éƒ¨ç½²æ–‡æ¡£æ˜¯æˆ‘å¸ç”Ÿäº§æ–‡æ¡£)</h3><ul><li>æ–‡æ¡£é“¾æ¥:<a href="https://github.com/Hackeruncle/MySQL" target="_blank" rel="noopener">https://github.com/Hackeruncle/MySQL</a></li><li>è§†é¢‘é“¾æ¥:<a href="https://pan.baidu.com/s/1jdM8WeIg8syU0evL1-tDOQ" target="_blank" rel="noopener">https://pan.baidu.com/s/1jdM8WeIg8syU0evL1-tDOQ</a> å¯†ç :whic</li></ul><h3 id="9-åˆ›å»ºCDHçš„å…ƒæ•°æ®åº“å’Œç”¨æˆ·ã€amonæœåŠ¡çš„æ•°æ®åº“åŠç”¨æˆ·"><a href="#9-åˆ›å»ºCDHçš„å…ƒæ•°æ®åº“å’Œç”¨æˆ·ã€amonæœåŠ¡çš„æ•°æ®åº“åŠç”¨æˆ·" class="headerlink" title="9.åˆ›å»ºCDHçš„å…ƒæ•°æ®åº“å’Œç”¨æˆ·ã€amonæœåŠ¡çš„æ•°æ®åº“åŠç”¨æˆ·"></a>9.åˆ›å»ºCDHçš„å…ƒæ•°æ®åº“å’Œç”¨æˆ·ã€amonæœåŠ¡çš„æ•°æ®åº“åŠç”¨æˆ·</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">create database cmf DEFAULT CHARACTER SET utf8;</span><br><span class="line">create database amon DEFAULT CHARACTER SET utf8;</span><br><span class="line">grant all on cmf.* TO &apos;cmf&apos;@&apos;%&apos; IDENTIFIED BY &apos;Ruozedata123456!&apos;;</span><br><span class="line">grant all on amon.* TO &apos;amon&apos;@&apos;%&apos; IDENTIFIED BY &apos;Ruozedata123456!&apos;;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><h3 id="10-hadoop001èŠ‚ç‚¹éƒ¨ç½²mysql-jdbc-jar"><a href="#10-hadoop001èŠ‚ç‚¹éƒ¨ç½²mysql-jdbc-jar" class="headerlink" title="10.hadoop001èŠ‚ç‚¹éƒ¨ç½²mysql jdbc jar"></a>10.hadoop001èŠ‚ç‚¹éƒ¨ç½²mysql jdbc jar</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /usr/share/java/</span><br><span class="line">cp mysql-connector-java.jar /usr/share/java/</span><br></pre></td></tr></table></figure><h2 id="ä¸‰-CDHéƒ¨ç½²"><a href="#ä¸‰-CDHéƒ¨ç½²" class="headerlink" title="ä¸‰.CDHéƒ¨ç½²"></a>ä¸‰.CDHéƒ¨ç½²</h2><h3 id="1-ç¦»çº¿éƒ¨ç½²cm-serveråŠagent"><a href="#1-ç¦»çº¿éƒ¨ç½²cm-serveråŠagent" class="headerlink" title="1.ç¦»çº¿éƒ¨ç½²cm serveråŠagent"></a>1.ç¦»çº¿éƒ¨ç½²cm serveråŠagent</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">1.1.æ‰€æœ‰èŠ‚ç‚¹åˆ›å»ºç›®å½•åŠè§£å‹</span><br><span class="line">mkdir /opt/cloudera-manager</span><br><span class="line">tar -zxvf cloudera-manager-centos7-cm5.16.1_x86_64.tar.gz -C /opt/cloudera-manager/</span><br><span class="line"></span><br><span class="line">1.2.æ‰€æœ‰èŠ‚ç‚¹ä¿®æ”¹agentçš„é…ç½®ï¼ŒæŒ‡å‘serverçš„èŠ‚ç‚¹hadoop001</span><br><span class="line">sed -i &quot;s/server_host=localhost/server_host=hadoop001/g&quot; /opt/cloudera-manager/cm-5.16.1/etc/cloudera-scm-agent/config.ini</span><br><span class="line"></span><br><span class="line">1.3.ä¸»èŠ‚ç‚¹ä¿®æ”¹serverçš„é…ç½®:</span><br><span class="line">vi /opt/cloudera-manager/cm-5.16.1/etc/cloudera-scm-server/db.properties </span><br><span class="line">com.cloudera.cmf.db.type=mysql</span><br><span class="line">com.cloudera.cmf.db.host=hadoop001</span><br><span class="line">com.cloudera.cmf.db.name=cmf</span><br><span class="line">com.cloudera.cmf.db.user=cmf</span><br><span class="line">com.cloudera.cmf.db.password=Ruozedata123456!</span><br><span class="line">com.cloudera.cmf.db.setupType=EXTERNAL</span><br><span class="line"></span><br><span class="line">1.4.æ‰€æœ‰èŠ‚ç‚¹åˆ›å»ºç”¨æˆ·</span><br><span class="line">useradd --system --home=/opt/cloudera-manager/cm-5.16.1/run/cloudera-scm-server/ --no-create-home --shell=/bin/false --comment &quot;Cloudera SCM User&quot; cloudera-scm</span><br><span class="line"></span><br><span class="line">1.5.ç›®å½•ä¿®æ”¹ç”¨æˆ·åŠç”¨æˆ·ç»„</span><br><span class="line">chown -R cloudera-scm:cloudera-scm /opt/cloudera-manager</span><br></pre></td></tr></table></figure><h3 id="2-hadoop001èŠ‚ç‚¹éƒ¨ç½²ç¦»çº¿parcelæº"><a href="#2-hadoop001èŠ‚ç‚¹éƒ¨ç½²ç¦»çº¿parcelæº" class="headerlink" title="2.hadoop001èŠ‚ç‚¹éƒ¨ç½²ç¦»çº¿parcelæº"></a>2.hadoop001èŠ‚ç‚¹éƒ¨ç½²ç¦»çº¿parcelæº</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">2.1.éƒ¨ç½²ç¦»çº¿parcelæº</span><br><span class="line">$ mkdir -p /opt/cloudera/parcel-repo</span><br><span class="line">$ ll</span><br><span class="line">total 3081664</span><br><span class="line">-rw-r--r-- 1 root root 2127506677 May  9 18:04 CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel</span><br><span class="line">-rw-r--r-- 1 root root         41 May  9 18:03 CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel.sha1</span><br><span class="line">-rw-r--r-- 1 root root  841524318 May  9 18:03 cloudera-manager-centos7-cm5.16.1_x86_64.tar.gz</span><br><span class="line">-rw-r--r-- 1 root root  185515842 Aug 10  2017 jdk-8u144-linux-x64.tar.gz</span><br><span class="line">-rw-r--r-- 1 root root      66538 May  9 18:03 manifest.json</span><br><span class="line">-rw-r--r-- 1 root root     989495 May 25  2017 mysql-connector-java.jar</span><br><span class="line">$ cp CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel /opt/cloudera/parcel-repo/</span><br><span class="line"></span><br><span class="line">#åˆ‡è®°cpæ—¶ï¼Œé‡å‘½åå»æ‰1ï¼Œä¸ç„¶åœ¨éƒ¨ç½²è¿‡ç¨‹CMè®¤ä¸ºå¦‚ä¸Šæ–‡ä»¶ä¸‹è½½æœªå®Œæ•´ï¼Œä¼šæŒç»­ä¸‹è½½</span><br><span class="line">$ cp CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel.sha1 /opt/cloudera/parcel-repo/CDH-5.16.1-1.cdh5.16.1.p0.3-el7.parcel.sha</span><br><span class="line">$ cp manifest.json /opt/cloudera/parcel-repo/</span><br><span class="line"></span><br><span class="line">2.2.ç›®å½•ä¿®æ”¹ç”¨æˆ·åŠç”¨æˆ·ç»„</span><br><span class="line">$ chown -R cloudera-scm:cloudera-scm /opt/cloudera/</span><br></pre></td></tr></table></figure><h3 id="3-æ‰€æœ‰èŠ‚ç‚¹åˆ›å»ºè½¯ä»¶å®‰è£…ç›®å½•ã€ç”¨æˆ·åŠç”¨æˆ·ç»„æƒé™"><a href="#3-æ‰€æœ‰èŠ‚ç‚¹åˆ›å»ºè½¯ä»¶å®‰è£…ç›®å½•ã€ç”¨æˆ·åŠç”¨æˆ·ç»„æƒé™" class="headerlink" title="3.æ‰€æœ‰èŠ‚ç‚¹åˆ›å»ºè½¯ä»¶å®‰è£…ç›®å½•ã€ç”¨æˆ·åŠç”¨æˆ·ç»„æƒé™"></a>3.æ‰€æœ‰èŠ‚ç‚¹åˆ›å»ºè½¯ä»¶å®‰è£…ç›®å½•ã€ç”¨æˆ·åŠç”¨æˆ·ç»„æƒé™</h3><p>mkdir -p /opt/cloudera/parcels<br>chown -R cloudera-scm:cloudera-scm /opt/cloudera/</p><h3 id="4-hadoop001èŠ‚ç‚¹å¯åŠ¨Server"><a href="#4-hadoop001èŠ‚ç‚¹å¯åŠ¨Server" class="headerlink" title="4.hadoop001èŠ‚ç‚¹å¯åŠ¨Server"></a>4.hadoop001èŠ‚ç‚¹å¯åŠ¨Server</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">4.1.å¯åŠ¨server</span><br><span class="line">/opt/cloudera-manager/cm-5.16.1/etc/init.d/cloudera-scm-server start</span><br><span class="line"></span><br><span class="line">4.2.é˜¿é‡Œäº‘webç•Œé¢ï¼Œè®¾ç½®è¯¥hadoop001èŠ‚ç‚¹é˜²ç«å¢™æ”¾å¼€7180ç«¯å£</span><br><span class="line">4.3.ç­‰å¾…1minï¼Œæ‰“å¼€ http://hadoop001:7180 è´¦å·å¯†ç :admin/admin</span><br><span class="line">4.4.å‡å¦‚æ‰“ä¸å¼€ï¼Œå»çœ‹serverçš„logï¼Œæ ¹æ®é”™è¯¯ä»”ç»†æ’æŸ¥é”™è¯¯</span><br></pre></td></tr></table></figure><h3 id="5-æ‰€æœ‰èŠ‚ç‚¹å¯åŠ¨Agent"><a href="#5-æ‰€æœ‰èŠ‚ç‚¹å¯åŠ¨Agent" class="headerlink" title="5.æ‰€æœ‰èŠ‚ç‚¹å¯åŠ¨Agent"></a>5.æ‰€æœ‰èŠ‚ç‚¹å¯åŠ¨Agent</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/cloudera-manager/cm-5.16.1/etc/init.d/cloudera-scm-agent start</span><br></pre></td></tr></table></figure><h3 id="6-æ¥ä¸‹æ¥ï¼Œå…¨éƒ¨Webç•Œé¢æ“ä½œ"><a href="#6-æ¥ä¸‹æ¥ï¼Œå…¨éƒ¨Webç•Œé¢æ“ä½œ" class="headerlink" title="6.æ¥ä¸‹æ¥ï¼Œå…¨éƒ¨Webç•Œé¢æ“ä½œ"></a>6.æ¥ä¸‹æ¥ï¼Œå…¨éƒ¨Webç•Œé¢æ“ä½œ</h3><p><a href="http://hadoop001:7180/" target="_blank" rel="noopener">http://hadoop001:7180/</a><br>è´¦å·å¯†ç :admin/admin</p><h3 id="7-æ¬¢è¿ä½¿ç”¨Cloudera-Managerâ€“æœ€ç»ˆç”¨æˆ·è®¸å¯æ¡æ¬¾ä¸æ¡ä»¶ã€‚å‹¾é€‰"><a href="#7-æ¬¢è¿ä½¿ç”¨Cloudera-Managerâ€“æœ€ç»ˆç”¨æˆ·è®¸å¯æ¡æ¬¾ä¸æ¡ä»¶ã€‚å‹¾é€‰" class="headerlink" title="7.æ¬¢è¿ä½¿ç”¨Cloudera Managerâ€“æœ€ç»ˆç”¨æˆ·è®¸å¯æ¡æ¬¾ä¸æ¡ä»¶ã€‚å‹¾é€‰"></a>7.æ¬¢è¿ä½¿ç”¨Cloudera Managerâ€“æœ€ç»ˆç”¨æˆ·è®¸å¯æ¡æ¬¾ä¸æ¡ä»¶ã€‚å‹¾é€‰</h3><p><img src="install pictures/1.png" alt="avatar"></p><h3 id="8-æ¬¢è¿ä½¿ç”¨Cloudera-Managerâ€“æ‚¨æƒ³è¦éƒ¨ç½²å“ªä¸ªç‰ˆæœ¬ï¼Ÿé€‰æ‹©Cloudera-Expresså…è´¹ç‰ˆæœ¬"><a href="#8-æ¬¢è¿ä½¿ç”¨Cloudera-Managerâ€“æ‚¨æƒ³è¦éƒ¨ç½²å“ªä¸ªç‰ˆæœ¬ï¼Ÿé€‰æ‹©Cloudera-Expresså…è´¹ç‰ˆæœ¬" class="headerlink" title="8.æ¬¢è¿ä½¿ç”¨Cloudera Managerâ€“æ‚¨æƒ³è¦éƒ¨ç½²å“ªä¸ªç‰ˆæœ¬ï¼Ÿé€‰æ‹©Cloudera Expresså…è´¹ç‰ˆæœ¬"></a>8.æ¬¢è¿ä½¿ç”¨Cloudera Managerâ€“æ‚¨æƒ³è¦éƒ¨ç½²å“ªä¸ªç‰ˆæœ¬ï¼Ÿé€‰æ‹©Cloudera Expresså…è´¹ç‰ˆæœ¬</h3><p><img src="install pictures/2.png" alt="avatar"></p><h3 id="9-æ„Ÿè°¢æ‚¨é€‰æ‹©Cloudera-Managerå’ŒCDH"><a href="#9-æ„Ÿè°¢æ‚¨é€‰æ‹©Cloudera-Managerå’ŒCDH" class="headerlink" title="9.æ„Ÿè°¢æ‚¨é€‰æ‹©Cloudera Managerå’ŒCDH"></a>9.æ„Ÿè°¢æ‚¨é€‰æ‹©Cloudera Managerå’ŒCDH</h3><p><img src="install pictures/3.png" alt="avatar"></p><h3 id="10-ä¸ºCDHé›†ç¾¤å®‰è£…æŒ‡å¯¼ä¸»æœºã€‚é€‰æ‹©-å½“å‰ç®¡ç†çš„ä¸»æœº-ï¼Œå…¨éƒ¨å‹¾é€‰"><a href="#10-ä¸ºCDHé›†ç¾¤å®‰è£…æŒ‡å¯¼ä¸»æœºã€‚é€‰æ‹©-å½“å‰ç®¡ç†çš„ä¸»æœº-ï¼Œå…¨éƒ¨å‹¾é€‰" class="headerlink" title="10.ä¸ºCDHé›†ç¾¤å®‰è£…æŒ‡å¯¼ä¸»æœºã€‚é€‰æ‹©[å½“å‰ç®¡ç†çš„ä¸»æœº]ï¼Œå…¨éƒ¨å‹¾é€‰"></a>10.ä¸ºCDHé›†ç¾¤å®‰è£…æŒ‡å¯¼ä¸»æœºã€‚é€‰æ‹©[å½“å‰ç®¡ç†çš„ä¸»æœº]ï¼Œå…¨éƒ¨å‹¾é€‰</h3><p><img src="install pictures/4.png" alt="avatar"></p><h3 id="11-é€‰æ‹©å­˜å‚¨åº“"><a href="#11-é€‰æ‹©å­˜å‚¨åº“" class="headerlink" title="11.é€‰æ‹©å­˜å‚¨åº“"></a>11.é€‰æ‹©å­˜å‚¨åº“</h3><p><img src="install pictures/5.png" alt="avatar"></p><h3 id="12-é›†ç¾¤å®‰è£…â€“æ­£åœ¨å®‰è£…é€‰å®šParcelå‡å¦‚"><a href="#12-é›†ç¾¤å®‰è£…â€“æ­£åœ¨å®‰è£…é€‰å®šParcelå‡å¦‚" class="headerlink" title="12.é›†ç¾¤å®‰è£…â€“æ­£åœ¨å®‰è£…é€‰å®šParcelå‡å¦‚"></a>12.é›†ç¾¤å®‰è£…â€“æ­£åœ¨å®‰è£…é€‰å®šParcelå‡å¦‚</h3><p>æœ¬åœ°parcelç¦»çº¿æºé…ç½®æ­£ç¡®ï¼Œåˆ™â€ä¸‹è½½â€é˜¶æ®µç¬é—´å®Œæˆï¼Œå…¶ä½™é˜¶æ®µè§†èŠ‚ç‚¹æ•°ä¸å†…éƒ¨ç½‘ç»œæƒ…å†µå†³å®šã€‚<br><img src="install pictures/6.png" alt="avatar"></p><h3 id="13-æ£€æŸ¥ä¸»æœºæ­£ç¡®æ€§"><a href="#13-æ£€æŸ¥ä¸»æœºæ­£ç¡®æ€§" class="headerlink" title="13.æ£€æŸ¥ä¸»æœºæ­£ç¡®æ€§"></a>13.æ£€æŸ¥ä¸»æœºæ­£ç¡®æ€§</h3><p><img src="install pictures/7.png" alt="avatar"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">13.1.å»ºè®®å°†/proc/sys/vm/swappinessè®¾ç½®ä¸ºæœ€å¤§å€¼10ã€‚</span><br><span class="line">swappinesså€¼æ§åˆ¶æ“ä½œç³»ç»Ÿå°è¯•äº¤æ¢å†…å­˜çš„ç§¯æï¼›</span><br><span class="line">swappiness=0ï¼šè¡¨ç¤ºæœ€å¤§é™åº¦ä½¿ç”¨ç‰©ç†å†…å­˜ï¼Œä¹‹åæ‰æ˜¯swapç©ºé—´ï¼›</span><br><span class="line">swappiness=100ï¼šè¡¨ç¤ºç§¯æä½¿ç”¨swapåˆ†åŒºï¼Œå¹¶ä¸”æŠŠå†…å­˜ä¸Šçš„æ•°æ®åŠæ—¶æ¬è¿åˆ°swapç©ºé—´ï¼›</span><br><span class="line">å¦‚æœæ˜¯æ··åˆæœåŠ¡å™¨ï¼Œä¸å»ºè®®å®Œå…¨ç¦ç”¨swapï¼Œå¯ä»¥å°è¯•é™ä½swappinessã€‚</span><br><span class="line"></span><br><span class="line">ä¸´æ—¶è°ƒæ•´ï¼š</span><br><span class="line">sysctl vm.swappiness=10</span><br><span class="line"></span><br><span class="line">æ°¸ä¹…è°ƒæ•´ï¼š</span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; /etc/sysctl.conf</span><br><span class="line"># Adjust swappiness value</span><br><span class="line">vm.swappiness=10</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">13.2.å·²å¯ç”¨é€æ˜å¤§é¡µé¢å‹ç¼©ï¼Œå¯èƒ½ä¼šå¯¼è‡´é‡å¤§æ€§èƒ½é—®é¢˜ï¼Œå»ºè®®ç¦ç”¨æ­¤è®¾ç½®ã€‚</span><br><span class="line">ä¸´æ—¶è°ƒæ•´ï¼š</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line"></span><br><span class="line">æ°¸ä¹…è°ƒæ•´ï¼š</span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; /etc/rc.d/rc.local</span><br><span class="line"># Disable transparent_hugepage</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># centos7.xç³»ç»Ÿï¼Œéœ€è¦ä¸º&quot;/etc/rc.d/rc.local&quot;æ–‡ä»¶èµ‹äºˆæ‰§è¡Œæƒé™</span><br><span class="line">chmod +x /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure><h3 id="14-è‡ªå®šä¹‰æœåŠ¡ï¼Œé€‰æ‹©éƒ¨ç½²Zookeeperã€HDFSã€YarnæœåŠ¡"><a href="#14-è‡ªå®šä¹‰æœåŠ¡ï¼Œé€‰æ‹©éƒ¨ç½²Zookeeperã€HDFSã€YarnæœåŠ¡" class="headerlink" title="14.è‡ªå®šä¹‰æœåŠ¡ï¼Œé€‰æ‹©éƒ¨ç½²Zookeeperã€HDFSã€YarnæœåŠ¡"></a>14.è‡ªå®šä¹‰æœåŠ¡ï¼Œé€‰æ‹©éƒ¨ç½²Zookeeperã€HDFSã€YarnæœåŠ¡</h3><p><img src="install pictures/8.png" alt="avatar"></p><h3 id="15-è‡ªå®šä¹‰è§’è‰²åˆ†é…"><a href="#15-è‡ªå®šä¹‰è§’è‰²åˆ†é…" class="headerlink" title="15.è‡ªå®šä¹‰è§’è‰²åˆ†é…"></a>15.è‡ªå®šä¹‰è§’è‰²åˆ†é…</h3><p><img src="install pictures/9.png" alt="avatar"></p><h3 id="16-æ•°æ®åº“è®¾ç½®"><a href="#16-æ•°æ®åº“è®¾ç½®" class="headerlink" title="16.æ•°æ®åº“è®¾ç½®"></a>16.æ•°æ®åº“è®¾ç½®</h3><p><img src="install pictures/10.png" alt="avatar"></p><h3 id="17-å®¡æ”¹è®¾ç½®ï¼Œé»˜è®¤å³å¯"><a href="#17-å®¡æ”¹è®¾ç½®ï¼Œé»˜è®¤å³å¯" class="headerlink" title="17.å®¡æ”¹è®¾ç½®ï¼Œé»˜è®¤å³å¯"></a>17.å®¡æ”¹è®¾ç½®ï¼Œé»˜è®¤å³å¯</h3><p><img src="install pictures/11.png" alt="avatar"></p><h3 id="18-é¦–æ¬¡è¿è¡Œ"><a href="#18-é¦–æ¬¡è¿è¡Œ" class="headerlink" title="18.é¦–æ¬¡è¿è¡Œ"></a>18.é¦–æ¬¡è¿è¡Œ</h3><p><img src="install pictures/12.png" alt="avatar"></p><h3 id="19-æ­å–œæ‚¨"><a href="#19-æ­å–œæ‚¨" class="headerlink" title="19.æ­å–œæ‚¨!"></a>19.æ­å–œæ‚¨!</h3><p><img src="install pictures/13.png" alt="avatar"></p><h3 id="20-ä¸»é¡µ"><a href="#20-ä¸»é¡µ" class="headerlink" title="20.ä¸»é¡µ"></a>20.ä¸»é¡µ</h3><p><img src="install pictures/14.png" alt="avatar"></p><hr><h3 id="CDHå…¨å¥—è¯¾ç¨‹ç›®å½•ï¼Œå¦‚æœ‰buyï¼ŒåŠ å¾®ä¿¡-ruoze-star"><a href="#CDHå…¨å¥—è¯¾ç¨‹ç›®å½•ï¼Œå¦‚æœ‰buyï¼ŒåŠ å¾®ä¿¡-ruoze-star" class="headerlink" title="CDHå…¨å¥—è¯¾ç¨‹ç›®å½•ï¼Œå¦‚æœ‰buyï¼ŒåŠ å¾®ä¿¡(ruoze_star)"></a>CDHå…¨å¥—è¯¾ç¨‹ç›®å½•ï¼Œå¦‚æœ‰buyï¼ŒåŠ å¾®ä¿¡(ruoze_star)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">0.é’äº‘ç¯å¢ƒä»‹ç»å’Œä½¿ç”¨ </span><br><span class="line">1.Preparation        </span><br><span class="line">è°ˆè°ˆæ€æ ·å…¥é—¨å¤§æ•°æ® </span><br><span class="line">è°ˆè°ˆæ€æ ·åšå¥½ä¸€ä¸ªå¤§æ•°æ®å¹³å°çš„è¿è¥å·¥ä½œ </span><br><span class="line">Linuxæœºå™¨,å„è½¯ä»¶ç‰ˆæœ¬ä»‹ç»åŠå®‰è£…(å½•æ’­) </span><br><span class="line">2.Introduction      </span><br><span class="line">Clouderaã€CMåŠCDHä»‹ç» </span><br><span class="line">CDHç‰ˆæœ¬é€‰æ‹© </span><br><span class="line">CDHå®‰è£…å‡ ç§æ–¹å¼è§£è¯» </span><br><span class="line">3.Install&amp;UnInstall  </span><br><span class="line">é›†ç¾¤èŠ‚ç‚¹è§„åˆ’,ç¯å¢ƒå‡†å¤‡(NTP,Jdk and etc) </span><br><span class="line">MySQLç¼–è¯‘å®‰è£…åŠå¸¸ç”¨å‘½ä»¤ </span><br><span class="line">æ¨è:CDHç¦»çº¿å®‰è£…(è¸©å‘å¿ƒå¾—,å…¨é¢å‰–æ) </span><br><span class="line">è§£è¯»æš´åŠ›å¸è½½è„šæœ¬ </span><br><span class="line"></span><br><span class="line">4.CDH Management      </span><br><span class="line">CDHä½“ç³»æ¶æ„å‰–æ </span><br><span class="line">CDHé…ç½®æ–‡ä»¶æ·±åº¦è§£æ </span><br><span class="line">CMçš„å¸¸ç”¨å‘½ä»¤ </span><br><span class="line">CDHé›†ç¾¤æ­£ç¡®å¯åŠ¨å’Œåœæ­¢é¡ºåº </span><br><span class="line">CDH Tsquery Language </span><br><span class="line">CDHå¸¸è§„ç®¡ç†(ç›‘æ§/é¢„è­¦/é…ç½®/èµ„æº/æ—¥å¿—/å®‰å…¨) </span><br><span class="line"></span><br><span class="line">5.Maintenance Experiment  </span><br><span class="line">HDFS HA é…ç½® åŠhadoop/hdfså¸¸è§„å‘½ä»¤ </span><br><span class="line">Yarn HA é…ç½® åŠyarnå¸¸è§„å‘½ä»¤ </span><br><span class="line">Other CDH Components HA é…ç½® </span><br><span class="line">CDHåŠ¨æ€æ·»åŠ åˆ é™¤æœåŠ¡(hive/spark/hbase) </span><br><span class="line">CDHåŠ¨æ€æ·»åŠ åˆ é™¤æœºå™¨ </span><br><span class="line">CDHåŠ¨æ€æ·»åŠ åˆ é™¤åŠè¿ç§»DataNodeè¿›ç¨‹ç­‰ </span><br><span class="line">CDHå‡çº§(5.10.0--&gt;5.12.0) </span><br><span class="line"></span><br><span class="line">6.Resource Management    </span><br><span class="line">Linux Cgroups </span><br><span class="line">é™æ€èµ„æºæ±  </span><br><span class="line">åŠ¨æ€èµ„æºæ±  </span><br><span class="line">å¤šç§Ÿæˆ·æ¡ˆä¾‹ </span><br><span class="line"></span><br><span class="line">7.Performance Tunning    </span><br><span class="line">Memory/CPU/Network/DiskåŠé›†ç¾¤è§„åˆ’ </span><br><span class="line">Linuxå‚æ•° </span><br><span class="line">HDFSå‚æ•° </span><br><span class="line">MapReduceåŠYarnå‚æ•° </span><br><span class="line">å…¶ä»–æœåŠ¡å‚æ•° </span><br><span class="line"></span><br><span class="line">8.Cases Share </span><br><span class="line">CDH4&amp;5ä¹‹Alternativeså‘½ä»¤ çš„ç ”ç©¶ </span><br><span class="line">CDH5.8.2å®‰è£…ä¹‹Hash verification failed </span><br><span class="line">è®°å½•ä¸€æ¬¡CDH4.8.6 é…ç½®HDFS HA å‘ </span><br><span class="line">CDH5.0é›†ç¾¤IPæ›´æ”¹ </span><br><span class="line">CDHçš„active namenode exit(GC)å’Œå½©è›‹åˆ†äº« </span><br><span class="line"></span><br><span class="line">9. Kerberos</span><br><span class="line">Kerberosç®€ä»‹</span><br><span class="line">Kerberosä½“ç³»ç»“æ„</span><br><span class="line">Kerberoså·¥ä½œæœºåˆ¶</span><br><span class="line">Kerberoså®‰è£…éƒ¨ç½²</span><br><span class="line">CDHå¯ç”¨kerberos</span><br><span class="line">Kerberoså¼€å‘ä½¿ç”¨(çœŸå®ä»£ç )</span><br><span class="line"></span><br><span class="line">10.Summary         </span><br><span class="line">æ€»ç»“</span><br></pre></td></tr></table></figure><hr><h4 id="Join-us-if-you-have-a-dream"><a href="#Join-us-if-you-have-a-dream" class="headerlink" title="Join us if you have a dream."></a>Join us if you have a dream.</h4><h5 id="è‹¥æ³½æ•°æ®å®˜ç½‘-http-ruozedata-com"><a href="#è‹¥æ³½æ•°æ®å®˜ç½‘-http-ruozedata-com" class="headerlink" title="è‹¥æ³½æ•°æ®å®˜ç½‘: http://ruozedata.com"></a>è‹¥æ³½æ•°æ®å®˜ç½‘: <a href="http://ruozedata.com" target="_blank" rel="noopener">http://ruozedata.com</a></h5><h5 id="è…¾è®¯è¯¾å ‚ï¼Œæœè‹¥æ³½æ•°æ®-http-ruoze-ke-qq-com"><a href="#è…¾è®¯è¯¾å ‚ï¼Œæœè‹¥æ³½æ•°æ®-http-ruoze-ke-qq-com" class="headerlink" title="è…¾è®¯è¯¾å ‚ï¼Œæœè‹¥æ³½æ•°æ®: http://ruoze.ke.qq.com"></a>è…¾è®¯è¯¾å ‚ï¼Œæœè‹¥æ³½æ•°æ®: <a href="http://ruoze.ke.qq.com" target="_blank" rel="noopener">http://ruoze.ke.qq.com</a></h5><h5 id="Bilibiliç½‘ç«™-æœè‹¥æ³½æ•°æ®-https-space-bilibili-com-356836323"><a href="#Bilibiliç½‘ç«™-æœè‹¥æ³½æ•°æ®-https-space-bilibili-com-356836323" class="headerlink" title="Bilibiliç½‘ç«™,æœè‹¥æ³½æ•°æ®: https://space.bilibili.com/356836323"></a>Bilibiliç½‘ç«™,æœè‹¥æ³½æ•°æ®: <a href="https://space.bilibili.com/356836323" target="_blank" rel="noopener">https://space.bilibili.com/356836323</a></h5><h5 id="è‹¥æ³½å¤§æ•°æ®â€“å®˜æ–¹åšå®¢"><a href="#è‹¥æ³½å¤§æ•°æ®â€“å®˜æ–¹åšå®¢" class="headerlink" title="è‹¥æ³½å¤§æ•°æ®â€“å®˜æ–¹åšå®¢"></a><a href="https://ruozedata.github.io" target="_blank" rel="noopener">è‹¥æ³½å¤§æ•°æ®â€“å®˜æ–¹åšå®¢</a></h5><h5 id="è‹¥æ³½å¤§æ•°æ®â€“åšå®¢ä¸€è§ˆ"><a href="#è‹¥æ³½å¤§æ•°æ®â€“åšå®¢ä¸€è§ˆ" class="headerlink" title="è‹¥æ³½å¤§æ•°æ®â€“åšå®¢ä¸€è§ˆ"></a><a href="https://github.com/ruozedata/BigData/blob/master/blog/BigDataBlogOverview.md" target="_blank" rel="noopener">è‹¥æ³½å¤§æ•°æ®â€“åšå®¢ä¸€è§ˆ</a></h5><h5 id="è‹¥æ³½å¤§æ•°æ®â€“å†…éƒ¨å­¦å‘˜é¢è¯•é¢˜"><a href="#è‹¥æ³½å¤§æ•°æ®â€“å†…éƒ¨å­¦å‘˜é¢è¯•é¢˜" class="headerlink" title="è‹¥æ³½å¤§æ•°æ®â€“å†…éƒ¨å­¦å‘˜é¢è¯•é¢˜"></a><a href="https://github.com/ruozedata/BigData/blob/master/interview/%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98.md" target="_blank" rel="noopener">è‹¥æ³½å¤§æ•°æ®â€“å†…éƒ¨å­¦å‘˜é¢è¯•é¢˜</a></h5><h5 id="æ‰«ä¸€æ‰«ï¼Œå­¦ä¸€å­¦"><a href="#æ‰«ä¸€æ‰«ï¼Œå­¦ä¸€å­¦" class="headerlink" title="æ‰«ä¸€æ‰«ï¼Œå­¦ä¸€å­¦:"></a>æ‰«ä¸€æ‰«ï¼Œå­¦ä¸€å­¦:</h5><p><img src="install pictures/è‹¥æ³½æ•°æ®--æ‰«æå…¥å£.png" alt="avatar"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 13 2019 20:18:11 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;è‹¥æ³½æ•°æ®&quot;&gt;&lt;a href=&quot;#è‹¥æ³½æ•°æ®&quot; class=&quot;headerlink&quot; title=&quot;è‹¥æ³½æ•°æ®&quot;&gt;&lt;/a&gt;&lt;a href=&quot;www.ruozedata.com&quot;&gt;è‹¥æ³½æ•°æ®&lt;/a&gt;&lt;/h2&gt;&lt;h2 id=&quot;CDH5-16-1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²-å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ&quot;&gt;&lt;a href=&quot;#CDH5-16-1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²-å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ&quot; class=&quot;headerlink&quot; title=&quot;CDH5.16.1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²(å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ)&quot;&gt;&lt;/a&gt;CDH5.16.1é›†ç¾¤ä¼ä¸šçœŸæ­£ç¦»çº¿éƒ¨ç½²(å…¨ç½‘æœ€ç»†ï¼Œé…å¥—è§†é¢‘ï¼Œç”Ÿäº§å¯å®è·µ)&lt;/h2&gt;&lt;p&gt;è§†é¢‘:&lt;a href=&quot;https://www.bilibili.com/video/av52167219&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.bilibili.com/video/av52167219&lt;/a&gt;&lt;br&gt;PS:å»ºè®®å…ˆçœ‹è¯¾ç¨‹è§†é¢‘1-2ç¯‡ï¼Œå†æ ¹æ®è§†é¢‘æˆ–æ–‡æ¡£éƒ¨ç½²ï¼Œ&lt;br&gt;å¦‚æœ‰é—®é¢˜ï¼ŒåŠæ—¶ä¸@è‹¥æ³½æ•°æ®Jå“¥è”ç³»ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="CDH" scheme="http://yoursite.com/categories/CDH/"/>
    
    
      <category term="cdh" scheme="http://yoursite.com/tags/cdh/"/>
    
  </entry>
  
  <entry>
    <title>è‹¥æ³½æ•°æ®è¯¾ç¨‹ä¸€è§ˆ</title>
    <link href="http://yoursite.com/2019/05/08/%E8%8B%A5%E6%B3%BD%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B8%80%E8%A7%88/"/>
    <id>http://yoursite.com/2019/05/08/è‹¥æ³½æ•°æ®è¯¾ç¨‹ä¸€è§ˆ/</id>
    <published>2019-05-07T16:00:00.000Z</published>
    <updated>2019-05-13T08:00:08.535Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --><h1 id="è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—"><a href="#è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—" class="headerlink" title="è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—"></a>è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—</h1><h2 id="åŸºç¡€ç­"><a href="#åŸºç¡€ç­" class="headerlink" title="åŸºç¡€ç­"></a>åŸºç¡€ç­</h2><h3 id="Liunx"><a href="#Liunx" class="headerlink" title="Liunx"></a>Liunx</h3><ul><li>VMè™šæ‹Ÿæœºå®‰è£…</li><li>Liunxå¸¸ç”¨å‘½ä»¤ï¼ˆé‡ç‚¹ï¼‰</li><li>å¼€å‘ç¯å¢ƒæ­</li></ul><h3 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h3><ul><li>æºç å®‰è£…&amp;yumå®‰è£…</li><li>CRUDç¼–å†™</li><li>æƒé™æ§åˆ¶</li></ul><h3 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h3><ul><li>æ¶æ„ä»‹ç»&amp;&amp;æºç ç¼–è¯‘</li><li>ä¼ªåˆ†å¸ƒå¼å®‰è£…&amp;&amp;ä¼ä¸šåº”ç”¨</li><li><p>HDFSï¼ˆé‡ç‚¹ï¼‰</p><ul><li>æ¶æ„è®¾è®¡</li><li>å‰¯æœ¬æ”¾ç½®ç­–ç•¥</li><li>è¯»å†™æµç¨‹</li></ul></li><li><p>YARNï¼ˆé‡ç‚¹ï¼‰</p><ul><li>æ¶æ„è®¾è®¡</li><li>å·¥ä½œæµç¨‹</li><li>è°ƒåº¦ç®¡ç†&amp;&amp;å¸¸è§å‚æ•°é…ç½®ï¼ˆè°ƒä¼˜ï¼‰</li></ul></li><li><p>MapReduce</p><ul><li>æ¶æ„è®¾è®¡</li><li>wordcountåŸç†&amp;&amp;joinåŸç†å’Œæ¡ˆä¾‹<a id="more"></a><h3 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h3></li></ul></li><li><p>æ¶æ„è®¾è®¡</p></li><li>Hive DDL&amp;DML</li><li>joinåœ¨å¤§æ•°æ®ä¸­çš„ä½¿ç”¨</li><li>ä½¿ç”¨è‡ªå¸¦UDFå’Œå¼€å‘è‡ªå®šä¹‰UDF</li></ul><h3 id="Sqoop"><a href="#Sqoop" class="headerlink" title="Sqoop"></a>Sqoop</h3><ul><li>æ¶æ„è®¾è®¡</li><li>RDBMSå¯¼å…¥å¯¼å‡º</li></ul><h3 id="æ•´åˆé¡¹ç›®å°†æ‰€æœ‰ç»„ä»¶åˆä½œä½¿ç”¨ã€‚"><a href="#æ•´åˆé¡¹ç›®å°†æ‰€æœ‰ç»„ä»¶åˆä½œä½¿ç”¨ã€‚" class="headerlink" title="æ•´åˆé¡¹ç›®å°†æ‰€æœ‰ç»„ä»¶åˆä½œä½¿ç”¨ã€‚"></a>æ•´åˆé¡¹ç›®å°†æ‰€æœ‰ç»„ä»¶åˆä½œä½¿ç”¨ã€‚</h3><h3 id="äººå·¥æ™ºèƒ½åŸºç¡€"><a href="#äººå·¥æ™ºèƒ½åŸºç¡€" class="headerlink" title="äººå·¥æ™ºèƒ½åŸºç¡€"></a>äººå·¥æ™ºèƒ½åŸºç¡€</h3><ul><li>pythonåŸºç¡€</li><li>å¸¸ç”¨åº“â€”â€”pandasã€numpyã€sklearnã€keras</li></ul><h2 id="é«˜çº§ç­"><a href="#é«˜çº§ç­" class="headerlink" title="é«˜çº§ç­"></a>é«˜çº§ç­</h2><h3 id="scalaç¼–ç¨‹ï¼ˆé‡ç‚¹ï¼‰"><a href="#scalaç¼–ç¨‹ï¼ˆé‡ç‚¹ï¼‰" class="headerlink" title="scalaç¼–ç¨‹ï¼ˆé‡ç‚¹ï¼‰"></a>scalaç¼–ç¨‹ï¼ˆé‡ç‚¹ï¼‰</h3><h3 id="Sparkï¼ˆäº”æ˜Ÿé‡ç‚¹ï¼‰"><a href="#Sparkï¼ˆäº”æ˜Ÿé‡ç‚¹ï¼‰" class="headerlink" title="Sparkï¼ˆäº”æ˜Ÿé‡ç‚¹ï¼‰"></a>Sparkï¼ˆäº”æ˜Ÿé‡ç‚¹ï¼‰</h3><h3 id="Hadoopé«˜çº§"><a href="#Hadoopé«˜çº§" class="headerlink" title="Hadoopé«˜çº§"></a>Hadoopé«˜çº§</h3><h3 id="Hiveé«˜çº§"><a href="#Hiveé«˜çº§" class="headerlink" title="Hiveé«˜çº§"></a>Hiveé«˜çº§</h3><h3 id="Flume"><a href="#Flume" class="headerlink" title="Flume"></a>Flume</h3><h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><h3 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h3><h3 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h3><h3 id="CDH"><a href="#CDH" class="headerlink" title="CDH"></a>CDH</h3><h3 id="å®¹å™¨"><a href="#å®¹å™¨" class="headerlink" title="å®¹å™¨"></a>å®¹å™¨</h3><h3 id="è°ƒåº¦å¹³å°"><a href="#è°ƒåº¦å¹³å°" class="headerlink" title="è°ƒåº¦å¹³å°"></a>è°ƒåº¦å¹³å°</h3><h2 id="çº¿ä¸‹ç­"><a href="#çº¿ä¸‹ç­" class="headerlink" title="çº¿ä¸‹ç­"></a>çº¿ä¸‹ç­</h2><p><img src="/assets/blogImg/è‹¥æ³½æ•°æ®.png" alt="enter description here"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—&quot;&gt;&lt;a href=&quot;#è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—&quot; class=&quot;headerlink&quot; title=&quot;è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—&quot;&gt;&lt;/a&gt;è‹¥æ³½æ•°æ®è¯¾ç¨‹ç³»åˆ—&lt;/h1&gt;&lt;h2 id=&quot;åŸºç¡€ç­&quot;&gt;&lt;a href=&quot;#åŸºç¡€ç­&quot; class=&quot;headerlink&quot; title=&quot;åŸºç¡€ç­&quot;&gt;&lt;/a&gt;åŸºç¡€ç­&lt;/h2&gt;&lt;h3 id=&quot;Liunx&quot;&gt;&lt;a href=&quot;#Liunx&quot; class=&quot;headerlink&quot; title=&quot;Liunx&quot;&gt;&lt;/a&gt;Liunx&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;VMè™šæ‹Ÿæœºå®‰è£…&lt;/li&gt;&lt;li&gt;Liunxå¸¸ç”¨å‘½ä»¤ï¼ˆé‡ç‚¹ï¼‰&lt;/li&gt;&lt;li&gt;å¼€å‘ç¯å¢ƒæ­&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;MySQL&quot;&gt;&lt;a href=&quot;#MySQL&quot; class=&quot;headerlink&quot; title=&quot;MySQL&quot;&gt;&lt;/a&gt;MySQL&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;æºç å®‰è£…&amp;amp;yumå®‰è£…&lt;/li&gt;&lt;li&gt;CRUDç¼–å†™&lt;/li&gt;&lt;li&gt;æƒé™æ§åˆ¶&lt;/li&gt;&lt;/ul&gt;&lt;h3 id=&quot;Hadoop&quot;&gt;&lt;a href=&quot;#Hadoop&quot; class=&quot;headerlink&quot; title=&quot;Hadoop&quot;&gt;&lt;/a&gt;Hadoop&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;æ¶æ„ä»‹ç»&amp;amp;&amp;amp;æºç ç¼–è¯‘&lt;/li&gt;&lt;li&gt;ä¼ªåˆ†å¸ƒå¼å®‰è£…&amp;amp;&amp;amp;ä¼ä¸šåº”ç”¨&lt;/li&gt;&lt;li&gt;&lt;p&gt;HDFSï¼ˆé‡ç‚¹ï¼‰&lt;/p&gt;&lt;ul&gt;&lt;li&gt;æ¶æ„è®¾è®¡&lt;/li&gt;&lt;li&gt;å‰¯æœ¬æ”¾ç½®ç­–ç•¥&lt;/li&gt;&lt;li&gt;è¯»å†™æµç¨‹&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;YARNï¼ˆé‡ç‚¹ï¼‰&lt;/p&gt;&lt;ul&gt;&lt;li&gt;æ¶æ„è®¾è®¡&lt;/li&gt;&lt;li&gt;å·¥ä½œæµç¨‹&lt;/li&gt;&lt;li&gt;è°ƒåº¦ç®¡ç†&amp;amp;&amp;amp;å¸¸è§å‚æ•°é…ç½®ï¼ˆè°ƒä¼˜ï¼‰&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;MapReduce&lt;/p&gt;&lt;ul&gt;&lt;li&gt;æ¶æ„è®¾è®¡&lt;/li&gt;&lt;li&gt;wordcountåŸç†&amp;amp;&amp;amp;joinåŸç†å’Œæ¡ˆä¾‹
    
    </summary>
    
      <category term="è¯¾ç¨‹" scheme="http://yoursite.com/categories/%E8%AF%BE%E7%A8%8B/"/>
    
    
      <category term="è¯¾ç¨‹" scheme="http://yoursite.com/tags/%E8%AF%BE%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>dockerå¸¸ç”¨å‘½ä»¤ä»¥åŠå®‰è£…mysql</title>
    <link href="http://yoursite.com/2019/05/08/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%BB%A5%E5%8F%8A%E5%AE%89%E8%A3%85mysql/"/>
    <id>http://yoursite.com/2019/05/08/dockerå¸¸ç”¨å‘½ä»¤ä»¥åŠå®‰è£…mysql/</id>
    <published>2019-05-07T16:00:00.000Z</published>
    <updated>2019-05-13T08:00:04.117Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --><h3 id="1-ç®€ä»‹"><a href="#1-ç®€ä»‹" class="headerlink" title="1.ç®€ä»‹"></a>1.ç®€ä»‹</h3><p>Dockeræ˜¯ä¸€ä¸ªå¼€æºçš„åº”ç”¨å®¹å™¨å¼•æ“ï¼›æ˜¯ä¸€ä¸ªè½»é‡çº§å®¹å™¨æŠ€æœ¯ï¼›</p><p>Dockeræ”¯æŒå°†è½¯ä»¶ç¼–è¯‘æˆä¸€ä¸ªé•œåƒï¼›ç„¶ååœ¨é•œåƒä¸­å„ç§è½¯ä»¶åšå¥½é…ç½®ï¼Œå°†é•œåƒå‘å¸ƒå‡ºå»ï¼Œå…¶ä»–ä½¿ç”¨è€…å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™ä¸ªé•œåƒï¼›</p><p>è¿è¡Œä¸­çš„è¿™ä¸ªé•œåƒç§°ä¸ºå®¹å™¨ï¼Œå®¹å™¨å¯åŠ¨æ˜¯éå¸¸å¿«é€Ÿçš„ã€‚<br><a id="more"></a></p><h3 id="2-æ ¸å¿ƒæ¦‚å¿µ"><a href="#2-æ ¸å¿ƒæ¦‚å¿µ" class="headerlink" title="2.æ ¸å¿ƒæ¦‚å¿µ"></a>2.æ ¸å¿ƒæ¦‚å¿µ</h3><p>dockerä¸»æœº(Host)ï¼šå®‰è£…äº†Dockerç¨‹åºçš„æœºå™¨ï¼ˆDockerç›´æ¥å®‰è£…åœ¨æ“ä½œç³»ç»Ÿä¹‹ä¸Šï¼‰ï¼›</p><p>dockerå®¢æˆ·ç«¯(Client)ï¼šè¿æ¥dockerä¸»æœºè¿›è¡Œæ“ä½œï¼›</p><p>dockerä»“åº“(Registry)ï¼šç”¨æ¥ä¿å­˜å„ç§æ‰“åŒ…å¥½çš„è½¯ä»¶é•œåƒï¼›</p><p>dockeré•œåƒ(Images)ï¼šè½¯ä»¶æ‰“åŒ…å¥½çš„é•œåƒï¼›æ”¾åœ¨dockerä»“åº“ä¸­ï¼›</p><p>dockerå®¹å™¨(Container)ï¼šé•œåƒå¯åŠ¨åçš„å®ä¾‹ç§°ä¸ºä¸€ä¸ªå®¹å™¨ï¼›å®¹å™¨æ˜¯ç‹¬ç«‹è¿è¡Œçš„ä¸€ä¸ªæˆ–ä¸€ç»„åº”ç”¨</p><h3 id="3-å®‰è£…ç¯å¢ƒ"><a href="#3-å®‰è£…ç¯å¢ƒ" class="headerlink" title="3.å®‰è£…ç¯å¢ƒ"></a>3.å®‰è£…ç¯å¢ƒ</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">VM ware Workstation10</span><br><span class="line">CentOS-7-x86_64-DVD-1804.iso</span><br><span class="line">uname -r</span><br><span class="line">3.10.0-862.el7.x86_64</span><br></pre></td></tr></table></figure><p><strong>æ£€æŸ¥å†…æ ¸ç‰ˆæœ¬ï¼Œå¿…é¡»æ˜¯3.10åŠä»¥ä¸Š</strong> æŸ¥çœ‹å‘½ä»¤ï¼šuname -r</p><h3 id="4-åœ¨linuxè™šæ‹Ÿæœºä¸Šå®‰è£…docker"><a href="#4-åœ¨linuxè™šæ‹Ÿæœºä¸Šå®‰è£…docker" class="headerlink" title="4.åœ¨linuxè™šæ‹Ÿæœºä¸Šå®‰è£…docker"></a>4.åœ¨linuxè™šæ‹Ÿæœºä¸Šå®‰è£…docker</h3><p>æ­¥éª¤ï¼š</p><p>1ã€æ£€æŸ¥å†…æ ¸ç‰ˆæœ¬ï¼Œå¿…é¡»æ˜¯3.10åŠä»¥ä¸Š<br>uname -r</p><p>2ã€å®‰è£…docker<br>yum install docker</p><p>3ã€è¾“å…¥yç¡®è®¤å®‰è£…<br>Dependency Updated:<br>audit.x86_64 0:2.8.1-3.el7_5.1 audit-libs.x86_64 0:2.8.1-3.el7_5.1</p><p>Complete!<br>(æˆåŠŸæ ‡å¿—)</p><p>4ã€å¯åŠ¨docker<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop000 ~]# systemctl start docker</span><br><span class="line">[root@hadoop000 ~]# docker -v</span><br><span class="line">Docker version 1.13.1, build 8633870/1.13.1</span><br></pre></td></tr></table></figure><p></p><p>5ã€å¼€æœºå¯åŠ¨docker<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop000 ~]# systemctl enable docker</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.</span><br></pre></td></tr></table></figure><p></p><p>6ã€åœæ­¢docker<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop000 ~]# systemctl stop docker</span><br><span class="line">``` </span><br><span class="line">### 5.å¸¸ç”¨å‘½ä»¤</span><br><span class="line"></span><br><span class="line">é•œåƒæ“ä½œ</span><br><span class="line">|æ“ä½œ|å‘½ä»¤|è¯´æ˜|</span><br><span class="line">|---|---|---|</span><br><span class="line">æ£€ç´¢|docker search å…³é”®å­— egï¼šdocker search redis|æˆ‘ä»¬ç»å¸¸å»docker hubä¸Šæ£€ç´¢é•œåƒçš„è¯¦ç»†ä¿¡æ¯ï¼Œå¦‚é•œåƒçš„TAGã€‚|</span><br><span class="line">æ‹‰å–|docker pull é•œåƒå:tag|:tagæ˜¯å¯é€‰çš„ï¼Œtagè¡¨ç¤ºæ ‡ç­¾ï¼Œå¤šä¸ºè½¯ä»¶çš„ç‰ˆæœ¬ï¼Œé»˜è®¤æ˜¯latest</span><br><span class="line">åˆ—è¡¨|docker images|æŸ¥çœ‹æ‰€æœ‰æœ¬åœ°é•œåƒ</span><br><span class="line">åˆ é™¤|docker rmi image-id|åˆ é™¤æŒ‡å®šçš„æœ¬åœ°é•œåƒ</span><br><span class="line"></span><br><span class="line">å½“ç„¶å¤§å®¶ä¹Ÿå¯ä»¥åœ¨å®˜ç½‘æŸ¥æ‰¾ï¼šhttps://hub.docker.com/</span><br><span class="line"></span><br><span class="line">å®¹å™¨æ“ä½œ</span><br><span class="line">è½¯ä»¶é•œåƒï¼ˆQQå®‰è£…ç¨‹åºï¼‰----è¿è¡Œé•œåƒ----äº§ç”Ÿä¸€ä¸ªå®¹å™¨ï¼ˆæ­£åœ¨è¿è¡Œçš„è½¯ä»¶ï¼Œè¿è¡Œçš„QQï¼‰ï¼›</span><br><span class="line"></span><br><span class="line">æ­¥éª¤ï¼š</span><br><span class="line"></span><br><span class="line">- 1ã€æœç´¢é•œåƒ</span><br><span class="line">[root@localhost ~]# docker search tomcat</span><br><span class="line">- 2ã€æ‹‰å–é•œåƒ</span><br><span class="line">[root@localhost ~]# docker pull tomcat</span><br><span class="line">- 3ã€æ ¹æ®é•œåƒå¯åŠ¨å®¹å™¨</span><br><span class="line">docker run --name mytomcat -d tomcat:latest</span><br><span class="line">- 4ã€docker ps  </span><br><span class="line">æŸ¥çœ‹è¿è¡Œä¸­çš„å®¹å™¨</span><br><span class="line">- 5ã€ åœæ­¢è¿è¡Œä¸­çš„å®¹å™¨</span><br><span class="line">docker stop  å®¹å™¨çš„id</span><br><span class="line">- 6ã€æŸ¥çœ‹æ‰€æœ‰çš„å®¹å™¨</span><br><span class="line">docker ps -a</span><br><span class="line">- 7ã€å¯åŠ¨å®¹å™¨</span><br><span class="line">docker start å®¹å™¨id</span><br><span class="line">- 8ã€åˆ é™¤ä¸€ä¸ªå®¹å™¨</span><br><span class="line"> docker rm å®¹å™¨id</span><br><span class="line">- 9ã€å¯åŠ¨ä¸€ä¸ªåšäº†ç«¯å£æ˜ å°„çš„tomcat</span><br><span class="line">[root@localhost ~]# docker run -d -p 8888:8080 tomcat</span><br><span class="line">-dï¼šåå°è¿è¡Œ</span><br><span class="line">-p: å°†ä¸»æœºçš„ç«¯å£æ˜ å°„åˆ°å®¹å™¨çš„ä¸€ä¸ªç«¯å£    ä¸»æœºç«¯å£:å®¹å™¨å†…éƒ¨çš„ç«¯å£</span><br><span class="line"></span><br><span class="line">- 10ã€ä¸ºäº†æ¼”ç¤ºç®€å•å…³é—­äº†linuxçš„é˜²ç«å¢™</span><br><span class="line">service firewalld status ï¼›æŸ¥çœ‹é˜²ç«å¢™çŠ¶æ€</span><br><span class="line">service firewalld stopï¼šå…³é—­é˜²ç«å¢™</span><br><span class="line">systemctl disable firewalld.service #ç¦æ­¢firewallå¼€æœºå¯åŠ¨</span><br><span class="line">- 11ã€æŸ¥çœ‹å®¹å™¨çš„æ—¥å¿—</span><br><span class="line">docker logs container-name/container-id</span><br><span class="line"></span><br><span class="line">æ›´å¤šå‘½ä»¤å‚çœ‹</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/docker/</span><br><span class="line">å¯ä»¥å‚è€ƒé•œåƒæ–‡æ¡£</span><br><span class="line"></span><br><span class="line">### 6.ä½¿ç”¨dockerå®‰è£…mysql</span><br><span class="line"></span><br><span class="line">- docker pull mysql</span><br></pre></td></tr></table></figure><p></p><p>docker pull mysql<br>Using default tag: latest<br>Trying to pull repository docker.io/library/mysql â€¦<br>latest: Pulling from docker.io/library/mysql<br>a5a6f2f73cd8: Pull complete<br>936836019e67: Pull complete<br>283fa4c95fb4: Pull complete<br>1f212fb371f9: Pull complete<br>e2ae0d063e89: Pull complete<br>5ed0ae805b65: Pull complete<br>0283dc49ef4e: Pull complete<br>a7e1170b4fdb: Pull complete<br>88918a9e4742: Pull complete<br>241282fa67c2: Pull complete<br>b0fecf619210: Pull complete<br>bebf9f901dcc: Pull complete<br>Digest: sha256:b7f7479f0a2e7a3f4ce008329572f3497075dc000d8b89bac3134b0fb0288de8<br>Status: Downloaded newer image for docker.io/mysql:latest<br>[root@hadoop000 ~]# docker images<br>REPOSITORY TAG IMAGE ID CREATED SIZE<br>docker.io/mysql latest f991c20cb508 10 days ago 486 MB<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- å¯åŠ¨</span><br></pre></td></tr></table></figure><p></p><p>[root@hadoop000 ~]# docker images<br>REPOSITORY TAG IMAGE ID CREATED SIZE<br>docker.io/mysql latest f991c20cb508 10 days ago 486 MB<br>[root@hadoop000 ~]# docker run â€“name mysql01 -d mysql<br>756620c8e5832f4f7ef3e82117c31760d18ec169d45b8d48c0a10ff2536dcc4a<br>[root@hadoop000 ~]# docker ps -a<br>CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES<br>756620c8e583 mysql â€œdocker-entrypointâ€¦â€ 9 seconds ago Exited (1) 7 seconds ago mysql01<br>[root@hadoop000 ~]# docker logs 756620c8e583<br>error: database is uninitialized and password option is not specified<br>You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">å¯ä»¥çœ‹åˆ°ä¸Šé¢å¯åŠ¨çš„æ–¹å¼æ˜¯é”™è¯¯çš„ï¼Œæç¤ºæˆ‘ä»¬è¦å¸¦ä¸Šå…·ä½“çš„å¯†ç </span><br></pre></td></tr></table></figure><p></p><p>[root@hadoop000 ~]# docker run -p 3306:3306 â€“name mysql02 -e MYSQL_ROOT_PASSWORD=123456 -d mysql<br>eae86796e132027df994e5f29775eb04c6a1039a92905c247f1d149714fedc06<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">```</span><br><span class="line">â€“nameï¼šç»™æ–°åˆ›å»ºçš„å®¹å™¨å‘½åï¼Œæ­¤å¤„å‘½åä¸ºpwc-mysql</span><br><span class="line">-eï¼šé…ç½®ä¿¡æ¯ï¼Œæ­¤å¤„é…ç½®mysqlçš„rootç”¨æˆ·çš„ç™»é™†å¯†ç </span><br><span class="line">-pï¼šç«¯å£æ˜ å°„ï¼Œæ­¤å¤„æ˜ å°„ä¸»æœº3306ç«¯å£åˆ°å®¹å™¨pwc-mysqlçš„3306ç«¯å£</span><br><span class="line">-dï¼šæˆåŠŸå¯åŠ¨å®¹å™¨åè¾“å‡ºå®¹å™¨çš„å®Œæ•´IDï¼Œä¾‹å¦‚ä¸Šå›¾ 73f8811f669ee...</span><br></pre></td></tr></table></figure><p></p><ul><li><p>æŸ¥çœ‹æ˜¯å¦å¯åŠ¨æˆåŠŸ</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop000 ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                               NAMES</span><br><span class="line">eae86796e132        mysql               &quot;docker-entrypoint...&quot;   8 minutes ago       Up 8 minutes        0.0.0.0:3306-&gt;3306/tcp, 33060/tcp   mysql02</span><br></pre></td></tr></table></figure></li><li><p>ç™»é™†MySQL</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it mysql04 /bin/bash</span><br><span class="line">root@e34aba02c0c3:/# mysql -uroot -p123456 </span><br><span class="line">mysql: [Warning] Using a password on the command line interface can be insecure.</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 80</span><br><span class="line">Server version: 8.0.13 MySQL Community Server - GPL</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure></li><li><p>å…¶ä»–çš„é«˜çº§æ“ä½œ</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker run --name mysql03 -v /conf/mysql:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag</span><br><span class="line">æŠŠä¸»æœºçš„/conf/mysqlæ–‡ä»¶å¤¹æŒ‚è½½åˆ° mysqldockerå®¹å™¨çš„/etc/mysql/conf.dæ–‡ä»¶å¤¹é‡Œé¢</span><br><span class="line">æ”¹mysqlçš„é…ç½®æ–‡ä»¶å°±åªéœ€è¦æŠŠmysqlé…ç½®æ–‡ä»¶æ”¾åœ¨è‡ªå®šä¹‰çš„æ–‡ä»¶å¤¹ä¸‹ï¼ˆ/conf/mysqlï¼‰</span><br><span class="line"></span><br><span class="line">docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci</span><br><span class="line">æŒ‡å®šmysqlçš„ä¸€äº›é…ç½®å‚æ•°</span><br></pre></td></tr></table></figure></li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --&gt;&lt;h3 id=&quot;1-ç®€ä»‹&quot;&gt;&lt;a href=&quot;#1-ç®€ä»‹&quot; class=&quot;headerlink&quot; title=&quot;1.ç®€ä»‹&quot;&gt;&lt;/a&gt;1.ç®€ä»‹&lt;/h3&gt;&lt;p&gt;Dockeræ˜¯ä¸€ä¸ªå¼€æºçš„åº”ç”¨å®¹å™¨å¼•æ“ï¼›æ˜¯ä¸€ä¸ªè½»é‡çº§å®¹å™¨æŠ€æœ¯ï¼›&lt;/p&gt;&lt;p&gt;Dockeræ”¯æŒå°†è½¯ä»¶ç¼–è¯‘æˆä¸€ä¸ªé•œåƒï¼›ç„¶ååœ¨é•œåƒä¸­å„ç§è½¯ä»¶åšå¥½é…ç½®ï¼Œå°†é•œåƒå‘å¸ƒå‡ºå»ï¼Œå…¶ä»–ä½¿ç”¨è€…å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™ä¸ªé•œåƒï¼›&lt;/p&gt;&lt;p&gt;è¿è¡Œä¸­çš„è¿™ä¸ªé•œåƒç§°ä¸ºå®¹å™¨ï¼Œå®¹å™¨å¯åŠ¨æ˜¯éå¸¸å¿«é€Ÿçš„ã€‚&lt;br&gt;
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="docker" scheme="http://yoursite.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>spark2.4.2è¯¦ç»†ä»‹ç»</title>
    <link href="http://yoursite.com/2019/04/23/spark2.4.2%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2019/04/23/spark2.4.2è¯¦ç»†ä»‹ç»/</id>
    <published>2019-04-22T16:00:00.000Z</published>
    <updated>2019-05-13T08:58:29.254Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --><p>Sparkå‘å¸ƒäº†æœ€æ–°çš„ç‰ˆæœ¬spark-2.4.2<br>æ ¹æ®å®˜ç½‘ä»‹ç»ï¼Œæ­¤ç‰ˆæœ¬å¯¹äºä½¿ç”¨spark2.4çš„ç”¨æˆ·æ¥è¯´å¸®åŠ©æ˜¯å·¨å¤§çš„</p><h4 id="ç‰ˆæœ¬ä»‹ç»"><a href="#ç‰ˆæœ¬ä»‹ç»" class="headerlink" title="ç‰ˆæœ¬ä»‹ç»"></a>ç‰ˆæœ¬ä»‹ç»</h4><p><img src="/assets/blogImg/spark2.4.2_1.jpg" alt="enter description here"><br>Spark2.4.2æ˜¯ä¸€ä¸ªåŒ…å«ç¨³å®šæ€§ä¿®å¤çš„ç»´æŠ¤ç‰ˆæœ¬ã€‚ æ­¤ç‰ˆæœ¬åŸºäºSpark2.4ç»´æŠ¤åˆ†æ”¯ã€‚<font color="#FF4500"> <strong>æˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‰€æœ‰2.4ç”¨æˆ·å‡çº§åˆ°æ­¤ç¨³å®šç‰ˆæœ¬ã€‚</strong></font><br><a id="more"></a></p><h4 id="æ˜¾è‘—çš„å˜åŒ–"><a href="#æ˜¾è‘—çš„å˜åŒ–" class="headerlink" title="æ˜¾è‘—çš„å˜åŒ–"></a>æ˜¾è‘—çš„å˜åŒ–</h4><p><img src="/assets/blogImg/spark2.4.2_2.jpg" alt="enter description here"></p><ul><li>SPARK-27419ï¼šåœ¨spark2.4ä¸­å°†spark.executor.heartbeatIntervalè®¾ç½®ä¸ºå°äº1ç§’çš„å€¼æ—¶ï¼Œå®ƒå°†å§‹ç»ˆå¤±è´¥ã€‚ å› ä¸ºè¯¥å€¼å°†è½¬æ¢ä¸º0ï¼Œå¿ƒè·³å°†å§‹ç»ˆè¶…æ—¶ï¼Œå¹¶æœ€ç»ˆç»ˆæ­¢æ‰§è¡Œç¨‹åºã€‚</li><li>è¿˜åŸSPARK-25250ï¼šå¯èƒ½å¯¼è‡´ä½œä¸šæ°¸ä¹…æŒ‚èµ·ï¼Œåœ¨2.4.2ä¸­è¿˜åŸã€‚</li></ul><h4 id="è¯¦ç»†æ›´æ”¹"><a href="#è¯¦ç»†æ›´æ”¹" class="headerlink" title="è¯¦ç»†æ›´æ”¹"></a>è¯¦ç»†æ›´æ”¹</h4><p><img src="/assets/blogImg/spark2.4.2_3.jpg" alt="enter description here"></p><h6 id="BUG"><a href="#BUG" class="headerlink" title="BUG"></a>BUG</h6><table><thead><tr><th>issues</th><th>å†…å®¹æ‘˜è¦</th></tr></thead><tbody><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-26961" target="_blank" rel="noopener">[ SPARK-26961 ]</a></td><td>åœ¨Spark Driverä¸­å‘ç°Javaæ­»é”</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-26998" target="_blank" rel="noopener">[ SPARK-26998 ]</a></td><td>åœ¨Standaloneæ¨¡å¼ä¸‹æ‰§è¡Œâ€™ps -efâ€™ç¨‹åºè¿›ç¨‹,è¾“å‡ºspark.ssl.keyStorePasswordçš„æ˜æ–‡</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27216" target="_blank" rel="noopener">[ SPARK-27216 ]</a></td><td>å°†RoaringBitmapå‡çº§åˆ°0.7.45ä»¥ä¿®å¤Kryoä¸å®‰å…¨çš„ser / dseré—®é¢˜</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27244" target="_blank" rel="noopener">[ SPARK-27244 ]</a></td><td>ä½¿ç”¨é€‰é¡¹logConf = trueæ—¶å¯†ç å°†ä»¥confçš„æ˜æ–‡å½¢å¼è®°å½•</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27267" target="_blank" rel="noopener">[ SPARK-27267 ]</a></td><td>ç”¨Snappy 1.1.7.1è§£å‹ã€å‹ç¼©ç©ºåºåˆ—åŒ–æ•°æ®æ—¶å¤±è´¥</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27275" target="_blank" rel="noopener">[ SPARK-27275 ]</a></td><td>EncryptedMessage.transferToä¸­çš„æ½œåœ¨æŸå</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27301" target="_blank" rel="noopener">[ SPARK-27301 ]</a></td><td>DStreamCheckpointDataå› æ–‡ä»¶ç³»ç»Ÿå·²ç¼“å­˜è€Œæ— æ³•æ¸…ç†</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27338" target="_blank" rel="noopener">[ SPARK-27338 ]</a></td><td>TaskMemoryManagerå’ŒUnsafeExternalSorter $ SpillableIteratorä¹‹é—´çš„æ­»é”</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27351" target="_blank" rel="noopener">[ SPARK-27351 ]</a></td><td>åœ¨ä»…ä½¿ç”¨ç©ºå€¼åˆ—çš„AggregateEstimationä¹‹åçš„é”™è¯¯outputRowsä¼°è®¡</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27390" target="_blank" rel="noopener">[ SPARK-27390 ]</a></td><td>ä¿®å¤åŒ…åç§°ä¸åŒ¹é…</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27394" target="_blank" rel="noopener">[ SPARK-27394 ]</a></td><td>å½“æ²¡æœ‰ä»»åŠ¡å¼€å§‹æˆ–ç»“æŸæ—¶ï¼ŒUI çš„é™ˆæ—§æ€§å¯èƒ½æŒç»­æ•°åˆ†é’Ÿæˆ–æ•°å°æ—¶</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27403" target="_blank" rel="noopener">[ SPARK-27403 ]</a></td><td>ä¿®å¤updateTableStatsä»¥ä½¿ç”¨æ–°ç»Ÿè®¡ä¿¡æ¯æˆ–æ— æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27406" target="_blank" rel="noopener">[ SPARK-27406 ]</a></td><td>å½“ä¸¤å°æœºå™¨å…·æœ‰ä¸åŒçš„Oopså¤§å°æ—¶ï¼ŒUnsafeArrayDataåºåˆ—åŒ–ä¼šä¸­æ–­</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27419" target="_blank" rel="noopener">[ SPARK-27419 ]</a></td><td>å°†spark.executor.heartbeatIntervalè®¾ç½®ä¸ºå°äº1ç§’çš„å€¼æ—¶ï¼Œå®ƒå°†å§‹ç»ˆå¤±è´¥</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27453" target="_blank" rel="noopener">[ SPARK-27453 ]</a></td><td>DSV1é™é»˜åˆ é™¤DataFrameWriter.partitionBy</td></tr></tbody></table><h6 id="æ”¹è¿›"><a href="#æ”¹è¿›" class="headerlink" title="æ”¹è¿›"></a>æ”¹è¿›</h6><table><thead><tr><th>issues</th><th>å†…å®¹æ‘˜è¦</th></tr></thead><tbody><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27346" target="_blank" rel="noopener">[ SPARK-27346 ]</a></td><td>æ¾å¼€åœ¨ExpressionInfoçš„â€™examplesâ€™å­—æ®µä¸­æ¢è¡Œæ–­è¨€æ¡ä»¶</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27358" target="_blank" rel="noopener">[ SPARK-27358 ]</a></td><td>å°†jqueryæ›´æ–°ä¸º1.12.xä»¥è·å–å®‰å…¨ä¿®å¤ç¨‹åº</td></tr><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27479" target="_blank" rel="noopener">[ SPARK-27479 ]</a></td><td>éšè—â€œorg.apache.spark.util.kvstoreâ€çš„APIæ–‡æ¡£</td></tr></tbody></table><h6 id="å·¥ä½œ"><a href="#å·¥ä½œ" class="headerlink" title="å·¥ä½œ"></a>å·¥ä½œ</h6><table><thead><tr><th>issues</th><th>å†…å®¹æ‘˜è¦</th></tr></thead><tbody><tr><td><a href="https://issues.apache.org/jira/browse/SPARK-27382" target="_blank" rel="noopener">[ SPARK-27382 ]</a></td><td>åœ¨HiveExternalCatalogVersionsSuiteä¸­æ›´æ–°Spark 2.4.xæµ‹è¯•</td></tr></tbody></table><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;Sparkå‘å¸ƒäº†æœ€æ–°çš„ç‰ˆæœ¬spark-2.4.2&lt;br&gt;æ ¹æ®å®˜ç½‘ä»‹ç»ï¼Œæ­¤ç‰ˆæœ¬å¯¹äºä½¿ç”¨spark2.4çš„ç”¨æˆ·æ¥è¯´å¸®åŠ©æ˜¯å·¨å¤§çš„&lt;/p&gt;&lt;h4 id=&quot;ç‰ˆæœ¬ä»‹ç»&quot;&gt;&lt;a href=&quot;#ç‰ˆæœ¬ä»‹ç»&quot; class=&quot;headerlink&quot; title=&quot;ç‰ˆæœ¬ä»‹ç»&quot;&gt;&lt;/a&gt;ç‰ˆæœ¬ä»‹ç»&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;/assets/blogImg/spark2.4.2_1.jpg&quot; alt=&quot;enter description here&quot;&gt;&lt;br&gt;Spark2.4.2æ˜¯ä¸€ä¸ªåŒ…å«ç¨³å®šæ€§ä¿®å¤çš„ç»´æŠ¤ç‰ˆæœ¬ã€‚ æ­¤ç‰ˆæœ¬åŸºäºSpark2.4ç»´æŠ¤åˆ†æ”¯ã€‚&lt;font color=&quot;#FF4500&quot;&gt; &lt;strong&gt;æˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‰€æœ‰2.4ç”¨æˆ·å‡çº§åˆ°æ­¤ç¨³å®šç‰ˆæœ¬ã€‚&lt;/strong&gt;&lt;/font&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>æˆ‘å¸Kafka+Flink+MySQLç”Ÿäº§å®Œæ•´æ¡ˆä¾‹ä»£ç </title>
    <link href="http://yoursite.com/2018/12/20/%E6%88%91%E5%8F%B8Kafka+Flink+MySQL%E7%94%9F%E4%BA%A7%E5%AE%8C%E6%95%B4%E6%A1%88%E4%BE%8B%E4%BB%A3%E7%A0%81/"/>
    <id>http://yoursite.com/2018/12/20/æˆ‘å¸Kafka+Flink+MySQLç”Ÿäº§å®Œæ•´æ¡ˆä¾‹ä»£ç /</id>
    <published>2018-12-19T16:00:00.000Z</published>
    <updated>2019-05-03T01:24:05.187Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --><font color="#FF4500"><br></font><h6 id="1-ç‰ˆæœ¬ä¿¡æ¯ï¼š"><a href="#1-ç‰ˆæœ¬ä¿¡æ¯ï¼š" class="headerlink" title="1.ç‰ˆæœ¬ä¿¡æ¯ï¼š"></a>1.ç‰ˆæœ¬ä¿¡æ¯ï¼š</h6><p>Flink Version:1.6.2<br>Kafka Version:0.9.0.0<br>MySQL Version:5.6.21</p><h6 id="2-Kafka-æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š-IP-TIME-URL-STATU-CODE-REFERER"><a href="#2-Kafka-æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š-IP-TIME-URL-STATU-CODE-REFERER" class="headerlink" title="2.Kafka æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š[IP TIME URL STATU_CODE REFERER]"></a>2.Kafka æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š[IP TIME URL STATU_CODE REFERER]</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.74.103.143    2018-12-20 18:12:00  &quot;GET /class/130.html HTTP/1.1&quot;     404 https://search.yahoo.com/search?p=Flinkå®æˆ˜</span><br></pre></td></tr></table></figure><a id="more"></a><h6 id="3-å·¥ç¨‹pom-xml"><a href="#3-å·¥ç¨‹pom-xml" class="headerlink" title="3.å·¥ç¨‹pom.xml"></a>3.å·¥ç¨‹pom.xml</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&lt;scala.version&gt;2.11.8&lt;/scala.version&gt;</span><br><span class="line">&lt;flink.version&gt;1.6.2&lt;/flink.version&gt;</span><br><span class="line"> &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;flink-java&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;flink-streaming-java_2.11&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;flink-clients_2.11&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;!--Flink-Kafka --&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;flink-connector-kafka-0.9_2.11&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;mysql&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;5.1.39&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>4.sConfç±» å®šä¹‰ä¸MySQLè¿æ¥çš„JDBCçš„å‚æ•°<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">package com.soul.conf;</span><br><span class="line">/**</span><br><span class="line"> * @author è‹¥æ³½æ•°æ®soulChun</span><br><span class="line"> * @create 2018-12-20-15:11</span><br><span class="line"> */</span><br><span class="line">public class sConf &#123;</span><br><span class="line">    public static final String USERNAME = &quot;root&quot;;</span><br><span class="line">    public static final String PASSWORD = &quot;www.ruozedata.com&quot;;</span><br><span class="line">    public static final String DRIVERNAME = &quot;com.mysql.jdbc.Driver&quot;;</span><br><span class="line">    public static final String URL = &quot;jdbc:mysql://localhost:3306/soul&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h6 id="5-MySQLSlinkç±»"><a href="#5-MySQLSlinkç±»" class="headerlink" title="5.MySQLSlinkç±»"></a>5.MySQLSlinkç±»</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">package com.soul.kafka;</span><br><span class="line">import com.soul.conf.sConf;</span><br><span class="line">import org.apache.flink.api.java.tuple.Tuple5;</span><br><span class="line">import org.apache.flink.configuration.Configuration;</span><br><span class="line">import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;</span><br><span class="line">import java.sql.Connection;</span><br><span class="line">import java.sql.DriverManager;</span><br><span class="line">import java.sql.PreparedStatement;</span><br><span class="line">/**</span><br><span class="line"> * @author è‹¥æ³½æ•°æ®soulChun</span><br><span class="line"> * @create 2018-12-20-15:09</span><br><span class="line"> */</span><br><span class="line">public class MySQLSink extends RichSinkFunction&lt;Tuple5&lt;String, String, String, String, String&gt;&gt; &#123;</span><br><span class="line">    private static final long serialVersionUID = 1L;</span><br><span class="line">    private Connection connection;</span><br><span class="line">    private PreparedStatement preparedStatement;</span><br><span class="line">    public void invoke(Tuple5&lt;String, String, String, String, String&gt; value) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            if (connection == null) &#123;</span><br><span class="line">                Class.forName(sConf.DRIVERNAME);</span><br><span class="line">                connection = DriverManager.getConnection(sConf.URL, sConf.USERNAME, sConf.PASSWORD);</span><br><span class="line">            &#125;</span><br><span class="line">            String sql = &quot;insert into log_info (ip,time,courseid,status_code,referer) values (?,?,?,?,?)&quot;;</span><br><span class="line">            preparedStatement = connection.prepareStatement(sql);</span><br><span class="line">            preparedStatement.setString(1, value.f0);</span><br><span class="line">            preparedStatement.setString(2, value.f1);</span><br><span class="line">            preparedStatement.setString(3, value.f2);</span><br><span class="line">            preparedStatement.setString(4, value.f3);</span><br><span class="line">            preparedStatement.setString(5, value.f4);</span><br><span class="line">            System.out.println(&quot;Start insert&quot;);</span><br><span class="line">            preparedStatement.executeUpdate();</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    public void open(Configuration parms) throws Exception &#123;</span><br><span class="line">        Class.forName(sConf.DRIVERNAME);</span><br><span class="line">        connection = DriverManager.getConnection(sConf.URL, sConf.USERNAME, sConf.PASSWORD);</span><br><span class="line">    &#125;</span><br><span class="line">    public void close() throws Exception &#123;</span><br><span class="line">        if (preparedStatement != null) &#123;</span><br><span class="line">            preparedStatement.close();</span><br><span class="line">        &#125;</span><br><span class="line">        if (connection != null) &#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="6-æ•°æ®æ¸…æ´—æ—¥æœŸå·¥å…·ç±»"><a href="#6-æ•°æ®æ¸…æ´—æ—¥æœŸå·¥å…·ç±»" class="headerlink" title="6.æ•°æ®æ¸…æ´—æ—¥æœŸå·¥å…·ç±»"></a>6.æ•°æ®æ¸…æ´—æ—¥æœŸå·¥å…·ç±»</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">package com.soul.utils;</span><br><span class="line">import org.apache.commons.lang3.time.FastDateFormat;</span><br><span class="line">import java.util.Date;</span><br><span class="line">/**</span><br><span class="line"> * @author soulChun</span><br><span class="line"> * @create 2018-12-19-18:44</span><br><span class="line"> */</span><br><span class="line">public class DateUtils &#123;</span><br><span class="line">    private static FastDateFormat SOURCE_FORMAT = FastDateFormat.getInstance(&quot;yyyy-MM-dd HH:mm:ss&quot;);</span><br><span class="line">    private static FastDateFormat TARGET_FORMAT = FastDateFormat.getInstance(&quot;yyyyMMddHHmmss&quot;);</span><br><span class="line">    public static Long  getTime(String  time) throws Exception&#123;</span><br><span class="line">        return SOURCE_FORMAT.parse(time).getTime();</span><br><span class="line">    &#125;</span><br><span class="line">    public static String parseMinute(String time) throws  Exception&#123;</span><br><span class="line">        return TARGET_FORMAT.format(new Date(getTime(time)));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    //æµ‹è¯•ä¸€ä¸‹</span><br><span class="line">    public static void main(String[] args) throws Exception&#123;</span><br><span class="line">        String time = &quot;2018-12-19 18:55:00&quot;;</span><br><span class="line">        System.out.println(parseMinute(time));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="7-MySQLå»ºè¡¨"><a href="#7-MySQLå»ºè¡¨" class="headerlink" title="7.MySQLå»ºè¡¨"></a>7.MySQLå»ºè¡¨</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">create table log_info(</span><br><span class="line">ID INT NOT NULL AUTO_INCREMENT,</span><br><span class="line">IP VARCHAR(50),</span><br><span class="line">TIME VARCHAR(50),</span><br><span class="line">CourseID VARCHAR(10),</span><br><span class="line">Status_Code VARCHAR(10),</span><br><span class="line">Referer VARCHAR(100),</span><br><span class="line">PRIMARY KEY ( ID )</span><br><span class="line">)ENGINE=InnoDB DEFAULT CHARSET=utf8;</span><br></pre></td></tr></table></figure><h6 id="8-ä¸»ç¨‹åºï¼š"><a href="#8-ä¸»ç¨‹åºï¼š" class="headerlink" title="8.ä¸»ç¨‹åºï¼š"></a>8.ä¸»ç¨‹åºï¼š</h6><p>ä¸»è¦æ˜¯å°†timeçš„æ ¼å¼è½¬æˆyyyyMMddHHmmss,</p><p>è¿˜æœ‰å–URLä¸­çš„è¯¾ç¨‹IDï¼Œå°†ä¸æ˜¯/classå¼€å¤´çš„è¿‡æ»¤æ‰ã€‚<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">package com.soul.kafka;</span><br><span class="line">import com.soul.utils.DateUtils;</span><br><span class="line">import org.apache.flink.api.common.functions.FilterFunction;</span><br><span class="line">import org.apache.flink.api.common.functions.MapFunction;</span><br><span class="line">import org.apache.flink.api.common.serialization.SimpleStringSchema;</span><br><span class="line">import org.apache.flink.api.java.tuple.Tuple5;</span><br><span class="line">import org.apache.flink.streaming.api.TimeCharacteristic;</span><br><span class="line">import org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line">import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line">import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09;</span><br><span class="line">import java.util.Properties;</span><br><span class="line">/**</span><br><span class="line"> * @author soulChun</span><br><span class="line"> * @create 2018-12-19-17:23</span><br><span class="line"> */</span><br><span class="line">public class FlinkCleanKafka &#123;</span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.enableCheckpointing(5000);</span><br><span class="line">        Properties properties = new Properties();</span><br><span class="line">        properties.setProperty(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);//kafkaçš„èŠ‚ç‚¹çš„IPæˆ–è€…hostNameï¼Œå¤šä¸ªä½¿ç”¨é€—å·åˆ†éš”</span><br><span class="line">        properties.setProperty(&quot;zookeeper.connect&quot;, &quot;localhost:2181&quot;);//zookeeperçš„èŠ‚ç‚¹çš„IPæˆ–è€…hostNameï¼Œå¤šä¸ªä½¿ç”¨é€—å·è¿›è¡Œåˆ†éš”</span><br><span class="line">        properties.setProperty(&quot;group.id&quot;, &quot;test-consumer-group&quot;);//flink consumer flinkçš„æ¶ˆè´¹è€…çš„group.id</span><br><span class="line">        FlinkKafkaConsumer09&lt;String&gt; myConsumer = new FlinkKafkaConsumer09&lt;String&gt;(&quot;imooc_topic&quot;, new SimpleStringSchema(), properties);</span><br><span class="line">        DataStream&lt;String&gt; stream = env.addSource(myConsumer);</span><br><span class="line">//        stream.print().setParallelism(2);</span><br><span class="line">        DataStream CleanData = stream.map(new MapFunction&lt;String, Tuple5&lt;String, String, String, String, String&gt;&gt;() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public Tuple5&lt;String, String, String, String, String&gt; map(String value) throws Exception &#123;</span><br><span class="line">                String[] data = value.split(&quot;\\\t&quot;);</span><br><span class="line">                String CourseID = null;</span><br><span class="line">                String url = data[2].split(&quot;\\ &quot;)[2];</span><br><span class="line">                if (url.startsWith(&quot;/class&quot;)) &#123;</span><br><span class="line">                    String CourseHTML = url.split(&quot;\\/&quot;)[2];</span><br><span class="line">                    CourseID = CourseHTML.substring(0, CourseHTML.lastIndexOf(&quot;.&quot;));</span><br><span class="line">//                    System.out.println(CourseID);</span><br><span class="line">                &#125;</span><br><span class="line">                return Tuple5.of(data[0], DateUtils.parseMinute(data[1]), CourseID, data[3], data[4]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).filter(new FilterFunction&lt;Tuple5&lt;String, String, String, String, String&gt;&gt;() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public boolean filter(Tuple5&lt;String, String, String, String, String&gt; value) throws Exception &#123;</span><br><span class="line">                return value.f2 != null;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        CleanData.addSink(new MySQLSink());</span><br><span class="line">        env.execute(&quot;Flink kafka&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h6 id="9-å¯åŠ¨ä¸»ç¨‹åºï¼ŒæŸ¥çœ‹MySQLè¡¨æ•°æ®åœ¨é€’å¢"><a href="#9-å¯åŠ¨ä¸»ç¨‹åºï¼ŒæŸ¥çœ‹MySQLè¡¨æ•°æ®åœ¨é€’å¢" class="headerlink" title="9.å¯åŠ¨ä¸»ç¨‹åºï¼ŒæŸ¥çœ‹MySQLè¡¨æ•°æ®åœ¨é€’å¢"></a>9.å¯åŠ¨ä¸»ç¨‹åºï¼ŒæŸ¥çœ‹MySQLè¡¨æ•°æ®åœ¨é€’å¢</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select count(*) from log_info;</span><br><span class="line">+----------+</span><br><span class="line">| count(*) |</span><br><span class="line">+----------+</span><br><span class="line">|    15137 |</span><br><span class="line">+----------+</span><br></pre></td></tr></table></figure><p>Kafkaè¿‡æ¥çš„æ¶ˆæ¯æ˜¯æˆ‘æ¨¡æ‹Ÿçš„ï¼Œä¸€åˆ†é’Ÿäº§ç”Ÿ100æ¡ã€‚</p><p>ä»¥ä¸Šæ˜¯æˆ‘å¸ç”Ÿäº§é¡¹ç›®ä»£ç çš„æŠ½å–å‡ºæ¥çš„æ¡ˆä¾‹ä»£ç V1ã€‚ç¨åè¿˜æœ‰WaterMarkä¹‹ç±»ä¼šåšåˆ†äº«ã€‚</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --&gt;&lt;font color=&quot;#FF4500&quot;&gt;&lt;br&gt;&lt;/font&gt;&lt;h6 id=&quot;1-ç‰ˆæœ¬ä¿¡æ¯ï¼š&quot;&gt;&lt;a href=&quot;#1-ç‰ˆæœ¬ä¿¡æ¯ï¼š&quot; class=&quot;headerlink&quot; title=&quot;1.ç‰ˆæœ¬ä¿¡æ¯ï¼š&quot;&gt;&lt;/a&gt;1.ç‰ˆæœ¬ä¿¡æ¯ï¼š&lt;/h6&gt;&lt;p&gt;Flink Version:1.6.2&lt;br&gt;Kafka Version:0.9.0.0&lt;br&gt;MySQL Version:5.6.21&lt;/p&gt;&lt;h6 id=&quot;2-Kafka-æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š-IP-TIME-URL-STATU-CODE-REFERER&quot;&gt;&lt;a href=&quot;#2-Kafka-æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š-IP-TIME-URL-STATU-CODE-REFERER&quot; class=&quot;headerlink&quot; title=&quot;2.Kafka æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š[IP TIME URL STATU_CODE REFERER]&quot;&gt;&lt;/a&gt;2.Kafka æ¶ˆæ¯æ ·ä¾‹åŠæ ¼å¼ï¼š[IP TIME URL STATU_CODE REFERER]&lt;/h6&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1.74.103.143    2018-12-20 18:12:00  &amp;quot;GET /class/130.html HTTP/1.1&amp;quot;     404 https://search.yahoo.com/search?p=Flinkå®æˆ˜&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Flink" scheme="http://yoursite.com/categories/Flink/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Sparkåœ¨æºç¨‹çš„å®è·µï¼ˆäºŒï¼‰</title>
    <link href="http://yoursite.com/2018/12/16/Spark%E5%9C%A8%E6%90%BA%E7%A8%8B%E7%9A%84%E5%AE%9E%E8%B7%B5%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>http://yoursite.com/2018/12/16/Sparkåœ¨æºç¨‹çš„å®è·µï¼ˆäºŒï¼‰/</id>
    <published>2018-12-15T16:00:00.000Z</published>
    <updated>2019-05-22T12:19:20.084Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed May 22 2019 20:21:18 GMT+0800 (GMT+08:00) --><p>ä»¥ä¸‹å†…å®¹æ¥è‡ªç¬¬ä¸‰å±Šæºç¨‹å¤§æ•°æ®æ²™é¾™</p><h3 id="ä¸ƒã€é‡åˆ°çš„é—®é¢˜"><a href="#ä¸ƒã€é‡åˆ°çš„é—®é¢˜" class="headerlink" title="ä¸ƒã€é‡åˆ°çš„é—®é¢˜"></a>ä¸ƒã€é‡åˆ°çš„é—®é¢˜</h3><h5 id="orc-split"><a href="#orc-split" class="headerlink" title="orc split"></a>orc split</h5><p>Sparkè¯»å–Hiveè¡¨ç”¨çš„å„ä¸ªæ–‡ä»¶æ ¼å¼çš„InuptFormatï¼Œè®¡ç®—è¯»å–è¡¨éœ€è¦çš„taskæ•°é‡ä¾èµ–äºInputFormat#getSplits<br>ç”±äºå¤§éƒ¨åˆ†è¡¨çš„å­˜å‚¨æ ¼å¼ä¸»è¦ä½¿ç”¨çš„æ˜¯orcï¼Œå½“ä¸€ä¸ªorcæ–‡ä»¶è¶…è¿‡256MBï¼Œsplitç®—æ³•å¹¶è¡Œå»è¯»å–orcå…ƒæ•°æ®ï¼Œæœ‰æ—¶å€™Driverå†…å­˜é£™å‡ï¼ŒOOM crashï¼ŒFull GCå¯¼è‡´network timeoutï¼Œspark context stop<br>Hiveè¯»è¿™äº›å¤§è¡¨ä¸ºä½•æ²¡æœ‰é—®é¢˜ï¼Ÿå› ä¸ºHiveé»˜è®¤ä½¿ç”¨çš„æ˜¯CombineHiveInputFormatï¼Œsplitæ˜¯åŸºäºæ–‡ä»¶å¤§å°çš„ã€‚<br>Sparkä¹Ÿéœ€è¦å®ç°ç±»ä¼¼äºHiveçš„CombineInputFormatï¼Œè¿˜èƒ½è§£å†³å°æ–‡ä»¶è¿‡å¤šå¯¼è‡´æäº¤taskæ•°é‡è¿‡å¤šçš„é—®é¢˜ã€‚<br>Executor Container killed<br>Executor : Container killed by YARN for exceeding memory limits. 13.9 GB of 12 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead<br><a id="more"></a></p><h5 id="åŸå› ï¼š"><a href="#åŸå› ï¼š" class="headerlink" title="åŸå› ï¼š"></a>åŸå› ï¼š</h5><p>1.Shuffle Readæ—¶nettyå †å¤–å†…å­˜çš„ä½¿ç”¨<br>2.Window function spill thresholdè¿‡å°ï¼Œå¯¼è‡´æ¯4096æ¡æˆ–è€…64MBä¸ºä¸€ä¸ªæ–‡ä»¶å†™åˆ°ç£ç›˜<br>å¤–éƒ¨æ’åºåŒæ—¶æ‰“å¼€æ¯ä¸ªæ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶å ç”¨1MBçš„å †å¤–å†…å­˜ï¼Œå¯¼è‡´containerä½¿ç”¨çš„å†…å­˜è¿œè¶…è¿‡ç”³è¯·çš„å†…å­˜ï¼Œé‚è¢«yarn killã€‚<br>è§£å†³ï¼š<br>Patchï¼š<br>[SPARK-19659] Fetch big blocks to disk when shuffle-read<br>[SPARK-21369][CORE] Donâ€™t use Scala Tuple2 in common/network-<em><br>å‚æ•°ï¼šspark.reducer.maxReqSizeShuffleToMem=209715200<br>Patchï¼š<br>[SPARK-21595]Separate thresholds for buffering and spilling in ExternalAppendOnlyUnsafeRowArray<br>å‚æ•°ï¼š<br>spark.sql.windowExec.buffer.in.memory.threshold=4096<br>spark.sql.windowExec.buffer.spill.threshold= 1024 </em>1024 * 1024 / 2</p><h5 id="å°æ–‡ä»¶é—®é¢˜"><a href="#å°æ–‡ä»¶é—®é¢˜" class="headerlink" title="å°æ–‡ä»¶é—®é¢˜"></a>å°æ–‡ä»¶é—®é¢˜</h5><p>Sparkå†™æ•°æ®æ—¶ç”Ÿæˆå¾ˆå¤šå°æ–‡ä»¶ï¼Œå¯¹NameNodeäº§ç”Ÿå·¨å¤§çš„å‹åŠ›ï¼Œåœ¨ä¸€å¼€å§‹Sparkç°åº¦ä¸Šçº¿çš„æ—¶å€™ï¼Œæ–‡ä»¶æ•°å’ŒBlockæ•°é£™å‡ï¼Œæ–‡ä»¶å˜å°å¯¼è‡´å‹ç¼©ç‡é™ä½ï¼Œå®¹é‡ä¹Ÿè·Ÿç€ä¸Šå»ã€‚</p><h5 id="ç§»æ¤Hive-MergeFileTaskçš„å®ç°"><a href="#ç§»æ¤Hive-MergeFileTaskçš„å®ç°" class="headerlink" title="ç§»æ¤Hive MergeFileTaskçš„å®ç°"></a>ç§»æ¤Hive MergeFileTaskçš„å®ç°</h5><p>åœ¨Sparkæœ€åå†™ç›®æ ‡è¡¨çš„é˜¶æ®µè¿½åŠ å…¥äº†ä¸€ä¸ªMergeFileTaskï¼Œå‚è€ƒäº†Hiveçš„å®ç°<br>org.apache.hadoop.hive.ql.io.merge.MergeFileTask<br>org.apache.hadoop.hive.ql.exec.OrcFileMergeOperator</p><h5 id="æ— æ•°æ®çš„æƒ…å†µä¸‹ä¸åˆ›å»ºç©ºæ–‡ä»¶"><a href="#æ— æ•°æ®çš„æƒ…å†µä¸‹ä¸åˆ›å»ºç©ºæ–‡ä»¶" class="headerlink" title="æ— æ•°æ®çš„æƒ…å†µä¸‹ä¸åˆ›å»ºç©ºæ–‡ä»¶"></a>æ— æ•°æ®çš„æƒ…å†µä¸‹ä¸åˆ›å»ºç©ºæ–‡ä»¶</h5><p>[SPARK-21435][SQL]<br>Empty files should be skipped while write to file</p><h3 id="å…«ã€ä¼˜åŒ–"><a href="#å…«ã€ä¼˜åŒ–" class="headerlink" title="å…«ã€ä¼˜åŒ–"></a>å…«ã€ä¼˜åŒ–</h3><p>1.æŸ¥è¯¢åˆ†åŒºè¡¨æ—¶æ”¯æŒbroadcast joinï¼ŒåŠ é€ŸæŸ¥è¯¢<br>2.å‡å°‘Broadcast joinçš„å†…å­˜å‹åŠ› SPARK-22170<br>3.Fetchå¤±è´¥åèƒ½å¿«é€Ÿå¤±è´¥ï¼Œä»¥å…ä½œä¸šå¡å‡ ä¸ªå°æ—¶ SPARK-19753<br>4.Spark Thrift Serverç¨³å®šæ€§<br>ç»å¸¸æŒ‚æ‰ï¼Œæ—¥å¿—é‡Œå¼‚å¸¸ï¼Œmore than one active taskSet for stage<br>Apply SPARK-23433ä»æœ‰å°‘æ•°æŒ‚æ‰çš„æƒ…å†µï¼Œ<br>æäº¤SPARK-24677åˆ°ç¤¾åŒºï¼Œä¿®å¤ä¹‹<br>5.ä½œä¸šhangä½ SPARK-21834 SPARK-19326 SPARK-11334</p><h3 id="ä¹ã€æœªæ¥è®¡åˆ’"><a href="#ä¹ã€æœªæ¥è®¡åˆ’" class="headerlink" title="ä¹ã€æœªæ¥è®¡åˆ’"></a>ä¹ã€æœªæ¥è®¡åˆ’</h3><h5 id="è‡ªåŠ¨è°ƒä¼˜å†…å­˜"><a href="#è‡ªåŠ¨è°ƒä¼˜å†…å­˜" class="headerlink" title="è‡ªåŠ¨è°ƒä¼˜å†…å­˜"></a>è‡ªåŠ¨è°ƒä¼˜å†…å­˜</h5><p>æ‰‹æœºspark driverå’Œexecutorå†…å­˜ä½¿ç”¨æƒ…å†µ<br>æ ¹æ®ä½œä¸šå†å²çš„å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œåœ¨è°ƒåº¦ç³»ç»Ÿç«¯è‡ªåŠ¨è®¾ç½®åˆé€‚çš„å†…å­˜<br><a href="https://github.com/uber-common/jvm-profiler" target="_blank" rel="noopener">https://github.com/uber-common/jvm-profiler</a></p><h5 id="spark-adaptive"><a href="#spark-adaptive" class="headerlink" title="spark adaptive"></a>spark adaptive</h5><p>åŠ¨æ€è°ƒæ•´æ‰§è¡Œè®¡åˆ’ SortMergeJoinè½¬åŒ–ä¸ºBroadcastHashJoin<br>åŠ¨æ€å¤„ç†æ•°æ®å€¾æ–œ<br><a href="https://issues.apache.org/jira/browse/SPARK-23128" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/SPARK-23128</a><br><a href="https://github.com/Intel-bigdata/spark-adaptive" target="_blank" rel="noopener">https://github.com/Intel-bigdata/spark-adaptive</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed May 22 2019 20:21:18 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;ä»¥ä¸‹å†…å®¹æ¥è‡ªç¬¬ä¸‰å±Šæºç¨‹å¤§æ•°æ®æ²™é¾™&lt;/p&gt;&lt;h3 id=&quot;ä¸ƒã€é‡åˆ°çš„é—®é¢˜&quot;&gt;&lt;a href=&quot;#ä¸ƒã€é‡åˆ°çš„é—®é¢˜&quot; class=&quot;headerlink&quot; title=&quot;ä¸ƒã€é‡åˆ°çš„é—®é¢˜&quot;&gt;&lt;/a&gt;ä¸ƒã€é‡åˆ°çš„é—®é¢˜&lt;/h3&gt;&lt;h5 id=&quot;orc-split&quot;&gt;&lt;a href=&quot;#orc-split&quot; class=&quot;headerlink&quot; title=&quot;orc split&quot;&gt;&lt;/a&gt;orc split&lt;/h5&gt;&lt;p&gt;Sparkè¯»å–Hiveè¡¨ç”¨çš„å„ä¸ªæ–‡ä»¶æ ¼å¼çš„InuptFormatï¼Œè®¡ç®—è¯»å–è¡¨éœ€è¦çš„taskæ•°é‡ä¾èµ–äºInputFormat#getSplits&lt;br&gt;ç”±äºå¤§éƒ¨åˆ†è¡¨çš„å­˜å‚¨æ ¼å¼ä¸»è¦ä½¿ç”¨çš„æ˜¯orcï¼Œå½“ä¸€ä¸ªorcæ–‡ä»¶è¶…è¿‡256MBï¼Œsplitç®—æ³•å¹¶è¡Œå»è¯»å–orcå…ƒæ•°æ®ï¼Œæœ‰æ—¶å€™Driverå†…å­˜é£™å‡ï¼ŒOOM crashï¼ŒFull GCå¯¼è‡´network timeoutï¼Œspark context stop&lt;br&gt;Hiveè¯»è¿™äº›å¤§è¡¨ä¸ºä½•æ²¡æœ‰é—®é¢˜ï¼Ÿå› ä¸ºHiveé»˜è®¤ä½¿ç”¨çš„æ˜¯CombineHiveInputFormatï¼Œsplitæ˜¯åŸºäºæ–‡ä»¶å¤§å°çš„ã€‚&lt;br&gt;Sparkä¹Ÿéœ€è¦å®ç°ç±»ä¼¼äºHiveçš„CombineInputFormatï¼Œè¿˜èƒ½è§£å†³å°æ–‡ä»¶è¿‡å¤šå¯¼è‡´æäº¤taskæ•°é‡è¿‡å¤šçš„é—®é¢˜ã€‚&lt;br&gt;Executor Container killed&lt;br&gt;Executor : Container killed by YARN for exceeding memory limits. 13.9 GB of 12 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead&lt;br&gt;
    
    </summary>
    
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>Sparkåœ¨æºç¨‹çš„å®è·µï¼ˆä¸€ï¼‰</title>
    <link href="http://yoursite.com/2018/12/09/Spark%E5%9C%A8%E6%90%BA%E7%A8%8B%E7%9A%84%E5%AE%9E%E8%B7%B5%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://yoursite.com/2018/12/09/Sparkåœ¨æºç¨‹çš„å®è·µï¼ˆä¸€ï¼‰/</id>
    <published>2018-12-08T16:00:00.000Z</published>
    <updated>2019-05-21T12:44:42.154Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue May 21 2019 20:46:50 GMT+0800 (GMT+08:00) --><a id="more"></a><h3 id="ä¸€ã€Sparkåœ¨æºç¨‹åº”ç”¨çš„ç°çŠ¶"><a href="#ä¸€ã€Sparkåœ¨æºç¨‹åº”ç”¨çš„ç°çŠ¶" class="headerlink" title="ä¸€ã€Sparkåœ¨æºç¨‹åº”ç”¨çš„ç°çŠ¶"></a>ä¸€ã€Sparkåœ¨æºç¨‹åº”ç”¨çš„ç°çŠ¶</h3><h6 id="é›†ç¾¤è§„æ¨¡ï¼š"><a href="#é›†ç¾¤è§„æ¨¡ï¼š" class="headerlink" title="é›†ç¾¤è§„æ¨¡ï¼š"></a>é›†ç¾¤è§„æ¨¡ï¼š</h6><p>å¹³å‡æ¯å¤©MRä»»åŠ¡æ•°ï¼š30W+</p><h6 id="å¼€å‘å¹³å°ï¼š"><a href="#å¼€å‘å¹³å°ï¼š" class="headerlink" title="å¼€å‘å¹³å°ï¼š"></a>å¼€å‘å¹³å°ï¼š</h6><p>è°ƒåº¦ç³»ç»Ÿè¿è¡Œçš„ä»»åŠ¡æ•°ï¼š10W+<br>æ¯å¤©è¿è¡Œä»»åŠ¡å®ä¾‹æ•°ï¼š23W+<br>ETL/è®¡ç®—ä»»åŠ¡ï¼š~58%</p><h6 id="æŸ¥è¯¢å¹³å°"><a href="#æŸ¥è¯¢å¹³å°" class="headerlink" title="æŸ¥è¯¢å¹³å°:"></a>æŸ¥è¯¢å¹³å°:</h6><p>adhocæŸ¥è¯¢ï¼š2W+<br>æ”¯æŒSpark/Hive/Presto<br><img src="/assets/blogImg/1209_1.png" alt="enter description here"></p><h3 id="äºŒã€Hiveä¸Sparkçš„åŒºåˆ«"><a href="#äºŒã€Hiveä¸Sparkçš„åŒºåˆ«" class="headerlink" title="äºŒã€Hiveä¸Sparkçš„åŒºåˆ«"></a>äºŒã€Hiveä¸Sparkçš„åŒºåˆ«</h3><h6 id="Hiveï¼š"><a href="#Hiveï¼š" class="headerlink" title="Hiveï¼š"></a>Hiveï¼š</h6><p>ä¼˜ç‚¹ï¼šè¿è¡Œç¨³å®šï¼Œå®¢æˆ·ç«¯å†…å­˜æ¶ˆè€—å°ã€‚<br>å­˜åœ¨é—®é¢˜ï¼šç”Ÿæˆå¤šä¸ªMapReduceä½œä¸šï¼›ä¸­é—´ç»“æœè½åœ°ï¼ŒIOå¼€é”€å¤§ï¼›é¢‘ç¹ç”³è¯·å’Œé‡Šæ”¾containerï¼Œèµ„æºæ²¡æœ‰åˆç†å……åˆ†åˆ©ç”¨</p><h6 id="Sparkï¼š"><a href="#Sparkï¼š" class="headerlink" title="Sparkï¼š"></a>Sparkï¼š</h6><p>å¿«ï¼šé«˜æ•ˆçš„DAGæ‰§è¡Œå¼•æ“ï¼Œå¯ä»¥åŸºäºå†…å­˜æ¥é«˜æ•ˆçš„å¤„ç†æ•°æ®æµï¼ŒèŠ‚çœå¤§é‡IOå¼€é”€<br>é€šç”¨æ€§ï¼šSparkSQLèƒ½ç›´æ¥ä½¿ç”¨HiveQLè¯­æ³•ï¼ŒHive Metastoreï¼ŒSerdesï¼ŒUDFs<br><img src="/assets/blogImg/1209_2.png" alt="enter description here"></p><h3 id="ä¸‰ã€è¿ç§»SparkSQLçš„æŒ‘æˆ˜"><a href="#ä¸‰ã€è¿ç§»SparkSQLçš„æŒ‘æˆ˜" class="headerlink" title="ä¸‰ã€è¿ç§»SparkSQLçš„æŒ‘æˆ˜"></a>ä¸‰ã€è¿ç§»SparkSQLçš„æŒ‘æˆ˜</h3><h6 id="å…¼å®¹æ€§ï¼š"><a href="#å…¼å®¹æ€§ï¼š" class="headerlink" title="å…¼å®¹æ€§ï¼š"></a>å…¼å®¹æ€§ï¼š</h6><p>HiveåŸå…ˆçš„æƒé™æ§åˆ¶<br>SQLè¯­æ³•ï¼ŒUDFå’ŒHiveçš„å…¼å®¹æ€§</p><h6 id="ç¨³å®šæ€§ï¼š"><a href="#ç¨³å®šæ€§ï¼š" class="headerlink" title="ç¨³å®šæ€§ï¼š"></a>ç¨³å®šæ€§ï¼š</h6><p>è¿ç§»é€æ˜ï¼Œä½ä¼˜å…ˆçº§ç”¨æˆ·æ— æ„ŸçŸ¥<br>ç›‘æ§ä½œä¸šè¿ç§»åæˆåŠŸç‡åŠè¿è¡Œæ—¶é•¿å¯¹æ¯”</p><h6 id="å‡†ç¡®æ€§ï¼š"><a href="#å‡†ç¡®æ€§ï¼š" class="headerlink" title="å‡†ç¡®æ€§ï¼š"></a>å‡†ç¡®æ€§ï¼š</h6><p>æ•°æ®ä¸€è‡´<br>åŠŸèƒ½å¢å¼ºï¼š<br>ç”¨æˆ·ä½“éªŒï¼Œæ˜¯å¦æ˜“ç”¨ï¼ŒæŠ¥é”™ä¿¡æ¯æ˜¯å¦å¯è¯»<br>æ½œåœ¨Bug<br>å‘¨è¾¹ç³»ç»Ÿé…åˆæ”¹é€ <br>è¡€ç¼˜æ”¶é›†</p><h3 id="å››ã€å…¼å®¹æ€§æ”¹é€ "><a href="#å››ã€å…¼å®¹æ€§æ”¹é€ " class="headerlink" title="å››ã€å…¼å®¹æ€§æ”¹é€ "></a>å››ã€å…¼å®¹æ€§æ”¹é€ </h3><h6 id="ç§»æ¤hiveæƒé™"><a href="#ç§»æ¤hiveæƒé™" class="headerlink" title="ç§»æ¤hiveæƒé™"></a>ç§»æ¤hiveæƒé™</h6><p>Sparkæ²¡æœ‰æƒé™è®¤è¯æ¨¡å—ï¼Œå¯å¯¹ä»»æ„è¡¨è¿›è¡ŒæŸ¥è¯¢ï¼Œæœ‰å®‰å…¨éšæ‚£<br>éœ€è¦ä¸Hiveå…±äº«åŒä¸€å¥—æƒé™</p><h6 id="æ–¹æ¡ˆï¼š"><a href="#æ–¹æ¡ˆï¼š" class="headerlink" title="æ–¹æ¡ˆï¼š"></a>æ–¹æ¡ˆï¼š</h6><p>æ‰§è¡ŒSQLæ—¶ï¼Œå¯¹SQLè§£æå¾—åˆ°LogicalPlanï¼Œå¯¹LogicalPlanè¿›è¡Œéå†ï¼Œæå–è¯»å–çš„è¡¨åŠå†™å…¥çš„è¡¨ï¼Œè°ƒç”¨Hvieçš„è®¤è¯æ–¹æ³•è¿›è¡Œæ£€æŸ¥ï¼Œå¦‚æœæœ‰æƒé™åˆ™ç»§ç»­æ‰§è¡Œï¼Œå¦åˆ™æ‹’ç»è¯¥ç”¨æˆ·çš„æ“ä½œã€‚<br>SQLè¯­æ³•å’Œhiveå…¼å®¹<br>Sparkåˆ›å»ºçš„æŸäº›è§†å›¾ï¼Œåœ¨HiveæŸ¥è¯¢æ—¶æŠ¥é”™ï¼ŒSparkåˆ›å»ºçš„è§†å›¾ä¸ä¼šå¯¹SQLè¿›è¡Œå±•å¼€ï¼Œè§†å›¾å®šä¹‰æ²¡æœ‰å½“å‰çš„DBä¿¡æ¯ï¼ŒHiveä¸å…¼å®¹è¯»å–è¿™æ ·çš„è§†å›¾</p><h6 id="æ–¹æ¡ˆï¼šã€"><a href="#æ–¹æ¡ˆï¼šã€" class="headerlink" title="æ–¹æ¡ˆï¼šã€"></a>æ–¹æ¡ˆï¼šã€</h6><p>ä¿æŒä¸Hiveä¸€è‡´ï¼Œåœ¨Sparkåˆ›å»ºå’Œä¿®æ”¹è§†å›¾æ—¶ï¼Œä½¿ç”¨hive cli driverå»æ‰§è¡Œcreate/alter view sql<br>UDFä¸hiveå…¼å®¹<br>UDFè®¡ç®—ç»“æœä¸ä¸€æ ·ï¼Œå³ä½¿æ˜¯æ­£å¸¸æ•°æ®ï¼ŒSparkè¿”å›nullï¼ŒHiveç»“æœæ­£ç¡®ï¼›å¼‚å¸¸æ•°æ®ï¼ŒSparkæŠ›exceptionå¯¼è‡´ä½œä¸šå¤±è´¥ï¼ŒHiveè¿”å›çš„nullã€‚</p><h6 id="æ–¹æ¡ˆï¼š-1"><a href="#æ–¹æ¡ˆï¼š-1" class="headerlink" title="æ–¹æ¡ˆï¼š"></a>æ–¹æ¡ˆï¼š</h6><p>Sparkå‡½æ•°ä¿®å¤ï¼Œæ¯”å¦‚roundå‡½æ•°<br>å°†hiveä¸€äº›å‡½æ•°ç§»æ¤ï¼Œå¹¶æ³¨å†Œæˆæ°¸ä¹…å‡½æ•°<br>æ•´ç†Sparkå’ŒHiveè¯­æ³•å’ŒUDFå·®å¼‚<br>äº”ã€ç¨³å®šæ€§å’Œå‡†ç¡®æ€§</p><h6 id="ç¨³å®šæ€§ï¼š-1"><a href="#ç¨³å®šæ€§ï¼š-1" class="headerlink" title="ç¨³å®šæ€§ï¼š"></a>ç¨³å®šæ€§ï¼š</h6><p>è¿ç§»é€æ˜ï¼šè°ƒåº¦ç³»ç»Ÿå¯¹ä½ä¼˜å…ˆçº§ä½œä¸šï¼ŒæŒ‰ä½œä¸šç²’åº¦åˆ‡æ¢æˆSparkæ‰§è¡Œï¼Œå¤±è´¥åå†åˆ‡æ¢æˆhive<br>ç°åº¦å˜æ›´ï¼Œå¤šç§å˜æ›´è§„åˆ™ï¼šæ”¯æŒå¤šç‰ˆæœ¬Sparkï¼Œè‡ªåŠ¨åˆ‡æ¢å¼•æ“ï¼ŒSpark v2 -&gt; Spark v1 -&gt; Hiveï¼›ç°åº¦æ¨é€å‚æ•°ï¼Œè°ƒä¼˜å‚æ•°ï¼ŒæŸäº›åŠŸèƒ½<br>ç›‘æ§ï¼šæ¯æ—¥ç»Ÿè®¡sparkå’Œhiveè¿è¡Œå¯¹æ¯”ï¼Œæ¯æ—¶æ”¶é›†ä½œä¸šç²’åº¦å¤±è´¥çš„Sparkä½œä¸šï¼Œåˆ†æå¤±è´¥åŸå› <br>å‡†ç¡®æ€§ï¼š<br>æ•°æ®è´¨é‡ç³»ç»Ÿï¼šæ ¡éªŒä»»åŠ¡ï¼Œæ£€æŸ¥æ•°æ®å‡†ç¡®æ€§</p><h3 id="å…­ã€åŠŸèƒ½å¢å¼º"><a href="#å…­ã€åŠŸèƒ½å¢å¼º" class="headerlink" title="å…­ã€åŠŸèƒ½å¢å¼º"></a>å…­ã€åŠŸèƒ½å¢å¼º</h3><h6 id="Spark-Thrift-Serverï¼š"><a href="#Spark-Thrift-Serverï¼š" class="headerlink" title="Spark Thrift Serverï¼š"></a>Spark Thrift Serverï¼š</h6><ul><li>1.åŸºäºdelegation tokençš„impersontion<br>Driverï¼š<br>ä¸ºä¸åŒçš„ç”¨æˆ·æ‹¿delegation tokenï¼Œå†™åˆ°stagingç›®å½•ï¼Œè®°å½•User-&gt;SQL-&gt;Jobæ˜ å°„å…³ç³»ï¼Œåˆ†å‘taskå¸¦ä¸Šå¯¹åº”çš„username<br>Executorï¼š<br>æ ¹æ®taskä¿¡æ¯å¸¦çš„usernameæ‰¾åˆ°stagingç›®å½•ä¸‹çš„tokenï¼ŒåŠ åˆ°å½“å‰proxy userçš„ugiï¼Œå®ç°impersonate</li><li>2.åŸºäºzookeeperçš„æœåŠ¡å‘ç°ï¼Œæ”¯æŒå¤šå°server<br>è¿™ä¸€å—ä¸»è¦ç§»æ¤äº†Hive zookeeperçš„å®ç°</li><li>3.é™åˆ¶å¤§æŸ¥è¯¢ä½œä¸šï¼Œé˜²æ­¢driver OOM<br>é™åˆ¶æ¯ä¸ªjobäº§ç”Ÿçš„taskæœ€å¤§æ•°é‡<br>é™åˆ¶æŸ¥è¯¢SQLçš„æœ€å¤§è¡Œæ•°ï¼Œå®¢æˆ·ç«¯æŸ¥è¯¢å¤§æ‰¹é‡æ•°æ®ï¼Œæ•°æ®æŒ¤å‹åœ¨Thrift Serverï¼Œå †å†…å†…å­˜é£™å‡ï¼Œå¼ºåˆ¶åœ¨åªæœ‰æŸ¥çš„SQLåŠ ä¸Šlimit<br>é™åˆ¶æŸ¥è¯¢SQLçš„ç»“æœé›†æ•°æ®å¤§å°</li><li>4.ç›‘æ§<br>å¯¹æ¯ä¸ªserverå®šæ—¶æŸ¥è¯¢ï¼Œæ£€æµ‹æ˜¯å¦å¯ç”¨<br>å¤šè¿è¡Œæ—¶é•¿è¾ƒä¹…çš„ä½œä¸šï¼Œä¸»åŠ¨kill<h6 id="ç”¨æˆ·ä½“éªŒ"><a href="#ç”¨æˆ·ä½“éªŒ" class="headerlink" title="ç”¨æˆ·ä½“éªŒ"></a>ç”¨æˆ·ä½“éªŒ</h6>ç”¨æˆ·çœ‹åˆ°çš„æ˜¯ç±»ä¼¼Hive MRè¿›åº¦çš„æ—¥å¿—ï¼ŒINFOçº§åˆ«æ—¥å¿—æ”¶é›†åˆ°ESï¼Œå¯ä¾›æ—¥å¿—çš„åˆ†æå’Œæ’æŸ¥é—®é¢˜<br>æ”¶é›†ç”Ÿæˆçš„è¡¨æˆ–è€…åˆ†åŒºçš„numRows numFile totalSizeï¼Œè¾“å‡ºåˆ°æ—¥å¿—<br>å¯¹ç®€å•çš„è¯­å¥ï¼Œå¦‚DDLè¯­å¥ï¼Œè‡ªåŠ¨ä½¿ç”¨â€“master=localæ–¹å¼å¯åŠ¨<h6 id="Combine-input-Format"><a href="#Combine-input-Format" class="headerlink" title="Combine input Format"></a>Combine input Format</h6>åœ¨HadoopTableReader#makeRDDForTableï¼Œæ‹¿åˆ°å¯¹åº”tableçš„InputFormatClassï¼Œè½¬æ¢æˆå¯¹åº”æ ¼å¼çš„CombineInputFormat<br>é€šè¿‡å¼€å…³æ¥å†³å®šæ˜¯å¦å¯ç”¨è¿™ä¸ªç‰¹æ€§<br>set spark.sql.combine.input.splits.enable=true<br>é€šè¿‡å‚æ•°æ¥è°ƒæ•´æ¯ä¸ªsplitçš„total input size<br>mapreduce.input.fileinputformat.split.maxsize=256MB <em>1024</em>1024<br>ä¹‹å‰driverè¯»å¤§è¡¨é«˜å³°æ—¶æ®µsplitéœ€è¦30åˆ†é’Ÿä¸æ­¢ï¼Œæ‰æŠŠä»»åŠ¡æäº¤ä¸Šï¼Œç°åœ¨åªè¦å‡ åˆ†é’Ÿå°±ç®—å¥½splitçš„æ•°é‡å¹¶æäº¤ä»»åŠ¡ï¼Œä¹Ÿè§£å†³äº†ä¸€äº›è¡¨ä¸å¤§ï¼Œå°æ–‡ä»¶å¤šï¼Œèƒ½åˆå¹¶åˆ°åŒä¸€ä¸ªtaskè¿›è¡Œè¯»å–</li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue May 21 2019 20:46:50 GMT+0800 (GMT+08:00) --&gt;
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>ä»£ç  | Sparkè¯»å–mongoDBæ•°æ®å†™å…¥Hiveæ™®é€šè¡¨å’Œåˆ†åŒºè¡¨</title>
    <link href="http://yoursite.com/2018/11/20/Spark%E8%AF%BB%E5%8F%96mongoDB%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5Hive%E6%99%AE%E9%80%9A%E8%A1%A8%E5%92%8C%E5%88%86%E5%8C%BA%E8%A1%A8/"/>
    <id>http://yoursite.com/2018/11/20/Sparkè¯»å–mongoDBæ•°æ®å†™å…¥Hiveæ™®é€šè¡¨å’Œåˆ†åŒºè¡¨/</id>
    <published>2018-11-19T16:00:00.000Z</published>
    <updated>2019-05-20T14:34:59.451Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 20 2019 22:37:10 GMT+0800 (GMT+08:00) --><a id="more"></a><h3 id="ç‰ˆæœ¬ï¼š"><a href="#ç‰ˆæœ¬ï¼š" class="headerlink" title="ç‰ˆæœ¬ï¼š"></a>ç‰ˆæœ¬ï¼š</h3><p>spark 2.2.0<br>hive 1.1.0<br>scala 2.11.8<br>hadoop-2.6.0-cdh5.7.0<br>jdk 1.8<br>MongoDB 3.6.4</p><h3 id="ä¸€-åŸå§‹æ•°æ®åŠHiveè¡¨"><a href="#ä¸€-åŸå§‹æ•°æ®åŠHiveè¡¨" class="headerlink" title="ä¸€ åŸå§‹æ•°æ®åŠHiveè¡¨"></a>ä¸€ åŸå§‹æ•°æ®åŠHiveè¡¨</h3><h5 id="MongoDBæ•°æ®æ ¼å¼"><a href="#MongoDBæ•°æ®æ ¼å¼" class="headerlink" title="MongoDBæ•°æ®æ ¼å¼"></a>MongoDBæ•°æ®æ ¼å¼</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;_id&quot; : ObjectId(&quot;5af65d86222b639e0c2212f3&quot;),</span><br><span class="line">    &quot;id&quot; : &quot;1&quot;,</span><br><span class="line">    &quot;name&quot; : &quot;lisi&quot;,</span><br><span class="line">    &quot;age&quot; : &quot;18&quot;,</span><br><span class="line">    &quot;deptno&quot; : &quot;01&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="Hiveæ™®é€šè¡¨"><a href="#Hiveæ™®é€šè¡¨" class="headerlink" title="Hiveæ™®é€šè¡¨"></a>Hiveæ™®é€šè¡¨</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create table mg_hive_test(</span><br><span class="line">id string,</span><br><span class="line">name string,</span><br><span class="line">age string,</span><br><span class="line">deptno string</span><br><span class="line">)row format delimited fields terminated by &apos;\t&apos;;</span><br></pre></td></tr></table></figure><h5 id="Hiveåˆ†åŒºè¡¨"><a href="#Hiveåˆ†åŒºè¡¨" class="headerlink" title="Hiveåˆ†åŒºè¡¨"></a>Hiveåˆ†åŒºè¡¨</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create table  mg_hive_external(</span><br><span class="line">id string,</span><br><span class="line">name string,</span><br><span class="line">age string</span><br><span class="line">)</span><br><span class="line">partitioned by (deptno string)</span><br><span class="line">row format delimited fields terminated by &apos;\t&apos;;</span><br></pre></td></tr></table></figure><h3 id="äºŒ-IDEA-Maven-Java"><a href="#äºŒ-IDEA-Maven-Java" class="headerlink" title="äºŒ IDEA+Maven+Java"></a>äºŒ IDEA+Maven+Java</h3><h5 id="ä¾èµ–"><a href="#ä¾èµ–" class="headerlink" title="ä¾èµ–"></a>ä¾èµ–</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;spark-sql_2.11&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;spark-hive_2.11&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.mongodb&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;mongo-java-driver&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;3.6.3&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.mongodb.spark&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;mongo-spark-connector_2.11&lt;/artifactId&gt;</span><br><span class="line">      &lt;version&gt;2.2.2&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h5 id="ä»£ç "><a href="#ä»£ç " class="headerlink" title="ä»£ç "></a>ä»£ç </h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line">package com.huawei.mongo;/*</span><br><span class="line"> * @Author: Create by Achun</span><br><span class="line"> *@Time: 2018/6/2 21:00</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line"></span><br><span class="line">import com.mongodb.spark.MongoSpark;</span><br><span class="line"></span><br><span class="line">import org.apache.spark.SparkConf;</span><br><span class="line">import org.apache.spark.api.java.JavaRDD;</span><br><span class="line">import org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line">import org.apache.spark.api.java.function.Function;</span><br><span class="line">import org.apache.spark.sql.Dataset;</span><br><span class="line">import org.apache.spark.sql.Row;</span><br><span class="line">import org.apache.spark.sql.RowFactory;</span><br><span class="line">import org.apache.spark.sql.SparkSession;</span><br><span class="line">import org.apache.spark.sql.hive.HiveContext;</span><br><span class="line">import org.apache.spark.sql.types.DataTypes;</span><br><span class="line">import org.apache.spark.sql.types.StructField;</span><br><span class="line">import org.apache.spark.sql.types.StructType;</span><br><span class="line">import org.bson.Document;</span><br><span class="line"></span><br><span class="line">import java.io.File;</span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.List;</span><br><span class="line"></span><br><span class="line">public class sparkreadmgtohive &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        //spark 2.x</span><br><span class="line">        String warehouseLocation = new File(&quot;spark-warehouse&quot;).getAbsolutePath();</span><br><span class="line">        SparkSession spark = SparkSession.builder()</span><br><span class="line">                .master(&quot;local[2]&quot;)</span><br><span class="line">                .appName(&quot;SparkReadMgToHive&quot;)</span><br><span class="line">                .config(&quot;spark.sql.warehouse.dir&quot;, warehouseLocation)</span><br><span class="line">                .config(&quot;spark.mongodb.input.uri&quot;, &quot;mongodb://127.0.0.1:27017/test.mgtest&quot;)</span><br><span class="line">                .enableHiveSupport()</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        JavaSparkContext sc = new JavaSparkContext(spark.sparkContext());</span><br><span class="line"></span><br><span class="line">        //spark 1.x</span><br><span class="line">//        JavaSparkContext sc = new JavaSparkContext(conf);</span><br><span class="line">//        sc.addJar(&quot;/Users/mac/zhangchun/jar/mongo-spark-connector_2.11-2.2.2.jar&quot;);</span><br><span class="line">//        sc.addJar(&quot;/Users/mac/zhangchun/jar/mongo-java-driver-3.6.3.jar&quot;);</span><br><span class="line">//        SparkConf conf = new SparkConf().setMaster(&quot;local[2]&quot;).setAppName(&quot;SparkReadMgToHive&quot;);</span><br><span class="line">//        conf.set(&quot;spark.mongodb.input.uri&quot;, &quot;mongodb://127.0.0.1:27017/test.mgtest&quot;);</span><br><span class="line">//        conf.set(&quot;spark. serializer&quot;,&quot;org.apache.spark.serializer.KryoSerialzier&quot;);</span><br><span class="line">//        HiveContext sqlContext = new HiveContext(sc);</span><br><span class="line">//        //create df from mongo</span><br><span class="line">//        Dataset&lt;Row&gt; df = MongoSpark.read(sqlContext).load().toDF();</span><br><span class="line">//        df.select(&quot;id&quot;,&quot;name&quot;,&quot;name&quot;).show();</span><br><span class="line"></span><br><span class="line">        String querysql= &quot;select id,name,age,deptno,DateTime,Job from mgtable b&quot;;</span><br><span class="line">        String opType =&quot;P&quot;;</span><br><span class="line"></span><br><span class="line">        SQLUtils sqlUtils = new SQLUtils();</span><br><span class="line">        List&lt;String&gt; column = sqlUtils.getColumns(querysql);</span><br><span class="line"></span><br><span class="line">        //create rdd from mongo</span><br><span class="line">        JavaRDD&lt;Document&gt; rdd = MongoSpark.load(sc);</span><br><span class="line">        //å°†Documentè½¬æˆObject</span><br><span class="line">        JavaRDD&lt;Object&gt; Ordd = rdd.map(new Function&lt;Document, Object&gt;() &#123;</span><br><span class="line">            public Object call(Document document)&#123;</span><br><span class="line">                List list = new ArrayList();</span><br><span class="line">                for (int i = 0; i &lt; column.size(); i++) &#123;</span><br><span class="line">                    list.add(String.valueOf(document.get(column.get(i))));</span><br><span class="line">                &#125;</span><br><span class="line">                return list;</span><br><span class="line"></span><br><span class="line">//                return list.toString().replace(&quot;[&quot;,&quot;&quot;).replace(&quot;]&quot;,&quot;&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        System.out.println(Ordd.first());</span><br><span class="line">        //é€šè¿‡ç¼–ç¨‹æ–¹å¼å°†RDDè½¬æˆDF</span><br><span class="line">        List ls= new ArrayList();</span><br><span class="line">        for (int i = 0; i &lt; column.size(); i++) &#123;</span><br><span class="line">            ls.add(column.get(i));</span><br><span class="line">        &#125;</span><br><span class="line">        String schemaString = ls.toString().replace(&quot;[&quot;,&quot;&quot;).replace(&quot;]&quot;,&quot;&quot;).replace(&quot; &quot;,&quot;&quot;);</span><br><span class="line">        System.out.println(schemaString);</span><br><span class="line"></span><br><span class="line">        List&lt;StructField&gt; fields = new ArrayList&lt;StructField&gt;();</span><br><span class="line">        for (String fieldName : schemaString.split(&quot;,&quot;)) &#123;</span><br><span class="line">            StructField field = DataTypes.createStructField(fieldName, DataTypes.StringType, true);</span><br><span class="line">            fields.add(field);</span><br><span class="line">        &#125;</span><br><span class="line">        StructType schema = DataTypes.createStructType(fields);</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;Row&gt; rowRDD = Ordd.map((Function&lt;Object, Row&gt;) record -&gt; &#123;</span><br><span class="line">            List fileds = (List) record;</span><br><span class="line">//            String[] attributes = record.toString().split(&quot;,&quot;);</span><br><span class="line">            return RowFactory.create(fileds.toArray());</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(rowRDD,schema);</span><br><span class="line"></span><br><span class="line">        //å°†DFå†™å…¥åˆ°Hiveä¸­</span><br><span class="line">        //é€‰æ‹©Hiveæ•°æ®åº“</span><br><span class="line">        spark.sql(&quot;use datalake&quot;);</span><br><span class="line">        //æ³¨å†Œä¸´æ—¶è¡¨</span><br><span class="line">        df.registerTempTable(&quot;mgtable&quot;);</span><br><span class="line"></span><br><span class="line">        if (&quot;O&quot;.equals(opType.trim())) &#123;</span><br><span class="line">            System.out.println(&quot;æ•°æ®æ’å…¥åˆ°Hive ordinary table&quot;);</span><br><span class="line">            Long t1 = System.currentTimeMillis();</span><br><span class="line">            spark.sql(&quot;insert into mgtohive_2 &quot; + querysql + &quot; &quot; + &quot;where b.id not in (select id from mgtohive_2)&quot;);</span><br><span class="line">            Long t2 = System.currentTimeMillis();</span><br><span class="line">            System.out.println(&quot;å…±è€—æ—¶ï¼š&quot; + (t2 - t1) / 60000 + &quot;åˆ†é’Ÿ&quot;);</span><br><span class="line">        &#125;else if (&quot;P&quot;.equals(opType.trim())) &#123;</span><br><span class="line"></span><br><span class="line">        System.out.println(&quot;æ•°æ®æ’å…¥åˆ°Hive  dynamic partition table&quot;);</span><br><span class="line">        Long t3 = System.currentTimeMillis();</span><br><span class="line">        //å¿…é¡»è®¾ç½®ä»¥ä¸‹å‚æ•° å¦åˆ™æŠ¥é”™</span><br><span class="line">        spark.sql(&quot;set hive.exec.dynamic.partition.mode=nonstrict&quot;);</span><br><span class="line">        //deptonä¸ºåˆ†åŒºå­—æ®µ   selectè¯­å¥æœ€åä¸€ä¸ªå­—æ®µå¿…é¡»æ˜¯deptno</span><br><span class="line">        spark.sql(&quot;insert into mg_hive_external partition(deptno) select id,name,age,deptno from mgtable b where b.id not in (select id from mg_hive_external)&quot;);</span><br><span class="line">        Long t4 = System.currentTimeMillis();</span><br><span class="line">        System.out.println(&quot;å…±è€—æ—¶ï¼š&quot;+(t4 -t3)/60000+ &quot;åˆ†é’Ÿ&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="å·¥å…·ç±»"><a href="#å·¥å…·ç±»" class="headerlink" title="å·¥å…·ç±»"></a>å·¥å…·ç±»</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">package com.huawei.mongo;/*</span><br><span class="line"> * @Author: Create by Achun</span><br><span class="line"> *@Time: 2018/6/3 23:20</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line"></span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.List;</span><br><span class="line"></span><br><span class="line">public class SQLUtils &#123;</span><br><span class="line"></span><br><span class="line">    public List&lt;String&gt; getColumns(String querysql)&#123;</span><br><span class="line">        List&lt;String&gt; column = new ArrayList&lt;String&gt;();</span><br><span class="line">        String tmp = querysql.substring(querysql.indexOf(&quot;select&quot;) + 6,</span><br><span class="line">                querysql.indexOf(&quot;from&quot;)).trim();</span><br><span class="line">        if (tmp.indexOf(&quot;*&quot;) == -1)&#123;</span><br><span class="line">            String cols[] = tmp.split(&quot;,&quot;);</span><br><span class="line">            for (String c:cols)&#123;</span><br><span class="line">                column.add(c);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return column;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String getTBname(String querysql)&#123;</span><br><span class="line">        String tmp = querysql.substring(querysql.indexOf(&quot;from&quot;)+4).trim();</span><br><span class="line">        int sx = tmp.indexOf(&quot; &quot;);</span><br><span class="line">        if(sx == -1)&#123;</span><br><span class="line">            return tmp;</span><br><span class="line">        &#125;else &#123;</span><br><span class="line">            return tmp.substring(0,sx);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ä¸‰-é”™è¯¯è§£å†³åŠæ³•"><a href="#ä¸‰-é”™è¯¯è§£å†³åŠæ³•" class="headerlink" title="ä¸‰ é”™è¯¯è§£å†³åŠæ³•"></a>ä¸‰ é”™è¯¯è§£å†³åŠæ³•</h3><p>1 IDEAä¼šè·å–ä¸åˆ°Hiveçš„æ•°æ®åº“å’Œè¡¨ï¼Œå°†hive-site.xmlæ”¾å…¥resourcesæ–‡ä»¶ä¸­ã€‚å¹¶ä¸”å°†resourcesè®¾ç½®æˆé…ç½®æ–‡ä»¶(è®¾ç½®æˆåŠŸæ–‡ä»¶å¤¹æ˜¯è“è‰²å¦åˆ™æ˜¯ç°è‰²)<br>fileâ€“&gt;Project Structureâ€“&gt;Modulesâ€“&gt;Source<br><img src="/assets/blogImg/1120_1.png" alt="enter description here"><br>2 ä¸Šé¢é”™è¯¯å¤„ç†å®Œåå¦‚æœæŠ¥JDOç±»å‹çš„é”™è¯¯ï¼Œé‚£ä¹ˆæ£€æŸ¥HIVE_HOME/libä¸‹æ—¶å€™å¦mysqlé©±åŠ¨ï¼Œå¦‚æœç¡®å®šæœ‰ï¼Œé‚£ä¹ˆå°±æ˜¯IDEAè·å–ä¸åˆ°ã€‚è§£å†³æ–¹æ³•å¦‚ä¸‹ï¼š</p><p>å°†mysqlé©±åŠ¨æ‹·è´åˆ°jdk1.8.0_171.jdk/Contents/Home/jre/lib/extè·¯å¾„ä¸‹(jdk/jre/lib/ext)<br>åœ¨IDEAé¡¹ç›®External Librariesä¸‹çš„&lt;1.8&gt;é‡Œé¢æ·»åŠ mysqlé©±åŠ¨<br><img src="/assets/blogImg/1120_2.png" alt="enter description here"></p><h3 id="å››-æ³¨æ„ç‚¹"><a href="#å››-æ³¨æ„ç‚¹" class="headerlink" title="å›› æ³¨æ„ç‚¹"></a>å›› æ³¨æ„ç‚¹</h3><p>ç”±äºå°†MongoDBæ•°æ®è¡¨æ³¨å†Œæˆäº†ä¸´æ—¶è¡¨å’ŒHiveè¡¨è¿›è¡Œäº†å…³è”ï¼Œæ‰€ä»¥è¦å°†MongoDBä¸­çš„idå­—æ®µè®¾ç½®æˆç´¢å¼•å­—æ®µï¼Œå¦åˆ™æ€§èƒ½ä¼šå¾ˆæ…¢ã€‚<br>MongoDBè®¾ç½®ç´¢å¼•æ–¹æ³•ï¼š<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.getCollection(&apos;mgtest&apos;).ensureIndex(&#123;&quot;id&quot; : &quot;1&quot;&#125;),&#123;&quot;background&quot;:true&#125;</span><br></pre></td></tr></table></figure><p></p><p>æŸ¥çœ‹ç´¢å¼•ï¼š<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">db.getCollection(&apos;mgtest&apos;).getIndexes()</span><br><span class="line">MongoSparkç½‘å€ï¼šhttps://docs.mongodb.com/spark-connector/current/java-api/</span><br></pre></td></tr></table></figure><p></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 20 2019 22:37:10 GMT+0800 (GMT+08:00) --&gt;
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>æœ€å…¨çš„Flinkéƒ¨ç½²åŠå¼€å‘æ¡ˆä¾‹(KafkaSource+SinkToMySQL)</title>
    <link href="http://yoursite.com/2018/11/10/%E6%9C%80%E5%85%A8%E7%9A%84Flink%E9%83%A8%E7%BD%B2%E5%8F%8A%E5%BC%80%E5%8F%91%E6%A1%88%E4%BE%8B(KafkaSource+SinkToMySQL)/"/>
    <id>http://yoursite.com/2018/11/10/æœ€å…¨çš„Flinkéƒ¨ç½²åŠå¼€å‘æ¡ˆä¾‹(KafkaSource+SinkToMySQL)/</id>
    <published>2018-11-09T16:00:00.000Z</published>
    <updated>2019-05-03T11:57:01.078Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --><h5 id="1-ä¸‹è½½Flinkå®‰è£…åŒ…"><a href="#1-ä¸‹è½½Flinkå®‰è£…åŒ…" class="headerlink" title="1.ä¸‹è½½Flinkå®‰è£…åŒ…"></a>1.ä¸‹è½½Flinkå®‰è£…åŒ…</h5><p>flinkä¸‹è½½åœ°å€</p><p><a href="https://archive.apache.org/dist/flink/flink-1.5.0/" target="_blank" rel="noopener">https://archive.apache.org/dist/flink/flink-1.5.0/</a></p><p>å› ä¸ºä¾‹å­ä¸éœ€è¦hadoopï¼Œä¸‹è½½flink-1.5.0-bin-scala_2.11.tgzå³å¯</p><p>ä¸Šä¼ è‡³æœºå™¨çš„/optç›®å½•ä¸‹<br><a id="more"></a></p><h5 id="2-è§£å‹"><a href="#2-è§£å‹" class="headerlink" title="2.è§£å‹"></a>2.è§£å‹</h5><p>tar -zxf flink-1.5.0-bin-scala_2.11.tgz -C ../opt/</p><h5 id="3-é…ç½®masterèŠ‚ç‚¹"><a href="#3-é…ç½®masterèŠ‚ç‚¹" class="headerlink" title="3.é…ç½®masterèŠ‚ç‚¹"></a>3.é…ç½®masterèŠ‚ç‚¹</h5><p>é€‰æ‹©ä¸€ä¸ª masterèŠ‚ç‚¹(JobManager)ç„¶ååœ¨conf/flink-conf.yamlä¸­è®¾ç½®jobmanager.rpc.address é…ç½®é¡¹ä¸ºè¯¥èŠ‚ç‚¹çš„IP æˆ–è€…ä¸»æœºåã€‚ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹æœ‰æœ‰ä¸€æ ·çš„jobmanager.rpc.address é…ç½®ã€‚</p><p>jobmanager.rpc.address: node1</p><p>(é…ç½®ç«¯å£å¦‚æœè¢«å ç”¨ä¹Ÿè¦æ”¹ å¦‚é»˜è®¤8080å·²ç»è¢«sparkå ç”¨ï¼Œæ”¹æˆäº†8088)</p><p>rest.port: 8088</p><p>æœ¬æ¬¡å®‰è£… masterèŠ‚ç‚¹ä¸ºnode1ï¼Œå› ä¸ºå•æœºï¼ŒslaveèŠ‚ç‚¹ä¹Ÿä¸ºnode1</p><h5 id="4-é…ç½®slaves"><a href="#4-é…ç½®slaves" class="headerlink" title="4.é…ç½®slaves"></a>4.é…ç½®slaves</h5><p>å°†æ‰€æœ‰çš„ worker èŠ‚ç‚¹ ï¼ˆTaskManagerï¼‰çš„IP æˆ–è€…ä¸»æœºåï¼ˆä¸€è¡Œä¸€ä¸ªï¼‰å¡«å…¥conf/slaves æ–‡ä»¶ä¸­ã€‚</p><h5 id="5-å¯åŠ¨flinké›†ç¾¤"><a href="#5-å¯åŠ¨flinké›†ç¾¤" class="headerlink" title="5.å¯åŠ¨flinké›†ç¾¤"></a>5.å¯åŠ¨flinké›†ç¾¤</h5><p>bin/start-cluster.sh</p><p>æ‰“å¼€ <a href="http://node1:8088" target="_blank" rel="noopener">http://node1:8088</a> æŸ¥çœ‹webé¡µé¢<br><img src="/assets/blogImg/1110_1.png" alt="enter description here"><br>Task Managersä»£è¡¨å½“å‰çš„flinkåªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œæ¯ä¸ªtaskè¿˜æœ‰ä¸¤ä¸ªslots</p><h5 id="6-æµ‹è¯•"><a href="#6-æµ‹è¯•" class="headerlink" title="6.æµ‹è¯•"></a>6.æµ‹è¯•</h5><p><strong>ä¾èµ–</strong><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&lt;groupId&gt;com.rz.flinkdemo&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;Flink-programe&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</span><br><span class="line"></span><br><span class="line">&lt;properties&gt;</span><br><span class="line">    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;</span><br><span class="line">    &lt;scala.binary.version&gt;2.11&lt;/scala.binary.version&gt;</span><br><span class="line">    &lt;flink.version&gt;1.5.0&lt;/flink.version&gt;</span><br><span class="line">&lt;/properties&gt;</span><br><span class="line">&lt;dependencies&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;flink-streaming-java_$&#123;scala.binary.version&#125;&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;flink-streaming-scala_$&#123;scala.binary.version&#125;&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;flink-cep_2.11&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;1.5.0&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">&lt;/dependencies&gt;</span><br></pre></td></tr></table></figure><p></p><h5 id="7-Socketæµ‹è¯•ä»£ç "><a href="#7-Socketæµ‹è¯•ä»£ç " class="headerlink" title="7.Socketæµ‹è¯•ä»£ç "></a>7.Socketæµ‹è¯•ä»£ç </h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">public class SocketWindowWordCount &#123;    public static void main(String[] args) throws Exception &#123;        // the port to connect to</span><br><span class="line">        final int port;        final String hostName;        try &#123;            final ParameterTool params = ParameterTool.fromArgs(args);</span><br><span class="line">            port = params.getInt(&quot;port&quot;);</span><br><span class="line">            hostName = params.get(&quot;hostname&quot;);</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            System.err.println(&quot;No port or hostname specified. Please run &apos;SocketWindowWordCount --port &lt;port&gt; --hostname &lt;hostname&gt;&apos;&quot;);            return;</span><br><span class="line">        &#125;        // get the execution environment</span><br><span class="line">        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();        // get input data by connecting to the socket</span><br><span class="line">        DataStream&lt;String&gt; text = env.socketTextStream(hostName, port, &quot;\n&quot;);        // parse the data, group it, window it, and aggregate the counts</span><br><span class="line">        DataStream&lt;WordWithCount&gt; windowCounts = text</span><br><span class="line">                .flatMap(new FlatMapFunction&lt;String, WordWithCount&gt;() &#123;                    public void flatMap(String value, Collector&lt;WordWithCount&gt; out) &#123;                        for (String word : value.split(&quot;\\s&quot;)) &#123;</span><br><span class="line">                            out.collect(new WordWithCount(word, 1L));</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;)</span><br><span class="line">                .keyBy(&quot;word&quot;)</span><br><span class="line">                .timeWindow(Time.seconds(5), Time.seconds(1))</span><br><span class="line">                .reduce(new ReduceFunction&lt;WordWithCount&gt;() &#123;                    public WordWithCount reduce(WordWithCount a, WordWithCount b) &#123;                        return new WordWithCount(a.word, a.count + b.count);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);        // print the results with a single thread, rather than in parallel</span><br><span class="line">        windowCounts.print().setParallelism(1);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        env.execute(&quot;Socket Window WordCount&quot;);</span><br><span class="line">    &#125;    // Data type for words with count</span><br><span class="line">    public static class WordWithCount &#123;        public String word;        public long count;        public WordWithCount() &#123;&#125;        public WordWithCount(String word, long count) &#123;            this.word = word;            this.count = count;</span><br><span class="line">        &#125;        @Override</span><br><span class="line">        public String toString() &#123;            return word + &quot; : &quot; + count;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ‰“åŒ…mvn clean install (å¦‚æœæ‰“åŒ…è¿‡ç¨‹ä¸­æŠ¥é”™java.lang.OutOfMemoryError)</p><p>åœ¨å‘½ä»¤è¡Œset MAVEN_OPTS= -Xms128m -Xmx512m</p><p>ç»§ç»­æ‰§è¡Œmvn clean install</p><p>ç”ŸæˆFlinkTest.jar<br><img src="/assets/blogImg/1110_2.png" alt="enter description here"><br>æ‰¾åˆ°æ‰“æˆçš„jarï¼Œå¹¶uploadï¼Œå¼€å§‹ä¸Šä¼ <br><img src="/assets/blogImg/1110_3.png" alt="enter description here"><br>è¿è¡Œå‚æ•°ä»‹ç»<br><img src="/assets/blogImg/1110_4.png" alt="enter description here"><br><img src="/assets/blogImg/1110_5.png" alt="enter description here"><br><img src="/assets/blogImg/1110_6.png" alt="enter description here"><br>æäº¤ç»“æŸä¹‹åå»overviewç•Œé¢çœ‹ï¼Œå¯ä»¥çœ‹åˆ°ï¼Œå¯ç”¨çš„slotså˜æˆäº†ä¸€ä¸ªï¼Œå› ä¸ºæˆ‘ä»¬çš„socketç¨‹åºå ç”¨äº†ä¸€ä¸ªï¼Œæ­£åœ¨runningçš„jobå˜æˆäº†ä¸€ä¸ª</p><p>å‘é€æ•°æ®<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop000 flink-1.5.0]# nc -l 8099</span><br><span class="line">aaa bbb</span><br><span class="line">aaa ccc</span><br><span class="line">aaa bbb</span><br><span class="line">bbb ccc</span><br></pre></td></tr></table></figure><p></p><p><img src="/assets/blogImg/1110_7.png" alt="enter description here"><br>ç‚¹å¼€runningçš„jobï¼Œä½ å¯ä»¥çœ‹è§æ¥æ”¶çš„å­—èŠ‚æ•°ç­‰ä¿¡æ¯</p><p>åˆ°logç›®å½•ä¸‹å¯ä»¥æ¸…æ¥šçš„çœ‹è§è¾“å‡º<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost log]# tail -f flink-root-taskexecutor-2-localhost.out</span><br><span class="line">aaa : 1</span><br><span class="line">ccc : 1</span><br><span class="line">ccc : 1</span><br><span class="line">bbb : 1</span><br><span class="line">ccc : 1</span><br><span class="line">bbb : 1</span><br><span class="line">bbb : 1</span><br><span class="line">ccc : 1</span><br><span class="line">bbb : 1</span><br><span class="line">ccc : 1</span><br></pre></td></tr></table></figure><p></p><p>é™¤äº†å¯ä»¥åœ¨ç•Œé¢æäº¤ï¼Œè¿˜å¯ä»¥å°†jarä¸Šä¼ çš„linuxä¸­è¿›è¡Œæäº¤ä»»åŠ¡</p><p>è¿è¡Œflinkä¸Šä¼ çš„jar<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flink run -c com.rz.flinkdemo.SocketWindowWordCount jars/FlinkTest.jar --port 8099 --hostname node1</span><br></pre></td></tr></table></figure><p></p><p>å…¶ä»–æ­¥éª¤ä¸€è‡´ã€‚</p><h5 id="8-ä½¿ç”¨kafkaä½œä¸ºsource"><a href="#8-ä½¿ç”¨kafkaä½œä¸ºsource" class="headerlink" title="8.ä½¿ç”¨kafkaä½œä¸ºsource"></a>8.ä½¿ç”¨kafkaä½œä¸ºsource</h5><p>åŠ ä¸Šä¾èµ–<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-connector-kafka-0.10_2.11&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.5.0&lt;/version&gt;&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public class KakfaSource010 &#123;    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        Properties properties = new Properties();</span><br><span class="line">        properties.setProperty(&quot;bootstrap.servers&quot;,&quot;node1:9092&quot;);</span><br><span class="line">        properties.setProperty(&quot;group.id&quot;,&quot;test&quot;);        //DataStream&lt;String&gt; test = env.addSource(new FlinkKafkaConsumer010&lt;String&gt;(&quot;topic&quot;, new SimpleStringSchema(), properties));</span><br><span class="line">        //å¯ä»¥é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æ¥åŒ¹é…åˆé€‚çš„topic</span><br><span class="line">        FlinkKafkaConsumer010&lt;String&gt; kafkaSource = new FlinkKafkaConsumer010&lt;&gt;(java.util.regex.Pattern.compile(&quot;test-[0-9]&quot;), new SimpleStringSchema(), properties);        //é…ç½®ä»æœ€æ–°çš„åœ°æ–¹å¼€å§‹æ¶ˆè´¹</span><br><span class="line">        kafkaSource.setStartFromLatest();        //ä½¿ç”¨addsourceï¼Œå°†kafkaçš„è¾“å…¥è½¬å˜ä¸ºdatastream</span><br><span class="line">        DataStream&lt;String&gt; consume = env.addSource(wordfre);</span><br><span class="line"></span><br><span class="line">        ...        //process  and   sink</span><br><span class="line"></span><br><span class="line">        env.execute(&quot;KakfaSource010&quot;);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="9-ä½¿ç”¨mysqlä½œä¸ºsink"><a href="#9-ä½¿ç”¨mysqlä½œä¸ºsink" class="headerlink" title="9.ä½¿ç”¨mysqlä½œä¸ºsink"></a>9.ä½¿ç”¨mysqlä½œä¸ºsink</h5><p>flinkæœ¬èº«å¹¶æ²¡æœ‰æä¾›datastreamè¾“å‡ºåˆ°mysqlï¼Œéœ€è¦æˆ‘ä»¬è‡ªå·±å»å®ç°</p><p>é¦–å…ˆï¼Œå¯¼å…¥ä¾èµ–<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;mysql&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;5.1.30&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p></p><p>è‡ªå®šä¹‰sinkï¼Œé¦–å…ˆæƒ³åˆ°çš„æ˜¯extends SinkFunctionï¼Œé›†æˆflinkè‡ªå¸¦çš„sinkfunctionï¼Œå†å½“ä¸­å®ç°æ–¹æ³•ï¼Œå®ç°å¦‚ä¸‹<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">public class MysqlSink implements</span><br><span class="line">        SinkFunction&lt;Tuple2&lt;String,String&gt;&gt; &#123;    private static final long serialVersionUID = 1L;    private Connection connection;    private PreparedStatement preparedStatement;</span><br><span class="line">    String username = &quot;mysql.user&quot;;</span><br><span class="line">    String password = &quot;mysql.password&quot;;</span><br><span class="line">    String drivername = &quot;mysql.driver&quot;;</span><br><span class="line">    String dburl = &quot;mysql.url&quot;;    @Override</span><br><span class="line">    public void invoke(Tuple2&lt;String,String&gt; value) throws Exception &#123;</span><br><span class="line">        Class.forName(drivername);</span><br><span class="line">        connection = DriverManager.getConnection(dburl, username, password);</span><br><span class="line">        String sql = &quot;insert into table(name,nickname) values(?,?)&quot;;</span><br><span class="line">        preparedStatement = connection.prepareStatement(sql);</span><br><span class="line">        preparedStatement.setString(1, value.f0);</span><br><span class="line">        preparedStatement.setString(2, value.f1);</span><br><span class="line">        preparedStatement.executeUpdate();        if (preparedStatement != null) &#123;</span><br><span class="line">            preparedStatement.close();</span><br><span class="line">        &#125;        if (connection != null) &#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>è¿™æ ·å®ç°æœ‰ä¸ªé—®é¢˜ï¼Œæ¯ä¸€æ¡æ•°æ®ï¼Œéƒ½è¦æ‰“å¼€mysqlè¿æ¥ï¼Œå†å…³é—­ï¼Œæ¯”è¾ƒè€—æ—¶ï¼Œè¿™ä¸ªå¯ä»¥ä½¿ç”¨flinkä¸­æ¯”è¾ƒå¥½çš„Richæ–¹å¼æ¥å®ç°ï¼Œä»£ç å¦‚ä¸‹<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">public class MysqlSink extends RichSinkFunction&lt;Tuple2&lt;String,String&gt;&gt; &#123;    private Connection connection = null;    private PreparedStatement preparedStatement = null;    private String userName = null;    private String password = null;    private String driverName = null;    private String DBUrl = null;    public MysqlSink() &#123;</span><br><span class="line">        userName = &quot;mysql.username&quot;;</span><br><span class="line">        password = &quot;mysql.password&quot;;</span><br><span class="line">        driverName = &quot;mysql.driverName&quot;;</span><br><span class="line">        DBUrl = &quot;mysql.DBUrl&quot;;</span><br><span class="line">    &#125;    public void invoke(Tuple2&lt;String,String&gt; value) throws Exception &#123;        if(connection==null)&#123;</span><br><span class="line">            Class.forName(driverName);</span><br><span class="line">            connection = DriverManager.getConnection(DBUrl, userName, password);</span><br><span class="line">        &#125;</span><br><span class="line">        String sql =&quot;insert into table(name,nickname) values(?,?)&quot;;</span><br><span class="line">        preparedStatement = connection.prepareStatement(sql);</span><br><span class="line"></span><br><span class="line">        preparedStatement.setString(1,value.f0);</span><br><span class="line">        preparedStatement.setString(2,value.f1);</span><br><span class="line"></span><br><span class="line">        preparedStatement.executeUpdate();//è¿”å›æˆåŠŸçš„è¯å°±æ˜¯ä¸€ä¸ªï¼Œå¦åˆ™å°±æ˜¯0</span><br><span class="line">    &#125;    @Override</span><br><span class="line">    public void open(Configuration parameters) throws Exception &#123;</span><br><span class="line">        Class.forName(driverName);</span><br><span class="line">        connection = DriverManager.getConnection(DBUrl, userName, password);</span><br><span class="line">    &#125;    @Override</span><br><span class="line">    public void close() throws Exception &#123;        if(preparedStatement!=null)&#123;</span><br><span class="line">            preparedStatement.close();</span><br><span class="line">        &#125;        if(connection!=null)&#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>Richæ–¹å¼çš„ä¼˜ç‚¹åœ¨äºï¼Œæœ‰ä¸ªopenå’Œcloseæ–¹æ³•ï¼Œåœ¨åˆå§‹åŒ–çš„æ—¶å€™å»ºç«‹ä¸€æ¬¡è¿æ¥ï¼Œä¹‹åä¸€ç›´ä½¿ç”¨è¿™ä¸ªè¿æ¥å³å¯ï¼Œç¼©çŸ­å»ºç«‹å’Œå…³é—­è¿æ¥çš„æ—¶é—´ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨è¿æ¥æ± å®ç°ï¼Œè¿™é‡Œåªæ˜¯æä¾›è¿™æ ·ä¸€ç§æ€è·¯ã€‚</p><p>ä½¿ç”¨è¿™ä¸ªmysqlsinkä¹Ÿéå¸¸ç®€å•<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">//ç›´æ¥addsinkï¼Œå³å¯è¾“å‡ºåˆ°è‡ªå®šä¹‰çš„mysqlä¸­ï¼Œä¹Ÿå¯ä»¥å°†mysqlçš„å­—æ®µç­‰å†™æˆå¯é…ç½®çš„ï¼Œæ›´åŠ æ–¹ä¾¿å’Œé€šç”¨proceDataStream.addSink(new MysqlSink());</span><br></pre></td></tr></table></figure><p></p><h5 id="10-æ€»ç»“"><a href="#10-æ€»ç»“" class="headerlink" title="10.æ€»ç»“"></a>10.æ€»ç»“</h5><p>æœ¬æ¬¡çš„ç¬”è®°åšäº†ç®€å•çš„éƒ¨ç½²ã€æµ‹è¯•ã€kafkademoï¼Œä»¥åŠè‡ªå®šä¹‰å®ç°mysqlsinkçš„ä¸€äº›å†…å®¹ï¼Œå…¶ä¸­æ¯”è¾ƒé‡è¦çš„æ˜¯Richçš„ä½¿ç”¨ï¼Œå¸Œæœ›å¤§å®¶èƒ½æœ‰æ‰€æ”¶è·ã€‚</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --&gt;&lt;h5 id=&quot;1-ä¸‹è½½Flinkå®‰è£…åŒ…&quot;&gt;&lt;a href=&quot;#1-ä¸‹è½½Flinkå®‰è£…åŒ…&quot; class=&quot;headerlink&quot; title=&quot;1.ä¸‹è½½Flinkå®‰è£…åŒ…&quot;&gt;&lt;/a&gt;1.ä¸‹è½½Flinkå®‰è£…åŒ…&lt;/h5&gt;&lt;p&gt;flinkä¸‹è½½åœ°å€&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://archive.apache.org/dist/flink/flink-1.5.0/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://archive.apache.org/dist/flink/flink-1.5.0/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;å› ä¸ºä¾‹å­ä¸éœ€è¦hadoopï¼Œä¸‹è½½flink-1.5.0-bin-scala_2.11.tgzå³å¯&lt;/p&gt;&lt;p&gt;ä¸Šä¼ è‡³æœºå™¨çš„/optç›®å½•ä¸‹&lt;br&gt;
    
    </summary>
    
      <category term="Flink" scheme="http://yoursite.com/categories/Flink/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>è¿™æ˜¯ä¸€ç¯‡çƒ­è…¾è…¾çš„é¢ç»</title>
    <link href="http://yoursite.com/2018/08/27/%E8%BF%99%E6%98%AF%E4%B8%80%E7%AF%87%E7%83%AD%E8%85%BE%E8%85%BE%E7%9A%84%E9%9D%A2%E7%BB%8F/"/>
    <id>http://yoursite.com/2018/08/27/è¿™æ˜¯ä¸€ç¯‡çƒ­è…¾è…¾çš„é¢ç»/</id>
    <published>2018-08-26T16:00:00.000Z</published>
    <updated>2019-05-19T14:24:12.651Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun May 19 2019 22:24:17 GMT+0800 (GMT+08:00) --><p>ä¼Ÿæ¢¦ï¼š<br>1.ä¸»è¦è¿˜æ˜¯é¡¹ç›®ï¼Ÿ<br>åŸºæœ¬ä¸Šæ²¡é—®ä»€ä¹ˆæŠ€æœ¯ï¼Œæˆ‘å°±è¯´äº†ä¸€éé¡¹ç›®æµç¨‹ï¼Œ<br>ç„¶åè¯´å‡ ä¸ªä¼˜åŒ–ç‚¹ï¼Œæ¯”å¦‚ä¸Šæ¬¡è®²çš„è¡€æ¡ˆï¼Œæˆ‘ä¹Ÿé¡ºå¸¦æäº†ä¸€ä¸‹ã€‚<br>2.åœ¨å¤§æ•°æ®ä¸­ï¼Œæœ‰æ²¡æœ‰ä»€ä¹ˆæ˜¯ä¸è¶³çš„ï¼Œé‡åˆ°è¿‡ä»€ä¹ˆé—®é¢˜ï¼Ÿ<br><a id="more"></a></p><p>å¾®ç›Ÿï¼š<br>1.SparkStreamingå¤„ç†å®Œä¸€æ‰¹æ¬¡çš„æ•°æ®ï¼Œå†™åç§»é‡ä¹‹å‰æŒ‚äº†ï¼Œæ•°æ®æ€ä¹ˆä¿è¯ä¸é‡ï¼Ÿ<br>2.Maxwellçš„åº•å±‚åŸç†ï¼Ÿ<br>3.æ‰‹å†™Springï¼Ÿ<br>4.éå†äºŒå‰æ ‘ï¼Ÿ<br>5.ç”¨è¿‡ä»€ä¹ˆç®—æ³•ï¼Ÿ<br>6.å¤šçº¿ç¨‹æ–¹é¢ï¼Œæ€ä¹ˆå®ç°ä¸€ä¸ªä¸»çº¿ç¨‹ï¼Œç­‰å¾…å…¶ä»–å­çº¿ç¨‹å®Œæˆåå†è¿è¡Œï¼Ÿ<br>7.Maxwellå’ŒCannalçš„æ¯”è¾ƒï¼Ÿ<br>8.directæ¯”è¾ƒreceiverçš„ä¼˜åŠ¿ï¼Ÿ<br>9.åŸæ¥æ˜¯æŠŠæ•°æ®ä¼ å…¥åˆ°Hiveï¼Œä¹‹åæ”¹äº†æ¶æ„ï¼Œæ€ä¹ˆæŠŠHiveçš„æ•°æ®å¯¼å…¥åˆ°Hbaseï¼Ÿ<br>10.ä¸ºä»€ä¹ˆç”¨Kafkaè‡ªå·±å­˜å‚¨offsetæ¥æ›¿ä»£checkpointï¼Œæ€ä¹ˆé˜²æ­¢äº†æ•°æ®åŒä»½è½åœ°ï¼Œæ•°æ®åŒä»½æ˜¯æŒ‡ä»€ä¹ˆï¼Ÿ<br>11.å•ä¾‹ç”¨è¿‡å—ï¼Ÿ</p><p>å¹³å®‰ï¼š<br>1.é—®é¡¹ç›®ï¼Œæµç¨‹ï¼Œä¸šåŠ¡ï¼Ÿ<br>2.æ•°æ®é‡ï¼Œå¢é‡ï¼Ÿ<br>3.å‡ ä¸ªäººå¼€å‘çš„ï¼Œä»£ç é‡å¤šå°‘ï¼Ÿ<br>4.ä½ ä¸»è¦åšä»€ä¹ˆçš„ï¼Ÿ<br>5.ä»€ä¹ˆåœºæ™¯ï¼Œç”¨SparkSqlåˆ†æä»€ä¹ˆä¸œè¥¿ï¼Ÿ</p><p>æ€»ç»“ï¼š<br>åŸºæœ¬ä¸Šéƒ½æ˜¯å›´ç»•é¡¹ç›®æ¥é¢ï¼Œç¬¬ä¸€å®¶é—®çš„æ¯”è¾ƒå°‘ï¼Œè€Œä¸”éƒ½æ˜¯å…³äºé¡¹ç›®ï¼›å¾®ç›Ÿçš„é¢è¯•å®˜åšçš„é¡¹ç›®ï¼Œ<br>è·Ÿç®€å†ä¸Šçš„é¡¹ç›®ï¼Œæ¶æ„ä¸ŠåŸºæœ¬ä¸€æ ·ï¼Œæ‰€ä»¥é—®çš„æ¯”è¾ƒæ·±ï¼Œé—®æˆ‘Maxwellçš„åº•å±‚åŸç†ï¼Œå¯¹æ¯”Cannalæœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Œ<br>ä¸ºä»€ä¹ˆé€‰æ‹©å®ƒï¼Œè¿™ä¸ªæˆ‘æ²¡å›ç­”ä¸Šæ¥ï¼Œåæ¥è®©æ‰‹å†™Springï¼Œç®—æ³•ï¼Œåæ¥å°±è®©æˆ‘èµ°äº†ï¼›<br>å¹³å®‰ä¹Ÿæ˜¯åŸºæœ¬å›´ç»•é¡¹ç›®ï¼Œä¸šåŠ¡ï¼Œæ•°æ®é‡ï¼Œæ²¡é—®ä»€ä¹ˆæŠ€æœ¯ï¼Œè€Œä¸”æˆ‘è¯´äº†å…³äºä¼˜åŒ–çš„ç‚¹(é¢è¯•å®˜è¯´ä¸è¦è¯´ç½‘ä¸Šéƒ½æœ‰çš„ä¸œè¥¿)ã€‚</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Sun May 19 2019 22:24:17 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;ä¼Ÿæ¢¦ï¼š&lt;br&gt;1.ä¸»è¦è¿˜æ˜¯é¡¹ç›®ï¼Ÿ&lt;br&gt;åŸºæœ¬ä¸Šæ²¡é—®ä»€ä¹ˆæŠ€æœ¯ï¼Œæˆ‘å°±è¯´äº†ä¸€éé¡¹ç›®æµç¨‹ï¼Œ&lt;br&gt;ç„¶åè¯´å‡ ä¸ªä¼˜åŒ–ç‚¹ï¼Œæ¯”å¦‚ä¸Šæ¬¡è®²çš„è¡€æ¡ˆï¼Œæˆ‘ä¹Ÿé¡ºå¸¦æäº†ä¸€ä¸‹ã€‚&lt;br&gt;2.åœ¨å¤§æ•°æ®ä¸­ï¼Œæœ‰æ²¡æœ‰ä»€ä¹ˆæ˜¯ä¸è¶³çš„ï¼Œé‡åˆ°è¿‡ä»€ä¹ˆé—®é¢˜ï¼Ÿ&lt;br&gt;
    
    </summary>
    
      <category term="é¢è¯•é¢˜" scheme="http://yoursite.com/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
    
      <category term="å¤§æ•°æ®é¢è¯•é¢˜" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>sparkä¸­é…ç½®å¯ç”¨LZOå‹ç¼©</title>
    <link href="http://yoursite.com/2018/08/20/spark%E4%B8%AD%E9%85%8D%E7%BD%AE%E5%90%AF%E7%94%A8LZO%E5%8E%8B%E7%BC%A9/"/>
    <id>http://yoursite.com/2018/08/20/sparkä¸­é…ç½®å¯ç”¨LZOå‹ç¼©/</id>
    <published>2018-08-19T16:00:00.000Z</published>
    <updated>2019-05-19T13:59:58.484Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun May 19 2019 22:03:32 GMT+0800 (GMT+08:00) --><p>Sparkä¸­é…ç½®å¯ç”¨LZOå‹ç¼©ï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š</p><h3 id="ä¸€ã€spark-env-shé…ç½®"><a href="#ä¸€ã€spark-env-shé…ç½®" class="headerlink" title="ä¸€ã€spark-env.shé…ç½®"></a>ä¸€ã€spark-env.shé…ç½®</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/app/hadoop-2.6.0-cdh5.7.0/lib/native</span><br><span class="line">export SPARK_LIBRARY_PATH=$SPARK_LIBRARY_PATH:/app/hadoop-2.6.0-cdh5.7.0/lib/native</span><br><span class="line">export SPARK_CLASSPATH=$SPARK_CLASSPATH:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/yarn/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/yarn/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/hdfs/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/hdfs/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/tools/lib/*:/app/spark-2.2.0-bin-2.6.0-cdh5.7.0/jars/*</span><br></pre></td></tr></table></figure><h3 id="äºŒã€spark-defaults-confé…ç½®"><a href="#äºŒã€spark-defaults-confé…ç½®" class="headerlink" title="äºŒã€spark-defaults.confé…ç½®"></a>äºŒã€spark-defaults.confé…ç½®</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.driver.extraClassPath /app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/hadoop-lzo-0.4.19.jar</span><br><span class="line">spark.executor.extraClassPath /app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/hadoop-lzo-0.4.19.jar</span><br></pre></td></tr></table></figure><p><font color="#FF4500">æ³¨ï¼šæŒ‡å‘ç¼–è¯‘ç”Ÿæˆlzoçš„jaråŒ…</font><br><a id="more"></a></p><h3 id="ä¸‰ã€æµ‹è¯•"><a href="#ä¸‰ã€æµ‹è¯•" class="headerlink" title="ä¸‰ã€æµ‹è¯•"></a>ä¸‰ã€æµ‹è¯•</h3><h4 id="1ã€è¯»å–Lzoæ–‡ä»¶"><a href="#1ã€è¯»å–Lzoæ–‡ä»¶" class="headerlink" title="1ã€è¯»å–Lzoæ–‡ä»¶"></a>1ã€è¯»å–Lzoæ–‡ä»¶</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spark-shell --master local[2]</span><br><span class="line">scala&gt; import com.hadoop.compression.lzo.LzopCodec</span><br><span class="line">scala&gt; val page_views = sc.textFile(&quot;/user/hive/warehouse/page_views_lzo/page_views.dat.lzo&quot;)</span><br></pre></td></tr></table></figure><h4 id="2ã€å†™å‡ºlzoæ–‡ä»¶"><a href="#2ã€å†™å‡ºlzoæ–‡ä»¶" class="headerlink" title="2ã€å†™å‡ºlzoæ–‡ä»¶"></a>2ã€å†™å‡ºlzoæ–‡ä»¶</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">spark-shell --master local[2]</span><br><span class="line">scala&gt; import com.hadoop.compression.lzo.LzopCodec</span><br><span class="line">scala&gt; val lzoTest = sc.parallelize(1 to 10)</span><br><span class="line">scala&gt; lzoTest.saveAsTextFile(&quot;/input/test_lzo&quot;, classOf[LzopCodec])</span><br></pre></td></tr></table></figure><p>ç»“æœï¼š<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@spark220 common]$ hdfs dfs -ls /input/test_lzo</span><br><span class="line">Found 3 items</span><br><span class="line">-rw-r--r--   1 hadoop supergroup          0 2018-03-16 23:24 /input/test_lzo/_SUCCESS</span><br><span class="line">-rw-r--r--   1 hadoop supergroup         60 2018-03-16 23:24 /input/test_lzo/part-00000.lzo</span><br><span class="line">-rw-r--r--   1 hadoop supergroup         61 2018-03-16 23:24 /input/test_lzo/part-00001.lzo</span><br></pre></td></tr></table></figure><p></p><p>è‡³æ­¤é…ç½®ä¸æµ‹è¯•å®Œæˆã€‚</p><h3 id="å››ã€é…ç½®ä¸æµ‹è¯•ä¸­å­˜é—®é¢˜"><a href="#å››ã€é…ç½®ä¸æµ‹è¯•ä¸­å­˜é—®é¢˜" class="headerlink" title="å››ã€é…ç½®ä¸æµ‹è¯•ä¸­å­˜é—®é¢˜"></a>å››ã€é…ç½®ä¸æµ‹è¯•ä¸­å­˜é—®é¢˜</h3><h4 id="1ã€å¼•ç”¨nativeï¼Œç¼ºå°‘LD-LIBRARY-PATH"><a href="#1ã€å¼•ç”¨nativeï¼Œç¼ºå°‘LD-LIBRARY-PATH" class="headerlink" title="1ã€å¼•ç”¨nativeï¼Œç¼ºå°‘LD_LIBRARY_PATH"></a>1ã€å¼•ç”¨nativeï¼Œç¼ºå°‘LD_LIBRARY_PATH</h4><h5 id="1-1ã€é”™è¯¯æç¤ºï¼š"><a href="#1-1ã€é”™è¯¯æç¤ºï¼š" class="headerlink" title="1.1ã€é”™è¯¯æç¤ºï¼š"></a>1.1ã€é”™è¯¯æç¤ºï¼š</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Caused by: java.lang.RuntimeException: native-lzo library not available</span><br><span class="line">  at com.hadoop.compression.lzo.LzopCodec.getDecompressorType(LzopCodec.java:120)</span><br><span class="line">  at org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:178)</span><br><span class="line">  at org.apache.hadoop.mapred.LineRecordReader.(LineRecordReader.java:111)</span><br><span class="line">  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)</span><br><span class="line">  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:246)</span><br><span class="line">  at org.apache.spark.rdd.HadoopRDD$$anon$1.(HadoopRDD.scala:245)</span><br><span class="line">  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:203)</span><br><span class="line">  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:94)</span><br><span class="line">  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)</span><br><span class="line">  at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)</span><br><span class="line">  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)</span><br><span class="line">  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)</span><br><span class="line">  at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)</span><br><span class="line">  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)</span><br><span class="line">  at org.apache.spark.scheduler.Task.run(Task.scala:108)</span><br><span class="line">  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)</span><br><span class="line">  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">  at java.lang.Thread.run(Thread.java:748)</span><br></pre></td></tr></table></figure><h5 id="1-2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-evn-shï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š"><a href="#1-2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-evn-shï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š" class="headerlink" title="1.2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-evn.shï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š"></a>1.2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-evn.shï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/app/hadoop-2.6.0-cdh5.7.0/lib/native</span><br><span class="line">export SPARK_LIBRARY_PATH=$SPARK_LIBRARY_PATH:/app/hadoop-2.6.0-cdh5.7.0/lib/native</span><br><span class="line">export SPARK_CLASSPATH=$SPARK_CLASSPATH:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/yarn/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/yarn/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/hdfs/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/hdfs/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/tools/lib/*:/app/spark-2.2.0-bin-2.6.0-cdh5.7.0/jars/*</span><br></pre></td></tr></table></figure><h4 id="2ã€æ— æ³•æ‰¾åˆ°LzopCodecç±»"><a href="#2ã€æ— æ³•æ‰¾åˆ°LzopCodecç±»" class="headerlink" title="2ã€æ— æ³•æ‰¾åˆ°LzopCodecç±»"></a>2ã€æ— æ³•æ‰¾åˆ°LzopCodecç±»</h4><h5 id="2-1ã€é”™è¯¯æç¤ºï¼š"><a href="#2-1ã€é”™è¯¯æç¤ºï¼š" class="headerlink" title="2.1ã€é”™è¯¯æç¤ºï¼š"></a>2.1ã€é”™è¯¯æç¤ºï¼š</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Caused by: java.lang.IllegalArgumentException: Compression codec com.hadoop.compression.lzo.LzopCodec not found.</span><br><span class="line">    at org.apache.hadoop.io.compress.CompressionCodecFactory.getCodecClasses(CompressionCodecFactory.java:135)</span><br><span class="line">    at org.apache.hadoop.io.compress.CompressionCodecFactory.&lt;init&gt;(CompressionCodecFactory.java:175)</span><br><span class="line">    at org.apache.hadoop.mapred.TextInputFormat.configure(TextInputFormat.java:45)</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: Class com.hadoop.compression.lzo.LzopCodec not found</span><br><span class="line">    at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1980)</span><br><span class="line">    at org.apache.hadoop.io.compress.CompressionCodecFactory.getCodecClasses(CompressionCodecFactory.java:128)</span><br></pre></td></tr></table></figure><h5 id="2-2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-defaults-confï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š"><a href="#2-2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-defaults-confï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š" class="headerlink" title="2.2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-defaults.confï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š"></a>2.2ã€è§£å†³åŠæ³•ï¼šåœ¨sparkçš„confä¸­é…ç½®spark-defaults.confï¼Œå¢åŠ ä»¥ä¸‹å†…å®¹ï¼š</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">spark.driver.extraClassPath /app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/hadoop-lzo-0.4.19.jar</span><br><span class="line">spark.executor.extraClassPath /app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/hadoop-lzo-0.4.19.ja</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Sun May 19 2019 22:03:32 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;Sparkä¸­é…ç½®å¯ç”¨LZOå‹ç¼©ï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š&lt;/p&gt;&lt;h3 id=&quot;ä¸€ã€spark-env-shé…ç½®&quot;&gt;&lt;a href=&quot;#ä¸€ã€spark-env-shé…ç½®&quot; class=&quot;headerlink&quot; title=&quot;ä¸€ã€spark-env.shé…ç½®&quot;&gt;&lt;/a&gt;ä¸€ã€spark-env.shé…ç½®&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/app/hadoop-2.6.0-cdh5.7.0/lib/native&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export SPARK_LIBRARY_PATH=$SPARK_LIBRARY_PATH:/app/hadoop-2.6.0-cdh5.7.0/lib/native&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export SPARK_CLASSPATH=$SPARK_CLASSPATH:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/yarn/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/yarn/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/hdfs/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/hdfs/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/lib/*:/app/hadoop-2.6.0-cdh5.7.0/share/hadoop/tools/lib/*:/app/spark-2.2.0-bin-2.6.0-cdh5.7.0/jars/*&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h3 id=&quot;äºŒã€spark-defaults-confé…ç½®&quot;&gt;&lt;a href=&quot;#äºŒã€spark-defaults-confé…ç½®&quot; class=&quot;headerlink&quot; title=&quot;äºŒã€spark-defaults.confé…ç½®&quot;&gt;&lt;/a&gt;äºŒã€spark-defaults.confé…ç½®&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;spark.driver.extraClassPath /app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/hadoop-lzo-0.4.19.jar&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;spark.executor.extraClassPath /app/hadoop-2.6.0-cdh5.7.0/share/hadoop/common/hadoop-lzo-0.4.19.jar&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;font color=&quot;#FF4500&quot;&gt;æ³¨ï¼šæŒ‡å‘ç¼–è¯‘ç”Ÿæˆlzoçš„jaråŒ…&lt;/font&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>HDFSä¹‹åƒåœ¾å›æ”¶ç®±é…ç½®åŠä½¿ç”¨</title>
    <link href="http://yoursite.com/2018/07/18/HDFS%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%B1%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BD%BF%E7%94%A8/"/>
    <id>http://yoursite.com/2018/07/18/HDFSä¹‹åƒåœ¾å›æ”¶ç®±é…ç½®åŠä½¿ç”¨/</id>
    <published>2018-07-17T16:00:00.000Z</published>
    <updated>2019-05-19T13:53:51.770Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun May 19 2019 22:03:32 GMT+0800 (GMT+08:00) --><p>HDFSä¸ºæ¯ä¸ªç”¨æˆ·åˆ›å»ºä¸€ä¸ªå›æ”¶ç«™:<br>ç›®å½•:/user/ç”¨æˆ·/.Trash/Current, ç³»ç»Ÿå›æ”¶ç«™éƒ½æœ‰ä¸€ä¸ªå‘¨æœŸ,å‘¨æœŸè¿‡åhdfsä¼šå½»åº•åˆ é™¤æ¸…ç©º,å‘¨æœŸå†…å¯ä»¥æ¢å¤ã€‚<br><a id="more"></a></p><h4 id="ä¸€ã€HDFSåˆ é™¤æ–‡ä»¶-æ— æ³•æ¢å¤"><a href="#ä¸€ã€HDFSåˆ é™¤æ–‡ä»¶-æ— æ³•æ¢å¤" class="headerlink" title="ä¸€ã€HDFSåˆ é™¤æ–‡ä»¶,æ— æ³•æ¢å¤"></a>ä¸€ã€HDFSåˆ é™¤æ–‡ä»¶,æ— æ³•æ¢å¤</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 opt]$ hdfs dfs -rm /123.log</span><br><span class="line">Deleted /123.log</span><br></pre></td></tr></table></figure><h4 id="äºŒã€-å¯ç”¨å›æ”¶ç«™åŠŸèƒ½"><a href="#äºŒã€-å¯ç”¨å›æ”¶ç«™åŠŸèƒ½" class="headerlink" title="äºŒã€ å¯ç”¨å›æ”¶ç«™åŠŸèƒ½"></a>äºŒã€ å¯ç”¨å›æ”¶ç«™åŠŸèƒ½</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vim core-site.xml</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;!--å¤šé•¿æ—¶é—´åˆ›å»ºCheckPoint NameNodeèŠ‚ç‚¹ä¸Šè¿è¡Œçš„CheckPointer </span><br><span class="line">ä»Currentæ–‡ä»¶å¤¹åˆ›å»ºCheckPoint; é»˜è®¤: 0 ç”±fs.trash.intervalé¡¹æŒ‡å®š --&gt;</span><br><span class="line">&lt;name&gt;fs.trash.checkpoint.interval&lt;/name&gt;</span><br><span class="line">&lt;value&gt;0&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;!--å¤šå°‘åˆ†é’Ÿ.Trashä¸‹çš„CheckPointç›®å½•ä¼šè¢«åˆ é™¤,</span><br><span class="line">è¯¥é…ç½®æœåŠ¡å™¨è®¾ç½®ä¼˜å…ˆçº§å¤§äºå®¢æˆ·ç«¯ï¼Œé»˜è®¤:ä¸å¯ç”¨ --&gt;</span><br><span class="line">    &lt;name&gt;fs.trash.interval&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1440&lt;/value&gt;  -- æ¸…é™¤å‘¨æœŸåˆ†é’Ÿ(24å°æ—¶)</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h5 id="1ã€é‡å¯hdfsæœåŠ¡"><a href="#1ã€é‡å¯hdfsæœåŠ¡" class="headerlink" title="1ã€é‡å¯hdfsæœåŠ¡"></a>1ã€é‡å¯hdfsæœåŠ¡</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 sbin]$ ./stop-dfs.sh</span><br><span class="line">[hadoop@hadoop001 sbin]$ ./start-dfs.sh</span><br></pre></td></tr></table></figure><h5 id="2ã€æµ‹è¯•å›æ”¶ç«™åŠŸèƒ½"><a href="#2ã€æµ‹è¯•å›æ”¶ç«™åŠŸèƒ½" class="headerlink" title="2ã€æµ‹è¯•å›æ”¶ç«™åŠŸèƒ½"></a>2ã€æµ‹è¯•å›æ”¶ç«™åŠŸèƒ½</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 opt]$ hdfs dfs -put 123.log /</span><br><span class="line">[hadoop@hadoop001 opt]$ hdfs dfs -ls /</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        162 2018-05-23 11:30 /123.log</span><br></pre></td></tr></table></figure><h5 id="æ–‡ä»¶åˆ é™¤æˆåŠŸå­˜æ”¾å›æ”¶ç«™è·¯å¾„ä¸‹"><a href="#æ–‡ä»¶åˆ é™¤æˆåŠŸå­˜æ”¾å›æ”¶ç«™è·¯å¾„ä¸‹" class="headerlink" title="æ–‡ä»¶åˆ é™¤æˆåŠŸå­˜æ”¾å›æ”¶ç«™è·¯å¾„ä¸‹"></a>æ–‡ä»¶åˆ é™¤æˆåŠŸå­˜æ”¾å›æ”¶ç«™è·¯å¾„ä¸‹</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 opt]$ hdfs dfs -rm /123.log</span><br><span class="line">18/05/23 11:32:50 INFO fs.TrashPolicyDefault: Moved: &apos;hdfs://192.168.0.129:9000/123.log&apos; to trash at: hdfs://192.168.0.129:9000/user/hadoop/.Trash/Current/123.log</span><br><span class="line">[hadoop@hadoop001 opt]$ hdfs dfs -ls /</span><br><span class="line">Found 1 items</span><br><span class="line">drwx------   - hadoop supergroup          0 2018-05-23 11:32 /user</span><br></pre></td></tr></table></figure><h5 id="æ¢å¤æ–‡ä»¶"><a href="#æ¢å¤æ–‡ä»¶" class="headerlink" title="æ¢å¤æ–‡ä»¶"></a>æ¢å¤æ–‡ä»¶</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ hdfs dfs -mv /user/hadoop/.Trash/Current/123.log /456.log</span><br><span class="line">[hadoop@hadoop001 ~]$ hdfs dfs -ls /</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   1 hadoop supergroup        162 2018-05-23 11:30 /456.log</span><br><span class="line">drwx------   - hadoop supergroup          0 2018-05-23 11:32 /user</span><br></pre></td></tr></table></figure><h5 id="åˆ é™¤æ–‡ä»¶è·³è¿‡å›æ”¶ç«™"><a href="#åˆ é™¤æ–‡ä»¶è·³è¿‡å›æ”¶ç«™" class="headerlink" title="åˆ é™¤æ–‡ä»¶è·³è¿‡å›æ”¶ç«™"></a>åˆ é™¤æ–‡ä»¶è·³è¿‡å›æ”¶ç«™</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop000 hadoop]$ hdfs dfs -rm -skipTrash /rz.log1</span><br><span class="line">[hadoop@hadoop001 ~]$ hdfs dfs -rm -skipTrash /456.log</span><br><span class="line">Deleted /456.log</span><br></pre></td></tr></table></figure><p>æºç å‚è€ƒï¼š<br><a href="https://blog.csdn.net/tracymkgld/article/details/17557655" target="_blank" rel="noopener">https://blog.csdn.net/tracymkgld/article/details/17557655</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Sun May 19 2019 22:03:32 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;HDFSä¸ºæ¯ä¸ªç”¨æˆ·åˆ›å»ºä¸€ä¸ªå›æ”¶ç«™:&lt;br&gt;ç›®å½•:/user/ç”¨æˆ·/.Trash/Current, ç³»ç»Ÿå›æ”¶ç«™éƒ½æœ‰ä¸€ä¸ªå‘¨æœŸ,å‘¨æœŸè¿‡åhdfsä¼šå½»åº•åˆ é™¤æ¸…ç©º,å‘¨æœŸå†…å¯ä»¥æ¢å¤ã€‚&lt;br&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Sparkåºåˆ—åŒ–ï¼Œä½ äº†è§£å—</title>
    <link href="http://yoursite.com/2018/07/16/Spark%E5%BA%8F%E5%88%97%E5%8C%96%EF%BC%8C%E4%BD%A0%E4%BA%86%E8%A7%A3%E5%90%97/"/>
    <id>http://yoursite.com/2018/07/16/Sparkåºåˆ—åŒ–ï¼Œä½ äº†è§£å—/</id>
    <published>2018-07-15T16:00:00.000Z</published>
    <updated>2019-05-17T14:24:36.362Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri May 17 2019 22:28:01 GMT+0800 (GMT+08:00) --><p>åºåˆ—åŒ–åœ¨åˆ†å¸ƒå¼åº”ç”¨çš„æ€§èƒ½ä¸­æ‰®æ¼”ç€é‡è¦çš„è§’è‰²ã€‚æ ¼å¼åŒ–å¯¹è±¡ç¼“æ…¢ï¼Œæˆ–è€…æ¶ˆè€—å¤§é‡çš„å­—èŠ‚æ ¼å¼åŒ–ï¼Œä¼šå¤§å¤§é™ä½è®¡ç®—æ€§èƒ½ã€‚é€šå¸¸è¿™æ˜¯åœ¨sparkåº”ç”¨ä¸­ç¬¬ä¸€ä»¶éœ€è¦ä¼˜åŒ–çš„äº‹æƒ…ã€‚Sparkçš„ç›®æ ‡æ˜¯åœ¨ä¾¿åˆ©ä¸æ€§èƒ½ä¸­å–å¾—å¹³è¡¡ï¼Œæ‰€ä»¥æä¾›2ç§åºåˆ—åŒ–çš„é€‰æ‹©ã€‚<br><a id="more"></a></p><h3 id="Java-serialization"><a href="#Java-serialization" class="headerlink" title="Java serialization"></a>Java serialization</h3><p>åœ¨é»˜è®¤æƒ…å†µä¸‹ï¼ŒSparkä¼šä½¿ç”¨Javaçš„ObjectOutputStreamæ¡†æ¶å¯¹å¯¹è±¡è¿›è¡Œåºåˆ—åŒ–ï¼Œå¹¶ä¸”å¯ä»¥ä¸ä»»ä½•å®ç°java.io.Serializableçš„ç±»ä¸€èµ·å·¥ä½œã€‚æ‚¨è¿˜å¯ä»¥é€šè¿‡æ‰©å±•java.io.Externalizableæ¥æ›´ç´§å¯†åœ°æ§åˆ¶åºåˆ—åŒ–çš„æ€§èƒ½ã€‚Javaåºåˆ—åŒ–æ˜¯çµæ´»çš„ï¼Œä½†é€šå¸¸ç›¸å½“æ…¢ï¼Œå¹¶ä¸”ä¼šå¯¼è‡´è®¸å¤šç±»çš„å¤§å‹åºåˆ—åŒ–æ ¼å¼ã€‚</p><h4 id="æµ‹è¯•ä»£ç ï¼š"><a href="#æµ‹è¯•ä»£ç ï¼š" class="headerlink" title="æµ‹è¯•ä»£ç ï¼š"></a>æµ‹è¯•ä»£ç ï¼š</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">package com.hihi.learn.sparkCore</span><br><span class="line"></span><br><span class="line">import org.apache.spark.storage.StorageLevel</span><br><span class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line"></span><br><span class="line">import scala.collection.mutable.ArrayBuffer</span><br><span class="line"></span><br><span class="line">case class Student(id: String, name: String, age: Int, gender: String)</span><br><span class="line"></span><br><span class="line">object SerializationDemo &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val conf = new SparkConf().setMaster(&quot;local[2]&quot;).setAppName(&quot;SerializationDemo&quot;)</span><br><span class="line">    val sc = new SparkContext(conf)</span><br><span class="line"></span><br><span class="line">    val stduentArr = new ArrayBuffer[Student]()</span><br><span class="line">    for (i &lt;- 1 to 1000000) &#123;</span><br><span class="line">      stduentArr += (Student(i + &quot;&quot;, i + &quot;a&quot;, 10, &quot;male&quot;))</span><br><span class="line">    &#125;</span><br><span class="line">    val JavaSerialization = sc.parallelize(stduentArr)</span><br><span class="line">    JavaSerialization.persist(StorageLevel.MEMORY_ONLY_SER).count()</span><br><span class="line"></span><br><span class="line">    while(true) &#123;</span><br><span class="line">      Thread.sleep(10000)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h4 id="æµ‹è¯•ç»“æœï¼š"><a href="#æµ‹è¯•ç»“æœï¼š" class="headerlink" title="æµ‹è¯•ç»“æœï¼š"></a>æµ‹è¯•ç»“æœï¼š</h4><p><img src="/assets/blogImg/716_1.png" alt="enter description here"></p><h3 id="Kryo-serialization"><a href="#Kryo-serialization" class="headerlink" title="Kryo serialization"></a>Kryo serialization</h3><p>Sparkè¿˜å¯ä»¥ä½¿ç”¨Kryoåº“ï¼ˆç‰ˆæœ¬2ï¼‰æ¥æ›´å¿«åœ°åºåˆ—åŒ–å¯¹è±¡ã€‚Kryoæ¯”Javaä¸²è¡ŒåŒ–ï¼ˆé€šå¸¸å¤šè¾¾10å€ï¼‰è¦å¿«å¾—å¤šï¼Œä¹Ÿæ›´ç´§å‡‘ï¼Œä½†æ˜¯ä¸æ”¯æŒæ‰€æœ‰å¯ä¸²è¡ŒåŒ–ç±»å‹ï¼Œå¹¶ä¸”è¦æ±‚æ‚¨æå‰æ³¨å†Œæ‚¨å°†åœ¨ç¨‹åºä¸­ä½¿ç”¨çš„ç±»ï¼Œä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚</p><h4 id="æµ‹è¯•ä»£ç ï¼š-1"><a href="#æµ‹è¯•ä»£ç ï¼š-1" class="headerlink" title="æµ‹è¯•ä»£ç ï¼š"></a>æµ‹è¯•ä»£ç ï¼š</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">package com.hihi.learn.sparkCore</span><br><span class="line"></span><br><span class="line">import org.apache.spark.storage.StorageLevel</span><br><span class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line"></span><br><span class="line">import scala.collection.mutable.ArrayBuffer</span><br><span class="line"></span><br><span class="line">case class Student(id: String, name: String, age: Int, gender: String)</span><br><span class="line"></span><br><span class="line">object SerializationDemo &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val conf = new SparkConf()</span><br><span class="line">      .setMaster(&quot;local[2]&quot;)</span><br><span class="line">      .setAppName(&quot;SerializationDemo&quot;)</span><br><span class="line">      .set(&quot;spark.serializer&quot;,&quot;org.apache.spark.serializer.KryoSerializer&quot;)</span><br><span class="line">    val sc = new SparkContext(conf)</span><br><span class="line"></span><br><span class="line">    val stduentArr = new ArrayBuffer[Student]()</span><br><span class="line">    for (i &lt;- 1 to 1000000) &#123;</span><br><span class="line">      stduentArr += (Student(i + &quot;&quot;, i + &quot;a&quot;, 10, &quot;male&quot;))</span><br><span class="line">    &#125;</span><br><span class="line">    val JavaSerialization = sc.parallelize(stduentArr)</span><br><span class="line">    JavaSerialization.persist(StorageLevel.MEMORY_ONLY_SER).count()</span><br><span class="line"></span><br><span class="line">    while(true) &#123;</span><br><span class="line">      Thread.sleep(10000)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p><img src="/assets/blogImg/716_2.png" alt="enter description here"><br>æµ‹è¯•ç»“æœä¸­å‘ç°ï¼Œä½¿ç”¨ Kryo serialization çš„åºåˆ—åŒ–å¯¹è±¡ æ¯”ä½¿ç”¨ Java serializationçš„åºåˆ—åŒ–å¯¹è±¡è¦å¤§ï¼Œä¸æè¿°çš„ä¸ä¸€æ ·ï¼Œè¿™æ˜¯ä¸ºä»€ä¹ˆå‘¢ï¼Ÿ<br>æŸ¥æ‰¾å®˜ç½‘ï¼Œå‘ç°è¿™ä¹ˆä¸€å¥è¯ Finally, if you donâ€™t register your custom classes, Kryo will still work, but it will have to store the full class name with each object, which is wasteful.ã€‚<br>ä¿®æ”¹ä»£ç ååœ¨æµ‹è¯•ä¸€æ¬¡<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">package com.hihi.learn.sparkCore</span><br><span class="line"></span><br><span class="line">import org.apache.spark.storage.StorageLevel</span><br><span class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line"></span><br><span class="line">import scala.collection.mutable.ArrayBuffer</span><br><span class="line"></span><br><span class="line">case class Student(id: String, name: String, age: Int, gender: String)</span><br><span class="line"></span><br><span class="line">object SerializationDemo &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val conf = new SparkConf()</span><br><span class="line">      .setMaster(&quot;local[2]&quot;)</span><br><span class="line">      .setAppName(&quot;SerializationDemo&quot;)</span><br><span class="line">      .set(&quot;spark.serializer&quot;,&quot;org.apache.spark.serializer.KryoSerializer&quot;)</span><br><span class="line">      .registerKryoClasses(Array(classOf[Student])) // å°†è‡ªå®šä¹‰çš„ç±»æ³¨å†Œåˆ°Kryo</span><br><span class="line">    val sc = new SparkContext(conf)</span><br><span class="line"></span><br><span class="line">    val stduentArr = new ArrayBuffer[Student]()</span><br><span class="line">    for (i &lt;- 1 to 1000000) &#123;</span><br><span class="line">      stduentArr += (Student(i + &quot;&quot;, i + &quot;a&quot;, 10, &quot;male&quot;))</span><br><span class="line">    &#125;</span><br><span class="line">    val JavaSerialization = sc.parallelize(stduentArr)</span><br><span class="line">    JavaSerialization.persist(StorageLevel.MEMORY_ONLY_SER).count()</span><br><span class="line"></span><br><span class="line">    while(true) &#123;</span><br><span class="line">      Thread.sleep(10000)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p></p><h4 id="æµ‹è¯•ç»“æœï¼š-1"><a href="#æµ‹è¯•ç»“æœï¼š-1" class="headerlink" title="æµ‹è¯•ç»“æœï¼š"></a>æµ‹è¯•ç»“æœï¼š</h4><p><img src="/assets/blogImg/716_3.png" alt="enter description here"></p><h3 id="æ€»ç»“ï¼š"><a href="#æ€»ç»“ï¼š" class="headerlink" title="æ€»ç»“ï¼š"></a>æ€»ç»“ï¼š</h3><p>Kryo serialization æ€§èƒ½å’Œåºåˆ—åŒ–å¤§å°éƒ½æ¯”é»˜è®¤æä¾›çš„ Java serialization è¦å¥½ï¼Œä½†æ˜¯ä½¿ç”¨Kryoéœ€è¦å°†è‡ªå®šä¹‰çš„ç±»å…ˆæ³¨å†Œè¿›å»ï¼Œä½¿ç”¨èµ·æ¥æ¯”Java serializationéº»çƒ¦ã€‚è‡ªä»Spark 2.0.0ä»¥æ¥ï¼Œæˆ‘ä»¬åœ¨ä½¿ç”¨ç®€å•ç±»å‹ã€ç®€å•ç±»å‹æ•°ç»„æˆ–å­—ç¬¦ä¸²ç±»å‹çš„ç®€å•ç±»å‹æ¥è°ƒæ•´RDDsæ—¶ï¼Œåœ¨å†…éƒ¨ä½¿ç”¨Kryoåºåˆ—åŒ–å™¨ã€‚<br>é€šè¿‡æŸ¥æ‰¾sparkcontextåˆå§‹åŒ–çš„æºç ï¼Œå¯ä»¥å‘ç°æŸäº›ç±»å‹å·²ç»åœ¨sparkcontextåˆå§‹åŒ–çš„æ—¶å€™è¢«æ³¨å†Œè¿›å»ã€‚<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"> /**</span><br><span class="line"> * Component which configures serialization, compression and encryption for various Spark</span><br><span class="line"> * components, including automatic selection of which [[Serializer]] to use for shuffles.</span><br><span class="line"> */</span><br><span class="line">private[spark] class SerializerManager(</span><br><span class="line">    defaultSerializer: Serializer,</span><br><span class="line">    conf: SparkConf,</span><br><span class="line">    encryptionKey: Option[Array[Byte]]) &#123;</span><br><span class="line"></span><br><span class="line">  def this(defaultSerializer: Serializer, conf: SparkConf) = this(defaultSerializer, conf, None)</span><br><span class="line"></span><br><span class="line">  private[this] val kryoSerializer = new KryoSerializer(conf)</span><br><span class="line"></span><br><span class="line">  private[this] val stringClassTag: ClassTag[String] = implicitly[ClassTag[String]]</span><br><span class="line">  private[this] val primitiveAndPrimitiveArrayClassTags: Set[ClassTag[_]] = &#123;</span><br><span class="line">    val primitiveClassTags = Set[ClassTag[_]](</span><br><span class="line">      ClassTag.Boolean,</span><br><span class="line">      ClassTag.Byte,</span><br><span class="line">      ClassTag.Char,</span><br><span class="line">      ClassTag.Double,</span><br><span class="line">      ClassTag.Float,</span><br><span class="line">      ClassTag.Int,</span><br><span class="line">      ClassTag.Long,</span><br><span class="line">      ClassTag.Null,</span><br><span class="line">      ClassTag.Short</span><br><span class="line">    )</span><br><span class="line">    val arrayClassTags = primitiveClassTags.map(_.wrap)</span><br><span class="line">    primitiveClassTags ++ arrayClassTags</span><br></pre></td></tr></table></figure><p></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Fri May 17 2019 22:28:01 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;åºåˆ—åŒ–åœ¨åˆ†å¸ƒå¼åº”ç”¨çš„æ€§èƒ½ä¸­æ‰®æ¼”ç€é‡è¦çš„è§’è‰²ã€‚æ ¼å¼åŒ–å¯¹è±¡ç¼“æ…¢ï¼Œæˆ–è€…æ¶ˆè€—å¤§é‡çš„å­—èŠ‚æ ¼å¼åŒ–ï¼Œä¼šå¤§å¤§é™ä½è®¡ç®—æ€§èƒ½ã€‚é€šå¸¸è¿™æ˜¯åœ¨sparkåº”ç”¨ä¸­ç¬¬ä¸€ä»¶éœ€è¦ä¼˜åŒ–çš„äº‹æƒ…ã€‚Sparkçš„ç›®æ ‡æ˜¯åœ¨ä¾¿åˆ©ä¸æ€§èƒ½ä¸­å–å¾—å¹³è¡¡ï¼Œæ‰€ä»¥æä¾›2ç§åºåˆ—åŒ–çš„é€‰æ‹©ã€‚&lt;br&gt;
    
    </summary>
    
      <category term="Spark Core" scheme="http://yoursite.com/categories/Spark-Core/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark Streaming çŠ¶æ€ç®¡ç†å‡½æ•°ï¼Œä½ äº†è§£å—</title>
    <link href="http://yoursite.com/2018/06/25/Spark%20Streaming%20%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86%E5%87%BD%E6%95%B0%EF%BC%8C%E4%BD%A0%E4%BA%86%E8%A7%A3%E5%90%97/"/>
    <id>http://yoursite.com/2018/06/25/Spark Streaming çŠ¶æ€ç®¡ç†å‡½æ•°ï¼Œä½ äº†è§£å—/</id>
    <published>2018-06-24T16:00:00.000Z</published>
    <updated>2019-05-16T11:42:29.333Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu May 16 2019 19:43:16 GMT+0800 (GMT+08:00) --><a id="more"></a><p>Spark Streaming çŠ¶æ€ç®¡ç†å‡½æ•°åŒ…æ‹¬updateStateByKeyå’ŒmapWithState</p><h4 id="ä¸€ã€updateStateByKey"><a href="#ä¸€ã€updateStateByKey" class="headerlink" title="ä¸€ã€updateStateByKey"></a>ä¸€ã€updateStateByKey</h4><p>å®˜ç½‘åŸè¯ï¼šIn every batch, Spark will apply the state update function for all existing keys, regardless of whether they have new data in a batch or not. If the update function returns None then the key-value pair will be eliminated.</p><p>ç»Ÿè®¡å…¨å±€çš„keyçš„çŠ¶æ€ï¼Œä½†æ˜¯å°±ç®—æ²¡æœ‰æ•°æ®è¾“å…¥ï¼Œä»–ä¹Ÿä¼šåœ¨æ¯ä¸€ä¸ªæ‰¹æ¬¡çš„æ—¶å€™è¿”å›ä¹‹å‰çš„keyçš„çŠ¶æ€ã€‚</p><p>è¿™æ ·çš„ç¼ºç‚¹ï¼šå¦‚æœæ•°æ®é‡å¤ªå¤§çš„è¯ï¼Œæˆ‘ä»¬éœ€è¦checkpointæ•°æ®ä¼šå ç”¨è¾ƒå¤§çš„å­˜å‚¨ã€‚è€Œä¸”æ•ˆç‡ä¹Ÿä¸é«˜<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">//[root@bda3 ~]# nc -lk 9999  </span><br><span class="line">object StatefulWordCountApp &#123;  </span><br><span class="line"></span><br><span class="line">  def main(args: Array[String]) &#123;  </span><br><span class="line">    StreamingExamples.setStreamingLogLevels()  </span><br><span class="line">    val sparkConf = new SparkConf()  </span><br><span class="line">      .setAppName(&quot;StatefulWordCountApp&quot;)  </span><br><span class="line">      .setMaster(&quot;local[2]&quot;)  </span><br><span class="line">    val ssc = new StreamingContext(sparkConf, Seconds(10))  </span><br><span class="line">    //æ³¨æ„ï¼šupdateStateByKeyå¿…é¡»è®¾ç½®checkpointç›®å½•  </span><br><span class="line">    ssc.checkpoint(&quot;hdfs://bda2:8020/logs/realtime&quot;)  </span><br><span class="line"></span><br><span class="line">    val lines = ssc.socketTextStream(&quot;bda3&quot;,9999)  </span><br><span class="line"></span><br><span class="line">    lines.flatMap(_.split(&quot;,&quot;)).map((_,1))  </span><br><span class="line">      .updateStateByKey(updateFunction).print()  </span><br><span class="line"></span><br><span class="line">    ssc.start()  // ä¸€å®šè¦å†™  </span><br><span class="line">    ssc.awaitTermination()  </span><br><span class="line">  &#125;  </span><br><span class="line">  /*çŠ¶æ€æ›´æ–°å‡½æ•°  </span><br><span class="line">  * @param currentValues  keyç›¸åŒvalueå½¢æˆçš„åˆ—è¡¨  </span><br><span class="line">  * @param preValues      keyå¯¹åº”çš„valueï¼Œå‰ä¸€çŠ¶æ€  </span><br><span class="line">  * */  </span><br><span class="line">  def updateFunction(currentValues: Seq[Int], preValues: Option[Int]): Option[Int] = &#123;  </span><br><span class="line">    val curr = currentValues.sum   //seqåˆ—è¡¨ä¸­æ‰€æœ‰valueæ±‚å’Œ  </span><br><span class="line">    val pre = preValues.getOrElse(0)  //è·å–ä¸Šä¸€çŠ¶æ€å€¼  </span><br><span class="line">    Some(curr + pre)  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h4 id="äºŒã€mapWithState-æ•ˆç‡æ›´é«˜ï¼Œç”Ÿäº§ä¸­å»ºè®®ä½¿ç”¨"><a href="#äºŒã€mapWithState-æ•ˆç‡æ›´é«˜ï¼Œç”Ÿäº§ä¸­å»ºè®®ä½¿ç”¨" class="headerlink" title="äºŒã€mapWithState  (æ•ˆç‡æ›´é«˜ï¼Œç”Ÿäº§ä¸­å»ºè®®ä½¿ç”¨)"></a>äºŒã€mapWithState (æ•ˆç‡æ›´é«˜ï¼Œç”Ÿäº§ä¸­å»ºè®®ä½¿ç”¨)</h4><p>mapWithStateï¼šä¹Ÿæ˜¯ç”¨äºå…¨å±€ç»Ÿè®¡keyçš„çŠ¶æ€ï¼Œä½†æ˜¯å®ƒå¦‚æœæ²¡æœ‰æ•°æ®è¾“å…¥ï¼Œä¾¿ä¸ä¼šè¿”å›ä¹‹å‰çš„keyçš„çŠ¶æ€ï¼Œæœ‰ä¸€ç‚¹å¢é‡çš„æ„Ÿè§‰ã€‚</p><p>è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥åªæ˜¯å…³å¿ƒé‚£äº›å·²ç»å‘ç”Ÿçš„å˜åŒ–çš„keyï¼Œå¯¹äºæ²¡æœ‰æ•°æ®è¾“å…¥ï¼Œåˆ™ä¸ä¼šè¿”å›é‚£äº›æ²¡æœ‰å˜åŒ–çš„keyçš„æ•°æ®ã€‚è¿™æ ·çš„è¯ï¼Œå³ä½¿æ•°æ®é‡å¾ˆå¤§ï¼Œcheckpointä¹Ÿä¸ä¼šåƒupdateStateByKeyé‚£æ ·ï¼Œå ç”¨å¤ªå¤šçš„å­˜å‚¨ã€‚</p><p>å®˜æ–¹ä»£ç å¦‚ä¸‹ï¼š<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">/**  </span><br><span class="line"> * Counts words cumulatively in UTF8 encoded, &apos;\n&apos; delimited text received from the network every  </span><br><span class="line"> * second starting with initial value of word count.  </span><br><span class="line"> * Usage: StatefulNetworkWordCount &lt;hostname&gt; &lt;port&gt;  </span><br><span class="line"> *   &lt;hostname&gt; and &lt;port&gt; describe the TCP server that Spark Streaming would connect to receive  </span><br><span class="line"> *   data.  </span><br><span class="line"> *  </span><br><span class="line"> * To run this on your local machine, you need to first run a Netcat server  </span><br><span class="line"> *    `$ nc -lk 9999`  </span><br><span class="line"> * and then run the example  </span><br><span class="line"> *    `$ bin/run-example  </span><br><span class="line"> *      org.apache.spark.examples.streaming.StatefulNetworkWordCount localhost 9999`  </span><br><span class="line"> */  </span><br><span class="line">object StatefulNetworkWordCount &#123;  </span><br><span class="line">  def main(args: Array[String]) &#123;  </span><br><span class="line">    if (args.length &lt; 2) &#123;  </span><br><span class="line">      System.err.println(&quot;Usage: StatefulNetworkWordCount &lt;hostname&gt; &lt;port&gt;&quot;)  </span><br><span class="line">      System.exit(1)  </span><br><span class="line">    &#125;  </span><br><span class="line"></span><br><span class="line">    StreamingExamples.setStreamingLogLevels()  </span><br><span class="line"></span><br><span class="line">    val sparkConf = new SparkConf().setAppName(&quot;StatefulNetworkWordCount&quot;)  </span><br><span class="line">    // Create the context with a 1 second batch size  </span><br><span class="line">    val ssc = new StreamingContext(sparkConf, Seconds(1))  </span><br><span class="line">    ssc.checkpoint(&quot;.&quot;)  </span><br><span class="line"></span><br><span class="line">    // Initial state RDD for mapWithState operation  </span><br><span class="line">    val initialRDD = ssc.sparkContext.parallelize(List((&quot;hello&quot;, 1), (&quot;world&quot;, 1)))  </span><br><span class="line"></span><br><span class="line">    // Create a ReceiverInputDStream on target ip:port and count the  </span><br><span class="line">    // words in input stream of \n delimited test (eg. generated by &apos;nc&apos;)  </span><br><span class="line">    val lines = ssc.socketTextStream(args(0), args(1).toInt)  </span><br><span class="line">    val words = lines.flatMap(_.split(&quot; &quot;))  </span><br><span class="line">    val wordDstream = words.map(x =&gt; (x, 1))  </span><br><span class="line"></span><br><span class="line">    // Update the cumulative count using mapWithState  </span><br><span class="line">    // This will give a DStream made of state (which is the cumulative count of the words)  </span><br><span class="line">    val mappingFunc = (word: String, one: Option[Int], state: State[Int]) =&gt; &#123;  </span><br><span class="line">      val sum = one.getOrElse(0) + state.getOption.getOrElse(0)  </span><br><span class="line">      val output = (word, sum)  </span><br><span class="line">      state.update(sum)  </span><br><span class="line">      output  </span><br><span class="line">    &#125;  </span><br><span class="line"></span><br><span class="line">    val stateDstream = wordDstream.mapWithState(  </span><br><span class="line">      StateSpec.function(mappingFunc).initialState(initialRDD))  </span><br><span class="line">    stateDstream.print()  </span><br><span class="line">    ssc.start()  </span><br><span class="line">    ssc.awaitTermination()  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Thu May 16 2019 19:43:16 GMT+0800 (GMT+08:00) --&gt;
    
    </summary>
    
      <category term="Spark Streaming" scheme="http://yoursite.com/categories/Spark-Streaming/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>Apache Sparkå’ŒDL/AIç»“åˆï¼Œè°ä¸äº‰é”‹? æœŸå¾…Spark3.0çš„åˆ°æ¥ï¼</title>
    <link href="http://yoursite.com/2018/06/22/AI%E7%BB%93%E5%90%88%EF%BC%8C%E8%B0%81%E4%B8%8E%E4%BA%89%E9%94%8B%20/"/>
    <id>http://yoursite.com/2018/06/22/AIç»“åˆï¼Œè°ä¸äº‰é”‹ /</id>
    <published>2018-06-21T16:00:00.000Z</published>
    <updated>2019-05-15T11:48:37.756Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed May 15 2019 19:56:22 GMT+0800 (GMT+08:00) --><p><img src="/assets/blogImg/0622_1.png" alt="enter description here"><br><a id="more"></a></p><p>ä¸çŸ¥å„ä½ï¼Œæ˜¯å¦å…³æ³¨ç¤¾åŒºçš„å‘å±•ï¼Ÿå…³æ³¨Sparkå‘¢ï¼Ÿ</p><p>å®˜ç½‘çš„Sparkå›¾æ ‡å’Œè§£é‡Šè¯­å·²ç»å‘ç”Ÿå˜åŒ–äº†ã€‚</p><p>ç„¶è€Œåœ¨6-18å·ï¼Œç¤¾åŒºæå‡ºSpark and DL/AIç›¸ç»“åˆï¼Œè¿™æ— æ¯”å†ä¸€æ¬¡è¯´æ˜ï¼ŒSparkåœ¨å¤§æ•°æ®çš„åœ°ä½æ˜¯æ— æ³•æ’¼åŠ¨çš„ï¼æœŸå¾…Spark3.0çš„åˆ°æ¥ï¼</p><p>æ¥ä¸‹æ¥å¯¹SPARK-24579çš„ç¿»è¯‘:</p><p>åœ¨å¤§æ•°æ®å’Œäººå·¥æ™ºèƒ½çš„åå­—è·¯å£ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†Apache Sparkä½œä¸ºä¸€ä¸ªç»Ÿä¸€çš„åˆ†æå¼•æ“ä»¥åŠAIæ¡†æ¶å¦‚TensorFlowå’ŒApache MXNet (æ­£åœ¨å­µåŒ–ä¸­)çš„å…´èµ·åŠè¿™ä¸¤å¤§å—çš„å·¨å¤§æˆåŠŸ ã€‚</p><p>å¤§æ•°æ®å’Œäººå·¥æ™ºèƒ½éƒ½æ˜¯æ¨åŠ¨ä¼ä¸šåˆ›æ–°çš„ä¸å¯æˆ–ç¼ºçš„ç»„æˆéƒ¨åˆ†ï¼Œ ä¸¤ä¸ªç¤¾åŒºçš„å¤šæ¬¡å°è¯•ï¼Œä½¿ä»–ä»¬ç»“åˆåœ¨ä¸€èµ·ã€‚</p><p>æˆ‘ä»¬çœ‹åˆ°AIç¤¾åŒºçš„åŠªåŠ›ï¼Œä¸ºAIæ¡†æ¶å®ç°æ•°æ®è§£å†³æ–¹æ¡ˆï¼Œå¦‚TF.DATAå’ŒTF.Trorã€‚ç„¶è€Œï¼Œ50+ä¸ªæ•°æ®æºå’Œå†…ç½®SQLã€æ•°æ®æµå’Œæµç‰¹å¾ï¼ŒSparkä»ç„¶æ˜¯å¯¹äºå¤§æ•°æ®ç¤¾åŒºé€‰æ‹©ã€‚</p><p>è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬çœ‹åˆ°è®¸å¤šåŠªåŠ›,å°†DL/AIæ¡†æ¶ä¸Sparkç»“åˆèµ·æ¥ï¼Œä»¥åˆ©ç”¨å®ƒçš„åŠ›é‡ï¼Œä¾‹å¦‚ï¼ŒSparkæ•°æ®æºTFRecordsã€TensorFlowOnSpark, TensorFramesç­‰ã€‚ä½œä¸ºé¡¹ç›®Hydrogençš„ä¸€éƒ¨åˆ†ï¼Œè¿™ä¸ªSPIPå°†Spark+AIä»ä¸åŒçš„è§’åº¦ç»Ÿä¸€èµ·æ¥ã€‚</p><p>æ²¡æœ‰åœ¨Sparkå’Œå¤–éƒ¨DL/AIæ¡†æ¶ä¹‹é—´äº¤æ¢æ•°æ®ï¼Œè¿™äº›é›†æˆéƒ½æ˜¯ä¸å¯èƒ½çš„,ä¹Ÿæœ‰æ€§èƒ½é—®é¢˜ã€‚ç„¶è€Œï¼Œç›®å‰è¿˜æ²¡æœ‰ä¸€ç§æ ‡å‡†çš„æ–¹å¼æ¥äº¤æ¢æ•°æ®ï¼Œå› æ­¤å®ç°å’Œæ€§èƒ½ä¼˜åŒ–å°±é™·å…¥äº†å›°å¢ƒã€‚ä¾‹å¦‚ï¼Œåœ¨Pythonä¸­ï¼ŒTensorFlowOnSparkä½¿ç”¨Hadoop InputFormat/OutputFormatä½œä¸ºTensorFlowçš„TFRecordsï¼Œæ¥åŠ è½½å’Œä¿å­˜æ•°æ®ï¼Œå¹¶å°†RDDæ•°æ®ä¼ é€’ç»™TensorFlowã€‚TensorFramesä½¿ç”¨TensorFlowçš„Java APIï¼Œè½¬æ¢ä¸º Spark DataFrames Rows to/from TensorFlow Tensors ã€‚æˆ‘ä»¬æ€æ ·æ‰èƒ½é™ä½å¤æ‚æ€§å‘¢?</p><p>è¿™é‡Œçš„å»ºè®®æ˜¯æ ‡å‡†åŒ–Sparkå’ŒDL/AIæ¡†æ¶ä¹‹é—´çš„æ•°æ®äº¤æ¢æ¥å£(æˆ–æ ¼å¼)ï¼Œå¹¶ä¼˜åŒ–ä»/åˆ°è¿™ä¸ªæ¥å£çš„æ•°æ®è½¬æ¢ã€‚å› æ­¤ï¼ŒDL/AIæ¡†æ¶å¯ä»¥åˆ©ç”¨Sparkä»ä»»ä½•åœ°æ–¹åŠ è½½æ•°æ®ï¼Œè€Œæ— éœ€èŠ±è´¹é¢å¤–çš„ç²¾åŠ›æ„å»ºå¤æ‚çš„æ•°æ®è§£å†³æ–¹æ¡ˆï¼Œæ¯”å¦‚ä»ç”Ÿäº§æ•°æ®ä»“åº“è¯»å–ç‰¹æ€§æˆ–æµæ¨¡å‹æ¨æ–­ã€‚Sparkç”¨æˆ·å¯ä»¥ä½¿ç”¨DL/AIæ¡†æ¶ï¼Œè€Œæ— éœ€å­¦ä¹ é‚£é‡Œå®ç°çš„ç‰¹å®šæ•°æ®apiã€‚è€Œä¸”åŒæ–¹çš„å¼€å‘äººå‘˜éƒ½å¯ä»¥ç‹¬ç«‹åœ°è¿›è¡Œæ€§èƒ½ä¼˜åŒ–ï¼Œå› ä¸ºæ¥å£æœ¬èº«ä¸ä¼šå¸¦æ¥å¾ˆå¤§çš„å¼€é”€ã€‚</p><p>ISSUE: <a href="https://issues.apache.org/jira/browse/SPARK-24579" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/SPARK-24579</a><br>è‹¥æ³½æ•°æ®ï¼Œæ˜Ÿæ˜Ÿæœ¬äººæ°´å¹³æœ‰é™ï¼Œç¿»è¯‘å¤šå¤šåŒ…æ¶µã€‚</p><p>å¯¹äº†å¿˜è®°è¯´äº†ï¼Œæœ¬ISSUEæœ‰ä¸ªPDFæ–‡æ¡£ï¼Œèµ¶å¿«å»ä¸‹è½½å§ã€‚<br><a href="https://issues.apache.org/jira/secure/attachment/12928222/%5BSPARK-24579%5D%20SPIP_%20Standardize%20Optimized%20Data%20Exchange%20between%20Apache%20Spark%20and%20DL%252FAI%20Frameworks%20.pdf" target="_blank" rel="noopener">https://issues.apache.org/jira/secure/attachment/12928222/%5BSPARK-24579%5D%20SPIP_%20Standardize%20Optimized%20Data%20Exchange%20between%20Apache%20Spark%20and%20DL%252FAI%20Frameworks%20.pdf</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed May 15 2019 19:56:22 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;img src=&quot;/assets/blogImg/0622_1.png&quot; alt=&quot;enter description here&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Spark MLlib" scheme="http://yoursite.com/categories/Spark-MLlib/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>æœ€å‰æ²¿ï¼å¸¦ä½ è¯»Structured Streamingé‡é‡çº§è®ºæ–‡ï¼</title>
    <link href="http://yoursite.com/2018/06/14/%E6%9C%80%E5%89%8D%E6%B2%BF%EF%BC%81%E5%B8%A6%E4%BD%A0%E8%AF%BBStructured%20Streaming%E9%87%8D%E9%87%8F%E7%BA%A7%E8%AE%BA%E6%96%87%EF%BC%81/"/>
    <id>http://yoursite.com/2018/06/14/æœ€å‰æ²¿ï¼å¸¦ä½ è¯»Structured Streamingé‡é‡çº§è®ºæ–‡ï¼/</id>
    <published>2018-06-13T16:00:00.000Z</published>
    <updated>2019-05-15T11:45:15.951Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed May 15 2019 19:56:23 GMT+0800 (GMT+08:00) --><a id="more"></a><h4 id="1-è®ºæ–‡ä¸‹è½½åœ°å€"><a href="#1-è®ºæ–‡ä¸‹è½½åœ°å€" class="headerlink" title="1.è®ºæ–‡ä¸‹è½½åœ°å€"></a>1.è®ºæ–‡ä¸‹è½½åœ°å€</h4><p><a href="https://cs.stanford.edu/~matei/papers/2018/sigmod_structured_streaming.pdf" target="_blank" rel="noopener">https://cs.stanford.edu/~matei/papers/2018/sigmod_structured_streaming.pdf</a></p><h4 id="2-å‰è¨€"><a href="#2-å‰è¨€" class="headerlink" title="2.å‰è¨€"></a>2.å‰è¨€</h4><p>å»ºè®®é¦–å…ˆé˜…è¯»Structured Streamingå®˜ç½‘ï¼š<a href="http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html</a><br>ä»¥åŠè¿™ä¸¤ç¯‡Databricksåœ¨2016å¹´å…³äºStructured Streamingçš„æ–‡ç« ï¼š</p><p><a href="https://databricks.com/blog/2016/07/28/continuous-applications-evolving-streaming-in-apache-spark-2-0.html" target="_blank" rel="noopener">https://databricks.com/blog/2016/07/28/continuous-applications-evolving-streaming-in-apache-spark-2-0.html</a></p><p><a href="https://databricks.com/blog/2016/07/28/structured-streaming-in-apache-spark.html" target="_blank" rel="noopener">https://databricks.com/blog/2016/07/28/structured-streaming-in-apache-spark.html</a></p><p>è¨€å½’æ­£ä¼ <br>è¯¥è®ºæ–‡æ”¶å½•è‡ª2018å¹´ACM SIGMODä¼šè®®ï¼Œæ˜¯ç”±ç¾å›½è®¡ç®—æœºåä¼šï¼ˆACMï¼‰å‘èµ·çš„ã€åœ¨æ•°æ®åº“é¢†åŸŸå…·æœ‰æœ€é«˜å­¦æœ¯åœ°ä½çš„å›½é™…æ€§å­¦æœ¯ä¼šè®®ã€‚è®ºæ–‡çš„ä½œè€…ä¸ºDatabricksçš„å·¥ç¨‹å¸ˆåŠSparkçš„å¼€å‘è€…ï¼Œå…¶æƒå¨æ€§ã€é‡è¦ç¨‹åº¦ä¸è¨€è€Œå–»ã€‚æ–‡ç« å¼€å¤´ä¸ºè¯¥è®ºæ–‡çš„ä¸‹è½½åœ°å€ï¼Œä¾›è¯»è€…é˜…è¯»äº¤æµã€‚æœ¬æ–‡å¯¹è¯¥è®ºæ–‡è¿›è¡Œç®€è¦çš„æ€»ç»“ï¼Œå¸Œæœ›å¤§å®¶èƒ½å¤Ÿä¸‹è½½åŸæ–‡ç»†ç»†å“è¯»ï¼Œäº†è§£æœ€å‰æ²¿çš„å¤§æ•°æ®æŠ€æœ¯ã€‚</p><h4 id="3-è®ºæ–‡ç®€è¦æ€»ç»“"><a href="#3-è®ºæ–‡ç®€è¦æ€»ç»“" class="headerlink" title="3.è®ºæ–‡ç®€è¦æ€»ç»“"></a>3.è®ºæ–‡ç®€è¦æ€»ç»“</h4><p>é¢˜ç›®ï¼šStructured Streaming: A Declarative API for Real-Time Applications in Apache Spark</p><h5 id="3-1-æ‘˜è¦"><a href="#3-1-æ‘˜è¦" class="headerlink" title="3.1 æ‘˜è¦"></a>3.1 æ‘˜è¦</h5><p>æ‘˜è¦æ˜¯ä¸€ç¯‡è®ºæ–‡çš„ç²¾é«“ï¼Œè¿™é‡Œç»™å‡ºæ‘˜è¦å®Œæ•´çš„ç¿»è¯‘ã€‚<br>éšç€å®æ—¶æ•°æ®çš„æ™®éå­˜åœ¨ï¼Œæˆ‘ä»¬éœ€è¦å¯æ‰©å±•çš„ã€æ˜“ç”¨çš„ã€æ˜“äºé›†æˆçš„æµå¼å¤„ç†ç³»ç»Ÿã€‚ç»“æ„åŒ–æµæ˜¯åŸºäºæˆ‘ä»¬å¯¹Spark Streamingçš„ç»éªŒå¼€å‘å‡ºæ¥çš„é«˜çº§åˆ«çš„Sparkæµå¼APIã€‚ç»“æ„åŒ–æµä¸å…¶ä»–ç°æœ‰çš„æµå¼APIï¼Œå¦‚è°·æ­Œçš„Dataflowï¼Œä¸»è¦æœ‰ä¸¤ç‚¹ä¸åŒã€‚ç¬¬ä¸€ï¼Œå®ƒæ˜¯ä¸€ä¸ªåŸºäºè‡ªåŠ¨å¢é‡åŒ–çš„å…³ç³»å‹æŸ¥è¯¢APIï¼Œæ— éœ€ç”¨æˆ·è‡ªå·±æ„å»ºDAGï¼›ç¬¬äºŒï¼Œç»“æ„åŒ–æµæ—¨åœ¨äºæ”¯æŒç«¯åˆ°ç«¯çš„å®æ—¶åº”ç”¨å¹¶æ•´åˆæµä¸æ‰¹å¤„ç†çš„äº¤äº’åˆ†æã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬å‘ç°è¿™ç§æ•´åˆæ˜¯ä¸€ä¸ªå…³é”®çš„æŒ‘æˆ˜ã€‚ç»“æ„åŒ–æµé€šè¿‡Spark SQLçš„ä»£ç ç”Ÿæˆå¼•æ“å®ç°äº†å¾ˆé«˜çš„æ€§èƒ½ï¼Œæ˜¯Apache Flinkçš„ä¸¤å€ä»¥åŠApache Kafkaçš„90å€ã€‚å®ƒè¿˜æä¾›äº†ä¸°å¯Œçš„è¿è¡Œç‰¹æ€§ï¼Œå¦‚å›æ»šã€ä»£ç æ›´æ–°ä»¥åŠæµ/æ‰¹æ··åˆæ‰§è¡Œã€‚æœ€åæˆ‘ä»¬æè¿°äº†ç³»ç»Ÿçš„è®¾è®¡ä»¥åŠéƒ¨ç½²åœ¨Databrickså‡ ç™¾ä¸ªç”Ÿäº§èŠ‚ç‚¹çš„ä¸€ä¸ªç”¨ä¾‹ã€‚</p><h5 id="3-2-æµå¼å¤„ç†é¢ä¸´çš„æŒ‘æˆ˜"><a href="#3-2-æµå¼å¤„ç†é¢ä¸´çš„æŒ‘æˆ˜" class="headerlink" title="3.2 æµå¼å¤„ç†é¢ä¸´çš„æŒ‘æˆ˜"></a>3.2 æµå¼å¤„ç†é¢ä¸´çš„æŒ‘æˆ˜</h5><p>(1) å¤æ‚ã€ä½çº§åˆ«çš„API<br>(2) ç«¯åˆ°ç«¯åº”ç”¨çš„é›†æˆ<br>(3) è¿è¡Œæ—¶æŒ‘æˆ˜ï¼šå®¹ç¾ï¼Œä»£ç æ›´æ–°ï¼Œç›‘æ§ç­‰<br>(4) æˆæœ¬å’Œæ€§èƒ½æŒ‘æˆ˜</p><h5 id="3-3-ç»“æ„åŒ–æµåŸºæœ¬æ¦‚å¿µ"><a href="#3-3-ç»“æ„åŒ–æµåŸºæœ¬æ¦‚å¿µ" class="headerlink" title="3.3 ç»“æ„åŒ–æµåŸºæœ¬æ¦‚å¿µ"></a>3.3 ç»“æ„åŒ–æµåŸºæœ¬æ¦‚å¿µ</h5><p><img src="/assets/blogImg/614_1.png" alt="enter description here"><br>å›¾1 ç»“æ„åŒ–æµçš„ç»„æˆéƒ¨åˆ†</p><p>(1) Input and Output<br>Input sources å¿…é¡»æ˜¯ replayable çš„ï¼Œæ”¯æŒèŠ‚ç‚¹å®•æœºåä»å½“å‰è¾“å…¥ç»§ç»­è¯»å–ã€‚ä¾‹å¦‚ï¼šApache Kinesiså’ŒApache Kafkaã€‚<br>Output sinks å¿…é¡»æ”¯æŒ idempotent ï¼ˆå¹‚ç­‰ï¼‰ï¼Œç¡®ä¿åœ¨èŠ‚ç‚¹å®•æœºæ—¶å¯é çš„æ¢å¤ã€‚<br>(2) APIs<br>ç¼–å†™ç»“æ„åŒ–æµç¨‹åºæ—¶ï¼Œå¯ä»¥ä½¿ç”¨Spark SQLçš„APIsï¼šDataFrameå’ŒSQLæ¥æŸ¥è¯¢streamså’Œtablesï¼Œè¯¥æŸ¥è¯¢å®šä¹‰äº†ä¸€ä¸ªoutput tableï¼ˆè¾“å‡ºè¡¨ï¼‰ï¼Œç”¨æ¥æ¥æ”¶æ¥è‡ªsteamçš„æ•°æ®ã€‚engineå†³å®šå¦‚ä½•è®¡ç®—å¹¶å°†è¾“å‡ºè¡¨ incrementallyï¼ˆå¢é‡åœ°ï¼‰å†™å…¥sinkã€‚ä¸åŒçš„sinksæ”¯æŒä¸åŒçš„output modesï¼ˆè¾“å‡ºæ¨¡å¼ï¼Œåé¢ä¼šæåˆ°ï¼‰ã€‚<br>ä¸ºäº†å¤„ç†æµå¼æ•°æ®ï¼Œç»“æ„åŒ–æµè¿˜å¢åŠ äº†ä¸€äº›APIsä¸å·²æœ‰çš„Spark SQL APIç›¸é…åˆï¼š</p><ul><li>a. Triggers æ§åˆ¶engineå¤šä¹…æ‰§è¡Œä¸€æ¬¡è®¡ç®—</li><li>b. event time æ˜¯æ•°æ®æºçš„æ—¶é—´æˆ³ï¼›watermark ç­–ç•¥ï¼Œä¸event time ç›¸å·®ä¸€æ®µæ—¶é—´åä¸å†æ¥æ”¶æ•°æ®ã€‚</li><li>c.Stateful operatorï¼ˆçŠ¶æ€ç®—å­ï¼‰ï¼Œç±»ä¼¼äºSpark Streaming çš„updateStateByKeyã€‚</li></ul><p>(3) æ‰§è¡Œ<br>ä¸€æ—¦æ¥æ”¶åˆ°äº†æŸ¥è¯¢ï¼Œç»“æ„åŒ–æµå°±ä¼šè¿›è¡Œä¼˜åŒ–é€’å¢ï¼Œå¹¶å¼€å§‹æ‰§è¡Œã€‚ç»“æ„åŒ–æµä½¿ç”¨ä¸¤ç§æŒä¹…åŒ–å­˜å‚¨çš„æ–¹å¼å®ç°å®¹é”™ï¼š</p><ul><li>a.write-ahead log ï¼ˆWALï¼šé¢„å†™æ—¥å¿—ï¼‰æŒç»­è¿½è¸ªå“ªäº›æ•°æ®å·²è¢«æ‰§è¡Œï¼Œç¡®ä¿æ•°æ®çš„å¯é å†™å…¥ã€‚</li><li>b.ç³»ç»Ÿé‡‡ç”¨å¤§è§„æ¨¡çš„ state storeï¼ˆçŠ¶æ€å­˜å‚¨ï¼‰æ¥ä¿å­˜é•¿æ—¶é—´è¿è¡Œçš„èšåˆç®—å­çš„ç®—å­çŠ¶æ€å¿«ç…§ã€‚</li></ul><h5 id="3-4-ç¼–ç¨‹æ¨¡å‹"><a href="#3-4-ç¼–ç¨‹æ¨¡å‹" class="headerlink" title="3.4 ç¼–ç¨‹æ¨¡å‹"></a>3.4 ç¼–ç¨‹æ¨¡å‹</h5><p>ç»“æ„åŒ–æµå°†è°·æ­Œçš„Dataflowã€å¢é‡æŸ¥è¯¢å’ŒSpark Streaming ç»“åˆèµ·æ¥ï¼Œä»¥ä¾¿åœ¨Spark SQLä¸‹å®ç°æµå¼å¤„ç†ã€‚</p><ul><li>a. A Short Example<pre><code>é¦–å…ˆä»ä¸€ä¸ªæ‰¹å¤„ç†ä½œä¸šå¼€å§‹ï¼Œç»Ÿè®¡ä¸€ä¸ªwebåº”ç”¨åœ¨ä¸åŒå›½å®¶çš„ç‚¹å‡»æ•°ã€‚å‡è®¾è¾“å…¥æ•°æ®æ˜¯ä¸€ä¸ªJSONæ–‡ä»¶ï¼Œè¾“å‡ºä¸€ä¸ªParquetæ–‡ä»¶ï¼Œè¯¥ä½œä¸šå¯ä»¥é€šè¿‡DataFrameæ¥å®Œæˆï¼š</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1// Define a DataFrame to read from static data</span><br><span class="line">2data = spark . read . format (&quot; json &quot;). load (&quot;/in&quot;)</span><br><span class="line">3// Transform it to compute a result</span><br><span class="line">4counts = data . groupBy ($&quot; country &quot;). count ()</span><br><span class="line">5// Write to a static data sink</span><br><span class="line">6counts . write . format (&quot; parquet &quot;). save (&quot;/ counts &quot;)</span><br></pre></td></tr></table></figure></li></ul><p>æŠŠè¯¥ä½œä¸šå˜æˆä½¿ç”¨ç»“æ„åŒ–æµä»…ä»…éœ€è¦æ”¹å˜è¾“å…¥å’Œè¾“å‡ºæºï¼Œä¾‹å¦‚ï¼Œå¦‚æœæ–°çš„JSONæ–‡ä»¶continuallyï¼ˆæŒç»­åœ°ï¼‰ä¸Šä¼ ï¼Œæˆ‘ä»¬åªéœ€è¦æ”¹å˜ç¬¬ä¸€è¡Œå’Œæœ€åä¸€è¡Œã€‚<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1// Define a DataFrame to read streaming data</span><br><span class="line">2data = spark . readStream . format (&quot; json &quot;). load (&quot;/in&quot;)</span><br><span class="line">3// Transform it to compute a result</span><br><span class="line">4counts = data . groupBy ($&quot; country &quot;). count ()</span><br><span class="line">5// Write to a streaming data sink</span><br><span class="line">6counts . writeStream . format (&quot; parquet &quot;)</span><br><span class="line">7. outputMode (&quot; complete &quot;). start (&quot;/ counts &quot;)</span><br></pre></td></tr></table></figure><p></p><p>ç»“æ„åŒ–æµä¹Ÿæ”¯æŒ windowingï¼ˆçª—å£ï¼‰å’Œé€šè¿‡Spark SQLå·²å­˜åœ¨çš„èšåˆç®—å­å¤„ç†event timeã€‚ä¾‹å¦‚ï¼šæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¿®æ”¹ä¸­é—´çš„ä»£ç ï¼Œè®¡ç®—1å°æ—¶çš„æ»‘åŠ¨çª—å£ï¼Œæ¯äº”åˆ†é’Ÿå‰è¿›ä¸€æ¬¡ï¼š<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1// Count events by windows on the &quot; time &quot; field</span><br><span class="line">2data . groupBy ( window ($&quot; time &quot;,&quot;1h&quot;,&quot;5min&quot;)). count ()</span><br></pre></td></tr></table></figure><p></p><ul><li>b. ç¼–ç¨‹æ¨¡å‹è¯­ä¹‰<br><img src="/assets/blogImg/614_2.png" alt="enter description here"></li></ul><p>å›¾ 2 ä¸¤ç§è¾“å‡ºæ¨¡å¼</p><ul><li>i. æ¯ä¸€ä¸ªè¾“å…¥æºæä¾›äº†ä¸€ä¸ªåŸºäºæ—¶é—´çš„éƒ¨åˆ†æœ‰åºçš„è®°å½•é›†ï¼ˆset of recordsï¼‰ï¼Œä¾‹å¦‚ï¼ŒKafkaå°†æµå¼æ•°æ®åˆ†ä¸ºå„è‡ªæœ‰åºçš„partitionsã€‚</li><li>ii. ç”¨æˆ·æä¾›è·¨è¾“å…¥æ•°æ®æ‰§è¡Œçš„æŸ¥è¯¢ï¼Œè¯¥è¾“å…¥æ•°æ®å¯ä»¥åœ¨ä»»æ„ç»™å®šçš„å¤„ç†æ—¶é—´ç‚¹è¾“å‡ºä¸€ä¸ª result tableï¼ˆç»“æœè¡¨ï¼‰ã€‚ç»“æ„åŒ–æµæ€»ä¼šäº§ç”Ÿä¸æ‰€æœ‰è¾“å…¥æºçš„æ•°æ®çš„å‰ç¼€ä¸Šï¼ˆprefix of the data in all input sourcesï¼‰æŸ¥è¯¢ç›¸ä¸€è‡´çš„ç»“æœã€‚</li><li>iii. Triggers å‘Šè¯‰ç³»ç»Ÿä½•æ—¶å»è¿è¡Œä¸€ä¸ªæ–°çš„å¢é‡è®¡ç®—ï¼Œä½•æ—¶æ›´æ–°result tableã€‚ä¾‹å¦‚ï¼Œåœ¨å¾®æ‰¹å¤„ç†æ¨¡å¼ï¼Œç”¨æˆ·å¸Œæœ›ä¼šæ¯åˆ†é’Ÿè§¦å‘ä¸€æ¬¡å¢é‡è®¡ç®—ã€‚</li><li>iiii. engineæ”¯æŒä¸‰ç§output modeï¼š<pre><code>  Completeï¼šengineä¸€æ¬¡å†™æ‰€æœ‰result tableã€‚  Appendï¼šengineä»…ä»…å‘sinkå¢åŠ è®°å½•ã€‚  Updateï¼šengineåŸºäºkeyæ›´æ–°æ¯ä¸€ä¸ªrecordï¼Œæ›´æ–°å€¼æ”¹å˜çš„keysã€‚è¯¥æ¨¡å‹æœ‰ä¸¤ä¸ªç‰¹æ€§ï¼šç¬¬ä¸€ï¼Œç»“æœè¡¨çš„å†…å®¹ç‹¬ç«‹äºè¾“å‡ºæ¨¡å¼ã€‚ç¬¬äºŒï¼Œè¯¥æ¨¡å‹å…·æœ‰å¾ˆå¼ºçš„è¯­ä¹‰ä¸€è‡´æ€§ï¼Œè¢«ç§°ä¸ºprefix consistencyã€‚</code></pre>c.æµå¼ç®—å­<pre><code>åŠ å…¥äº†ä¸¤ç§ç±»å‹çš„ç®—å­ï¼šwatermarkingç®—å­å‘Šè¯‰ç³»ç»Ÿä½•æ—¶å…³é—­event time windowå’Œè¾“å‡ºç»“æœï¼›ç»“æ„åŒ–æµå…è®¸ç”¨æˆ·é€šè¿‡withWatermarkç®—å­æ¥è®¾ç½®ä¸€ä¸ªwatermarkï¼Œè¯¥ç®—å­ç»™ç³»ç»Ÿè®¾ç½®ä¸€ä¸ªç»™å®šæ—¶é—´æˆ³Cçš„å»¶è¿Ÿé˜ˆå€¼tCï¼Œåœ¨ä»»æ„æ—¶é—´ç‚¹ï¼ŒCçš„watermarkæ˜¯maxï¼ˆCï¼‰-tCã€‚stateful operatorså…è®¸ç”¨æˆ·ç¼–å†™è‡ªå®šä¹‰é€»è¾‘æ¥å®ç°å¤æ‚çš„åŠŸèƒ½ã€‚</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"> 1// Define an update function that simply tracks the</span><br><span class="line"> 2// number of events for each key as its state , returns</span><br><span class="line"> 3// that as its result , and times out keys after 30 min.</span><br><span class="line"> 4def updateFunc (key: UserId , newValues : Iterator [ Event ],</span><br><span class="line"> 5state : GroupState [Int ]): Int = &#123;</span><br><span class="line"> 6val totalEvents = state .get () + newValues . size ()</span><br><span class="line"> 7state . update ( totalEvents )</span><br><span class="line"> 8state . setTimeoutDuration (&quot;30 min&quot;)</span><br><span class="line"> 9return totalEvents</span><br><span class="line">10&#125;</span><br><span class="line">11// Use this update function on a stream , returning a</span><br><span class="line">12// new table lens that contains the session lengths .</span><br><span class="line">13lens = events . groupByKey ( event =&gt; event . userId )</span><br><span class="line">14. mapGroupsWithState ( updateFunc )</span><br></pre></td></tr></table></figure></li></ul><p>ç”¨mapGroupWithStateç®—å­æ¥è¿½è¸ªæ¯ä¸ªä¼šè¯çš„äº‹ä»¶æ•°é‡ï¼Œ30åˆ†é’Ÿåå…³é—­ä¼šè¯ã€‚</p><h5 id="3-5-è¿è¡Œç‰¹æ€§"><a href="#3-5-è¿è¡Œç‰¹æ€§" class="headerlink" title="3.5 è¿è¡Œç‰¹æ€§"></a>3.5 è¿è¡Œç‰¹æ€§</h5><p>(1) ä»£ç æ›´æ–°ï¼ˆcode updateï¼‰<br>å¼€å‘è€…èƒ½å¤Ÿåœ¨ç¼–ç¨‹è¿‡ç¨‹ä¸­æ›´æ–°UDFï¼Œå¹¶ä¸”å¯ä»¥ç®€å•çš„é‡å¯ä»¥ä½¿ç”¨æ–°ç‰ˆæœ¬çš„ä»£ç ã€‚<br>(2) æ‰‹åŠ¨å›æ»šï¼ˆmanual rollbackï¼‰<br>æœ‰æ—¶åœ¨ç”¨æˆ·å‘ç°ä¹‹å‰ï¼Œç¨‹åºä¼šè¾“å‡ºé”™è¯¯çš„ç»“æœï¼Œå› æ­¤å›æ»šè‡³å…³é‡è¦ã€‚ç»“æ„åŒ–æµå¾ˆå®¹æ˜“å®šä½é—®é¢˜æ‰€åœ¨ã€‚åŒæ—¶æ‰‹åŠ¨å›æ»šä¸å‰é¢æåˆ°çš„prefix consistencyæœ‰å¾ˆå¥½çš„äº¤äº’ã€‚<br>(3) æµå¼å’Œæ‰¹æ¬¡æ··åˆå¤„ç†<br>è¿™æ˜¯ç»“æ„åŒ–æµæœ€æ˜¾è€Œæ˜“è§çš„å¥½å¤„ï¼Œç”¨æˆ·èƒ½å¤Ÿå…±ç”¨æµå¼å¤„ç†å’Œæ‰¹å¤„ç†ä½œä¸šçš„ä»£ç ã€‚<br>(4) ç›‘æ§<br>ç»“æ„åŒ–æµä½¿ç”¨Sparkå·²æœ‰çš„APIå’Œç»“æ„åŒ–æ—¥å¿—æ¥æŠ¥å‘Šä¿¡æ¯ï¼Œä¾‹å¦‚å¤„ç†è¿‡çš„è®°å½•æ•°é‡ï¼Œè·¨ç½‘ç»œçš„å­—èŠ‚æ•°ç­‰ã€‚è¿™äº›æ¥å£è¢«Sparkå¼€å‘è€…æ‰€ç†ŸçŸ¥ï¼Œå¹¶æ˜“äºè¿æ¥åˆ°ä¸åŒçš„UIå·¥å…·ã€‚</p><h5 id="3-6-ç”Ÿäº§ç”¨ä¾‹ä¸æ€»ç»“"><a href="#3-6-ç”Ÿäº§ç”¨ä¾‹ä¸æ€»ç»“" class="headerlink" title="3.6 ç”Ÿäº§ç”¨ä¾‹ä¸æ€»ç»“"></a>3.6 ç”Ÿäº§ç”¨ä¾‹ä¸æ€»ç»“</h5><p>ç»™å‡ºç®€è¦æ¶æ„å›¾ï¼Œç¯‡å¹…åŸå› ä¸å†èµ˜è¿°ï¼Œå¸Œæœ›è¯¦ç»†äº†è§£çš„ä¸‹è½½è®ºæ–‡è‡ªè¡Œé˜…è¯»ã€‚æœ¬æ–‡åªæŒ‘é€‰äº†éƒ¨åˆ†å…³é”®ç‚¹è¿›è¡Œäº†æµ…å±‚æ¬¡çš„å™è¿°ï¼Œå¸Œæœ›è¯»è€…èƒ½å¤Ÿå°†è®ºæ–‡ä¸‹è½½ä¸‹æ¥è®¤çœŸå“è¯»ï¼Œææ‡‚å¼€å‘è€…çš„å¼€å‘æ€è·¯ï¼Œè·Ÿä¸Šå¤§æ•°æ®çš„å‰æ²¿æ­¥ä¼ã€‚<br><img src="/assets/blogImg/614_3.png" alt="enter description here"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed May 15 2019 19:56:23 GMT+0800 (GMT+08:00) --&gt;
    
    </summary>
    
      <category term="Spark Streaming" scheme="http://yoursite.com/categories/Spark-Streaming/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>ç”Ÿäº§å¼€å‘å¿…ç”¨-Spark RDDè½¬DataFrameçš„ä¸¤ç§æ–¹æ³•</title>
    <link href="http://yoursite.com/2018/06/14/%E7%94%9F%E4%BA%A7%E5%BC%80%E5%8F%91%E5%BF%85%E7%94%A8-Spark%20RDD%E8%BD%ACDataFrame%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95/"/>
    <id>http://yoursite.com/2018/06/14/ç”Ÿäº§å¼€å‘å¿…ç”¨-Spark RDDè½¬DataFrameçš„ä¸¤ç§æ–¹æ³•/</id>
    <published>2018-06-13T16:00:00.000Z</published>
    <updated>2019-05-13T12:14:30.405Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 13 2019 20:18:11 GMT+0800 (GMT+08:00) --><p>æœ¬ç¯‡æ–‡ç« å°†ä»‹ç»Spark SQLä¸­çš„DataFrameï¼Œå…³äºDataFrameçš„ä»‹ç»å¯ä»¥å‚è€ƒ:<br><a href="https://blog.csdn.net/lemonzhaotao/article/details/80211231" target="_blank" rel="noopener">https://blog.csdn.net/lemonzhaotao/article/details/80211231</a></p><p>åœ¨æœ¬ç¯‡æ–‡ç« ä¸­ï¼Œå°†ä»‹ç»RDDè½¬æ¢ä¸ºDataFrameçš„2ç§æ–¹å¼</p><p>å®˜ç½‘ä¹‹RDDè½¬DF:<br><a href="http://spark.apache.org/docs/latest/sql-programming-guide.html#interoperating-with-rdds" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/sql-programming-guide.html#interoperating-with-rdds</a><br><a id="more"></a><br>DataFrame ä¸ RDD çš„äº¤äº’</p><p>Spark SQLå®ƒæ”¯æŒä¸¤ç§ä¸åŒçš„æ–¹å¼è½¬æ¢å·²ç»å­˜åœ¨çš„RDDåˆ°DataFrame</p><h4 id="æ–¹æ³•ä¸€"><a href="#æ–¹æ³•ä¸€" class="headerlink" title="æ–¹æ³•ä¸€"></a>æ–¹æ³•ä¸€</h4><p>ç¬¬ä¸€ç§æ–¹å¼æ˜¯ä½¿ç”¨åå°„çš„æ–¹å¼ï¼Œç”¨åå°„å»æ¨å€’å‡ºæ¥RDDé‡Œé¢çš„schemaã€‚è¿™ä¸ªæ–¹å¼ç®€å•ï¼Œä½†æ˜¯ä¸å»ºè®®ä½¿ç”¨ï¼Œå› ä¸ºåœ¨å·¥ä½œå½“ä¸­ï¼Œä½¿ç”¨è¿™ç§æ–¹å¼æ˜¯æœ‰é™åˆ¶çš„ã€‚<br>å¯¹äºä»¥å‰çš„ç‰ˆæœ¬æ¥è¯´ï¼Œcase classæœ€å¤šæ”¯æŒ22ä¸ªå­—æ®µå¦‚æœè¶…è¿‡äº†22ä¸ªå­—æ®µï¼Œæˆ‘ä»¬å°±å¿…é¡»è¦è‡ªå·±å¼€å‘ä¸€ä¸ªç±»ï¼Œå®ç°productæ¥å£æ‰è¡Œã€‚å› æ­¤è¿™ç§æ–¹å¼è™½ç„¶ç®€å•ï¼Œä½†æ˜¯ä¸é€šç”¨ï¼›å› ä¸ºç”Ÿäº§ä¸­çš„å­—æ®µæ˜¯éå¸¸éå¸¸å¤šçš„ï¼Œæ˜¯ä¸å¯èƒ½åªæœ‰20æ¥ä¸ªå­—æ®µçš„ã€‚<br>ç¤ºä¾‹ï¼š<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">  * convert rdd to dataframe 1</span><br><span class="line">  * @param spark</span><br><span class="line">  */</span><br><span class="line">private def runInferSchemaExample(spark:SparkSession): Unit =&#123;</span><br><span class="line">  import spark.implicits._</span><br><span class="line">  val rdd = spark.sparkContext.textFile(&quot;E:/å¤§æ•°æ®/data/people.txt&quot;)</span><br><span class="line">  val df = rdd.map(_.split(&quot;,&quot;))</span><br><span class="line">              .map(x =&gt; People(x(0), x(1).trim.toInt))  //å°†rddçš„æ¯ä¸€è¡Œéƒ½è½¬æ¢æˆäº†ä¸€ä¸ªpeople</span><br><span class="line">              .toDF         //å¿…é¡»å…ˆå¯¼å…¥import spark.implicits._  ä¸ç„¶è¿™ä¸ªæ–¹æ³•ä¼šæŠ¥é”™</span><br><span class="line">  df.show()</span><br><span class="line">  df.createOrReplaceTempView(&quot;people&quot;)</span><br><span class="line">  // è¿™ä¸ªDFåŒ…å«äº†ä¸¤ä¸ªå­—æ®µnameå’Œage</span><br><span class="line">  val teenagersDF = spark.sql(&quot;SELECT name, age FROM people WHERE age BETWEEN 13 AND 19&quot;)</span><br><span class="line">  // teenager(0)ä»£è¡¨ç¬¬ä¸€ä¸ªå­—æ®µ</span><br><span class="line">  // å–å€¼çš„ç¬¬ä¸€ç§æ–¹å¼ï¼šindex from zero</span><br><span class="line">  teenagersDF.map(teenager =&gt; &quot;Name: &quot; + teenager(0)).show()</span><br><span class="line">  // å–å€¼çš„ç¬¬äºŒç§æ–¹å¼ï¼šbyName</span><br><span class="line">  teenagersDF.map(teenager =&gt; &quot;Name: &quot; + teenager.getAs[String](&quot;name&quot;) + &quot;,&quot; + teenager.getAs[Int](&quot;age&quot;)).show()</span><br><span class="line">&#125;</span><br><span class="line">// æ³¨æ„ï¼šcase classå¿…é¡»å®šä¹‰åœ¨mainæ–¹æ³•ä¹‹å¤–ï¼›å¦åˆ™ä¼šæŠ¥é”™</span><br><span class="line">case class People(name:String, age:Int)</span><br></pre></td></tr></table></figure><p></p><h4 id="æ–¹æ³•äºŒ"><a href="#æ–¹æ³•äºŒ" class="headerlink" title="æ–¹æ³•äºŒ"></a>æ–¹æ³•äºŒ</h4><p>åˆ›å»ºä¸€ä¸ªDataFrameï¼Œä½¿ç”¨ç¼–ç¨‹çš„æ–¹å¼ è¿™ä¸ªæ–¹å¼ç”¨çš„éå¸¸å¤šã€‚é€šè¿‡ç¼–ç¨‹æ–¹å¼æŒ‡å®šschema ï¼Œå¯¹äºç¬¬ä¸€ç§æ–¹å¼çš„schemaå…¶å®å®šä¹‰åœ¨äº†case classé‡Œé¢äº†ã€‚<br>å®˜ç½‘è§£è¯»ï¼š<br>å½“æˆ‘ä»¬çš„case classä¸èƒ½æå‰å®šä¹‰(å› ä¸ºä¸šåŠ¡å¤„ç†çš„è¿‡ç¨‹å½“ä¸­ï¼Œä½ çš„å­—æ®µå¯èƒ½æ˜¯åœ¨å˜åŒ–çš„),å› æ­¤ä½¿ç”¨case classå¾ˆéš¾å»æå‰å®šä¹‰ã€‚<br>ä½¿ç”¨è¯¥æ–¹å¼åˆ›å»ºDFçš„ä¸‰å¤§æ­¥éª¤ï¼š</p><ul><li>Create an RDD of Rows from the original RDD;</li><li>Create the schema represented by a StructType matching the structure of Rows in the RDD created in Step 1.</li><li>Apply the schema to the RDD of Rows via createDataFrame method provided by SparkSession.<br>ç¤ºä¾‹ï¼š<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">  * convert rdd to dataframe 2</span><br><span class="line">  * @param spark</span><br><span class="line">  */</span><br><span class="line">private def runProgrammaticSchemaExample(spark:SparkSession): Unit =&#123;</span><br><span class="line">  // 1.è½¬æˆRDD</span><br><span class="line">  val rdd = spark.sparkContext.textFile(&quot;E:/å¤§æ•°æ®/data/people.txt&quot;)</span><br><span class="line">  // 2.å®šä¹‰schemaï¼Œå¸¦æœ‰StructTypeçš„</span><br><span class="line">  // å®šä¹‰schemaä¿¡æ¯</span><br><span class="line">  val schemaString = &quot;name age&quot;</span><br><span class="line">  // å¯¹schemaä¿¡æ¯æŒ‰ç©ºæ ¼è¿›è¡Œåˆ†å‰²</span><br><span class="line">  // æœ€ç»ˆfiledsé‡ŒåŒ…å«äº†2ä¸ªStructField</span><br><span class="line">  val fields = schemaString.split(&quot; &quot;)</span><br><span class="line">                            // å­—æ®µç±»å‹ï¼Œå­—æ®µåç§°åˆ¤æ–­æ˜¯ä¸æ˜¯ä¸ºç©º</span><br><span class="line">                           .map(fieldName =&gt; StructField(fieldName, StringType, nullable = true))</span><br><span class="line">  val schema = StructType(fields)</span><br><span class="line">  // 3.æŠŠæˆ‘ä»¬çš„schemaä¿¡æ¯ä½œç”¨åˆ°RDDä¸Š</span><br><span class="line">  //   è¿™ä¸ªRDDé‡Œé¢åŒ…å«äº†ä¸€äº›è¡Œ</span><br><span class="line">  // å½¢æˆRowç±»å‹çš„RDD</span><br><span class="line">  val rowRDD = rdd.map(_.split(&quot;,&quot;))</span><br><span class="line">                  .map(x =&gt; Row(x(0), x(1).trim))</span><br><span class="line">  // é€šè¿‡SparkSessionåˆ›å»ºä¸€ä¸ªDataFrame</span><br><span class="line">  // ä¼ è¿›æ¥ä¸€ä¸ªrowRDDå’Œschemaï¼Œå°†schemaä½œç”¨åˆ°rowRDDä¸Š</span><br><span class="line">  val peopleDF = spark.createDataFrame(rowRDD, schema)</span><br><span class="line">  peopleDF.show()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="æ‰©å±•-ç”Ÿäº§ä¸Šåˆ›å»ºDataFrameçš„ä»£ç ä¸¾ä¾‹"><a href="#æ‰©å±•-ç”Ÿäº§ä¸Šåˆ›å»ºDataFrameçš„ä»£ç ä¸¾ä¾‹" class="headerlink" title="[æ‰©å±•]ç”Ÿäº§ä¸Šåˆ›å»ºDataFrameçš„ä»£ç ä¸¾ä¾‹"></a>[æ‰©å±•]ç”Ÿäº§ä¸Šåˆ›å»ºDataFrameçš„ä»£ç ä¸¾ä¾‹</h4><p>åœ¨å®é™…ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬å…¶å®é€‰æ‹©çš„æ˜¯æ–¹å¼äºŒè¿™ç§è¿›è¡Œåˆ›å»ºDataFrameçš„ï¼Œè¿™é‡Œå°†å±•ç¤ºéƒ¨åˆ†ä»£ç ï¼š</p><h4 id="Schemaçš„å®šä¹‰"><a href="#Schemaçš„å®šä¹‰" class="headerlink" title="Schemaçš„å®šä¹‰"></a>Schemaçš„å®šä¹‰</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">object AccessConvertUtil &#123;</span><br><span class="line">  val struct = StructType(</span><br><span class="line">    Array(</span><br><span class="line">      StructField(&quot;url&quot;,StringType),</span><br><span class="line">      StructField(&quot;cmsType&quot;,StringType),</span><br><span class="line">      StructField(&quot;cmsId&quot;,LongType),</span><br><span class="line">      StructField(&quot;traffic&quot;,LongType),</span><br><span class="line">      StructField(&quot;ip&quot;,StringType),</span><br><span class="line">      StructField(&quot;city&quot;,StringType),</span><br><span class="line">      StructField(&quot;time&quot;,StringType),</span><br><span class="line">      StructField(&quot;day&quot;,StringType)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  /**</span><br><span class="line">    * æ ¹æ®è¾“å…¥çš„æ¯ä¸€è¡Œä¿¡æ¯è½¬æ¢æˆè¾“å‡ºçš„æ ·å¼</span><br><span class="line">    */</span><br><span class="line">  def parseLog(log:String) = &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      val splits = log.split(&quot;\t&quot;)</span><br><span class="line">      val url = splits(1)</span><br><span class="line">      val traffic = splits(2).toLong</span><br><span class="line">      val ip = splits(3)</span><br><span class="line">      val domain = &quot;http://www.imooc.com/&quot;</span><br><span class="line">      val cms = url.substring(url.indexOf(domain) + domain.length)</span><br><span class="line">      val cmsTypeId = cms.split(&quot;/&quot;)</span><br><span class="line">      var cmsType = &quot;&quot;</span><br><span class="line">      var cmsId = 0l</span><br><span class="line">      if (cmsTypeId.length &gt; 1) &#123;</span><br><span class="line">        cmsType = cmsTypeId(0)</span><br><span class="line">        cmsId = cmsTypeId(1).toLong</span><br><span class="line">      &#125;</span><br><span class="line">      val city = IpUtils.getCity(ip)</span><br><span class="line">      val time = splits(0)</span><br><span class="line">      val day = time.substring(0,10).replace(&quot;-&quot;,&quot;&quot;)</span><br><span class="line">      //è¿™ä¸ªRowé‡Œé¢çš„å­—æ®µè¦å’Œstructä¸­çš„å­—æ®µå¯¹åº”ä¸Š</span><br><span class="line">      Row(url, cmsType, cmsId, traffic, ip, city, time, day)</span><br><span class="line">    &#125; catch &#123;</span><br><span class="line">      case e: Exception =&gt; Row(0)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="åˆ›å»ºDataFrame"><a href="#åˆ›å»ºDataFrame" class="headerlink" title="åˆ›å»ºDataFrame"></a>åˆ›å»ºDataFrame</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">object SparkStatCleanJob &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val spark = SparkSession.builder().appName(&quot;SparkStatCleanJob&quot;)</span><br><span class="line">      .master(&quot;local[2]&quot;).getOrCreate()</span><br><span class="line">    val accessRDD = spark.sparkContext.textFile(&quot;/Users/lemon/project/data/access.log&quot;)</span><br><span class="line">    //accessRDD.take(10).foreach(println)</span><br><span class="line">    //RDD ==&gt; DFï¼Œåˆ›å»ºç”ŸæˆDataFrame</span><br><span class="line">    val accessDF = spark.createDataFrame(accessRDD.map(x =&gt; AccessConvertUtil.parseLog(x)),</span><br><span class="line">      AccessConvertUtil.struct)</span><br><span class="line">    accessDF.coalesce(1).write.format(&quot;parquet&quot;).mode(SaveMode.Overwrite)</span><br><span class="line">            .partitionBy(&quot;day&quot;).save(&quot;/Users/lemon/project/clean&quot;)</span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 13 2019 20:18:11 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;æœ¬ç¯‡æ–‡ç« å°†ä»‹ç»Spark SQLä¸­çš„DataFrameï¼Œå…³äºDataFrameçš„ä»‹ç»å¯ä»¥å‚è€ƒ:&lt;br&gt;&lt;a href=&quot;https://blog.csdn.net/lemonzhaotao/article/details/80211231&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://blog.csdn.net/lemonzhaotao/article/details/80211231&lt;/a&gt;&lt;/p&gt;&lt;p&gt;åœ¨æœ¬ç¯‡æ–‡ç« ä¸­ï¼Œå°†ä»‹ç»RDDè½¬æ¢ä¸ºDataFrameçš„2ç§æ–¹å¼&lt;/p&gt;&lt;p&gt;å®˜ç½‘ä¹‹RDDè½¬DF:&lt;br&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/sql-programming-guide.html#interoperating-with-rdds&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://spark.apache.org/docs/latest/sql-programming-guide.html#interoperating-with-rdds&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Spark Core" scheme="http://yoursite.com/categories/Spark-Core/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>ä½ å¤§çˆ·æ°¸è¿œæ˜¯ä½ å¤§çˆ·ï¼ŒRDDè¡€ç¼˜å…³ç³»æºç è¯¦è§£ï¼</title>
    <link href="http://yoursite.com/2018/06/13/%E4%BD%A0%E5%A4%A7%E7%88%B7%E6%B0%B8%E8%BF%9C%E6%98%AF%E4%BD%A0%E5%A4%A7%E7%88%B7%EF%BC%8CRDD%E8%A1%80%E7%BC%98%E5%85%B3%E7%B3%BB%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3%EF%BC%81/"/>
    <id>http://yoursite.com/2018/06/13/ä½ å¤§çˆ·æ°¸è¿œæ˜¯ä½ å¤§çˆ·ï¼ŒRDDè¡€ç¼˜å…³ç³»æºç è¯¦è§£ï¼/</id>
    <published>2018-06-12T16:00:00.000Z</published>
    <updated>2019-05-13T12:17:09.141Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 13 2019 20:18:11 GMT+0800 (GMT+08:00) --><h4 id="ä¸€ã€RDDçš„ä¾èµ–å…³ç³»"><a href="#ä¸€ã€RDDçš„ä¾èµ–å…³ç³»" class="headerlink" title="ä¸€ã€RDDçš„ä¾èµ–å…³ç³»"></a>ä¸€ã€RDDçš„ä¾èµ–å…³ç³»</h4><p>RDDçš„ä¾èµ–å…³ç³»åˆ†ä¸ºä¸¤ç±»ï¼šå®½ä¾èµ–å’Œçª„ä¾èµ–ã€‚æˆ‘ä»¬å¯ä»¥è¿™æ ·è®¤ä¸ºï¼š</p><ul><li><p>ï¼ˆ1ï¼‰çª„ä¾èµ–ï¼šæ¯ä¸ªparent RDD çš„ partition æœ€å¤šè¢« child RDD çš„ä¸€ä¸ªpartition ä½¿ç”¨ã€‚</p></li><li><p>ï¼ˆ2ï¼‰å®½ä¾èµ–ï¼šæ¯ä¸ªparent RDD partition è¢«å¤šä¸ª child RDD çš„partition ä½¿ç”¨ã€‚</p></li></ul><p>çª„ä¾èµ–æ¯ä¸ª child RDD çš„ partition çš„ç”Ÿæˆæ“ä½œéƒ½æ˜¯å¯ä»¥å¹¶è¡Œçš„ï¼Œè€Œå®½ä¾èµ–åˆ™éœ€è¦æ‰€æœ‰çš„ parent RDD partition shuffle ç»“æœå¾—åˆ°åå†è¿›è¡Œã€‚<br><a id="more"></a></p><h4 id="äºŒã€org-apache-spark-Dependency-scala-æºç è§£æ"><a href="#äºŒã€org-apache-spark-Dependency-scala-æºç è§£æ" class="headerlink" title="äºŒã€org.apache.spark.Dependency.scala æºç è§£æ"></a>äºŒã€org.apache.spark.Dependency.scala æºç è§£æ</h4><p>Dependencyæ˜¯ä¸€ä¸ªæŠ½è±¡ç±»ï¼š<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// Denpendency.scala</span><br><span class="line">abstract class Dependency[T] extends Serializable &#123;</span><br><span class="line">  def rdd: RDD[T]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>å®ƒæœ‰ä¸¤ä¸ªå­ç±»ï¼šNarrowDependency å’Œ ShuffleDenpendencyï¼Œåˆ†åˆ«å¯¹åº”çª„ä¾èµ–å’Œå®½ä¾èµ–ã€‚</p><h5 id="ï¼ˆ1ï¼‰NarrowDependencyä¹Ÿæ˜¯ä¸€ä¸ªæŠ½è±¡ç±»"><a href="#ï¼ˆ1ï¼‰NarrowDependencyä¹Ÿæ˜¯ä¸€ä¸ªæŠ½è±¡ç±»" class="headerlink" title="ï¼ˆ1ï¼‰NarrowDependencyä¹Ÿæ˜¯ä¸€ä¸ªæŠ½è±¡ç±»"></a>ï¼ˆ1ï¼‰NarrowDependencyä¹Ÿæ˜¯ä¸€ä¸ªæŠ½è±¡ç±»</h5><p>å®šä¹‰äº†æŠ½è±¡æ–¹æ³•getParentsï¼Œè¾“å…¥partitionIdï¼Œç”¨äºè·å¾—child RDD çš„æŸä¸ªpartitionä¾èµ–çš„parent RDDçš„æ‰€æœ‰ partitionsã€‚<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// Denpendency.scala</span><br><span class="line">abstract class NarrowDependency[T](_rdd: RDD[T]) extends Dependency[T] &#123;  </span><br><span class="line">/**</span><br><span class="line">   * Get the parent partitions for a child partition.</span><br><span class="line">   * @param partitionId a partition of the child RDD</span><br><span class="line">   * @return the partitions of the parent RDD that the child partition depends upon</span><br><span class="line">   */</span><br><span class="line">  def getParents(partitionId: Int): Seq[Int]</span><br><span class="line"></span><br><span class="line">  override def rdd: RDD[T] = _rdd</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>çª„ä¾èµ–åˆæœ‰ä¸¤ä¸ªå…·ä½“çš„å®ç°ï¼šOneToOneDependencyå’ŒRangeDependencyã€‚<br>ï¼ˆaï¼‰OneToOneDependencyæŒ‡child RDDçš„partitionåªä¾èµ–äºparent RDD çš„ä¸€ä¸ªpartitionï¼Œäº§ç”ŸOneToOneDependencyçš„ç®—å­æœ‰mapï¼Œfilterï¼ŒflatMapç­‰ã€‚å¯ä»¥çœ‹åˆ°getParentså®ç°å¾ˆç®€å•ï¼Œå°±æ˜¯ä¼ è¿›å»ä¸€ä¸ªpartitionIdï¼Œå†æŠŠpartitionIdæ”¾åœ¨Listé‡Œé¢ä¼ å‡ºå»ã€‚<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">// Denpendency.scala</span><br><span class="line">class OneToOneDependency[T](rdd: RDD[T]) extends NarrowDependency[T](rdd) &#123;</span><br><span class="line">  override def getParents(partitionId: Int): List[Int] = List(partitionId)</span><br><span class="line">&#125;</span><br><span class="line">        ï¼ˆbï¼‰RangeDependencyæŒ‡child RDD partitionåœ¨ä¸€å®šçš„èŒƒå›´å†…ä¸€å¯¹ä¸€çš„ä¾èµ–äºparent RDD partitionï¼Œä¸»è¦ç”¨äºunionã€‚</span><br><span class="line"></span><br><span class="line">// Denpendency.scala</span><br><span class="line">class RangeDependency[T](rdd: RDD[T], inStart: Int, outStart: Int, length: Int)  </span><br><span class="line">  extends NarrowDependency[T](rdd) &#123;//inStartè¡¨ç¤ºparent RDDçš„å¼€å§‹ç´¢å¼•ï¼ŒoutStartè¡¨ç¤ºchild RDD çš„å¼€å§‹ç´¢å¼•</span><br><span class="line">  override def getParents(partitionId: Int): List[Int] = &#123;    </span><br><span class="line">    if (partitionId &gt;= outStart &amp;&amp; partitionId &lt; outStart + length) &#123;</span><br><span class="line">      List(partitionId - outStart + inStart)//è¡¨ç¤ºäºå½“å‰ç´¢å¼•çš„ç›¸å¯¹ä½ç½®</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      Nil</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h5 id="ï¼ˆ2ï¼‰ShuffleDependencyæŒ‡å®½ä¾èµ–"><a href="#ï¼ˆ2ï¼‰ShuffleDependencyæŒ‡å®½ä¾èµ–" class="headerlink" title="ï¼ˆ2ï¼‰ShuffleDependencyæŒ‡å®½ä¾èµ–"></a>ï¼ˆ2ï¼‰ShuffleDependencyæŒ‡å®½ä¾èµ–</h5><p>è¡¨ç¤ºä¸€ä¸ªparent RDDçš„partitionä¼šè¢«child RDDçš„partitionä½¿ç”¨å¤šæ¬¡ã€‚éœ€è¦ç»è¿‡shuffleæ‰èƒ½å½¢æˆã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">// Denpendency.scala</span><br><span class="line">class ShuffleDependency[K: ClassTag, V: ClassTag, C: ClassTag](</span><br><span class="line">    @transient private val _rdd: RDD[_ &lt;: Product2[K, V]],    </span><br><span class="line">    val partitioner: Partitioner,    </span><br><span class="line">    val serializer: Serializer = SparkEnv.get.serializer,</span><br><span class="line">    val keyOrdering: Option[Ordering[K]] = None,</span><br><span class="line">    val aggregator: Option[Aggregator[K, V, C]] = None,</span><br><span class="line">    val mapSideCombine: Boolean = false)</span><br><span class="line">  extends Dependency[Product2[K, V]] &#123;  //shuffleéƒ½æ˜¯åŸºäºPairRDDè¿›è¡Œçš„ï¼Œæ‰€ä»¥ä¼ å…¥çš„RDDè¦æ˜¯key-valueç±»å‹çš„</span><br><span class="line">  override def rdd: RDD[Product2[K, V]] = _rdd.asInstanceOf[RDD[Product2[K, V]]]</span><br><span class="line"></span><br><span class="line">  private[spark] val keyClassName: String = reflect.classTag[K].runtimeClass.getName</span><br><span class="line">  private[spark] val valueClassName: String = reflect.classTag[V].runtimeClass.getName</span><br><span class="line">  private[spark] val combinerClassName: Option[String] =</span><br><span class="line">    Option(reflect.classTag[C]).map(_.runtimeClass.getName)  //è·å–shuffleId</span><br><span class="line">  val shuffleId: Int = _rdd.context.newShuffleId()  //å‘shuffleManageræ³¨å†Œshuffleä¿¡æ¯</span><br><span class="line">  val shuffleHandle: ShuffleHandle = _rdd.context.env.shuffleManager.registerShuffle(</span><br><span class="line">    shuffleId, _rdd.partitions.length, this)</span><br><span class="line"></span><br><span class="line">  _rdd.sparkContext.cleaner.foreach(_.registerShuffleForCleanup(this))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ç”±äºshuffleæ¶‰åŠåˆ°ç½‘ç»œä¼ è¾“ï¼Œæ‰€ä»¥è¦æœ‰åºåˆ—åŒ–serializerï¼Œä¸ºäº†å‡å°‘ç½‘ç»œä¼ è¾“ï¼Œå¯ä»¥mapç«¯èšåˆï¼Œé€šè¿‡mapSideCombineå’Œaggregatoræ§åˆ¶ï¼Œè¿˜æœ‰keyæ’åºç›¸å…³çš„keyOrderingï¼Œä»¥åŠé‡è¾“å‡ºçš„æ•°æ®å¦‚ä½•åˆ†åŒºçš„partitionerï¼Œè¿˜æœ‰ä¸€äº›classä¿¡æ¯ã€‚Partitionä¹‹é—´çš„å…³ç³»åœ¨shuffleå¤„æˆ›ç„¶è€Œæ­¢ï¼Œå› æ­¤shuffleæ˜¯åˆ’åˆ†stageçš„ä¾æ®ã€‚</p><h4 id="ä¸‰ã€ä¸¤ç§ä¾èµ–çš„åŒºåˆ†"><a href="#ä¸‰ã€ä¸¤ç§ä¾èµ–çš„åŒºåˆ†" class="headerlink" title="ä¸‰ã€ä¸¤ç§ä¾èµ–çš„åŒºåˆ†"></a>ä¸‰ã€ä¸¤ç§ä¾èµ–çš„åŒºåˆ†</h4><p>é¦–å…ˆï¼Œçª„ä¾èµ–å…è®¸åœ¨ä¸€ä¸ªé›†ç¾¤èŠ‚ç‚¹ä¸Šä»¥æµæ°´çº¿çš„æ–¹å¼ï¼ˆpipelineï¼‰è®¡ç®—æ‰€æœ‰çˆ¶åˆ†åŒºã€‚ä¾‹å¦‚ï¼Œé€ä¸ªå…ƒç´ åœ°æ‰§è¡Œmapã€ç„¶åfilteræ“ä½œï¼›è€Œå®½ä¾èµ–åˆ™éœ€è¦é¦–å…ˆè®¡ç®—å¥½æ‰€æœ‰çˆ¶åˆ†åŒºæ•°æ®ï¼Œç„¶ååœ¨èŠ‚ç‚¹ä¹‹é—´è¿›è¡ŒShuffleï¼Œè¿™ä¸MapReduceç±»ä¼¼ã€‚ç¬¬äºŒï¼Œçª„ä¾èµ–èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¿›è¡Œå¤±æ•ˆèŠ‚ç‚¹çš„æ¢å¤ï¼Œå³åªéœ€é‡æ–°è®¡ç®—ä¸¢å¤±RDDåˆ†åŒºçš„çˆ¶åˆ†åŒºï¼Œè€Œä¸”ä¸åŒèŠ‚ç‚¹ä¹‹é—´å¯ä»¥å¹¶è¡Œè®¡ç®—ï¼›è€Œå¯¹äºä¸€ä¸ªå®½ä¾èµ–å…³ç³»çš„Lineageå›¾ï¼Œå•ä¸ªèŠ‚ç‚¹å¤±æ•ˆå¯èƒ½å¯¼è‡´è¿™ä¸ªRDDçš„æ‰€æœ‰ç¥–å…ˆä¸¢å¤±éƒ¨åˆ†åˆ†åŒºï¼Œå› è€Œéœ€è¦æ•´ä½“é‡æ–°è®¡ç®—ã€‚</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 13 2019 20:18:11 GMT+0800 (GMT+08:00) --&gt;&lt;h4 id=&quot;ä¸€ã€RDDçš„ä¾èµ–å…³ç³»&quot;&gt;&lt;a href=&quot;#ä¸€ã€RDDçš„ä¾èµ–å…³ç³»&quot; class=&quot;headerlink&quot; title=&quot;ä¸€ã€RDDçš„ä¾èµ–å…³ç³»&quot;&gt;&lt;/a&gt;ä¸€ã€RDDçš„ä¾èµ–å…³ç³»&lt;/h4&gt;&lt;p&gt;RDDçš„ä¾èµ–å…³ç³»åˆ†ä¸ºä¸¤ç±»ï¼šå®½ä¾èµ–å’Œçª„ä¾èµ–ã€‚æˆ‘ä»¬å¯ä»¥è¿™æ ·è®¤ä¸ºï¼š&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;ï¼ˆ1ï¼‰çª„ä¾èµ–ï¼šæ¯ä¸ªparent RDD çš„ partition æœ€å¤šè¢« child RDD çš„ä¸€ä¸ªpartition ä½¿ç”¨ã€‚&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;ï¼ˆ2ï¼‰å®½ä¾èµ–ï¼šæ¯ä¸ªparent RDD partition è¢«å¤šä¸ª child RDD çš„partition ä½¿ç”¨ã€‚&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;çª„ä¾èµ–æ¯ä¸ª child RDD çš„ partition çš„ç”Ÿæˆæ“ä½œéƒ½æ˜¯å¯ä»¥å¹¶è¡Œçš„ï¼Œè€Œå®½ä¾èµ–åˆ™éœ€è¦æ‰€æœ‰çš„ parent RDD partition shuffle ç»“æœå¾—åˆ°åå†è¿›è¡Œã€‚&lt;br&gt;
    
    </summary>
    
      <category term="Spark Core" scheme="http://yoursite.com/categories/Spark-Core/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>Javaå¯æ‰©å±•çº¿ç¨‹æ± ä¹‹ThreadPoolExecutor</title>
    <link href="http://yoursite.com/2018/06/13/Java%E5%8F%AF%E6%89%A9%E5%B1%95%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B9%8BThreadPoolExecutor/"/>
    <id>http://yoursite.com/2018/06/13/Javaå¯æ‰©å±•çº¿ç¨‹æ± ä¹‹ThreadPoolExecutor/</id>
    <published>2018-06-12T16:00:00.000Z</published>
    <updated>2019-05-15T11:35:24.458Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed May 15 2019 19:56:23 GMT+0800 (GMT+08:00) --><h4 id="1ã€ThreadPoolExecutor"><a href="#1ã€ThreadPoolExecutor" class="headerlink" title="1ã€ThreadPoolExecutor"></a>1ã€ThreadPoolExecutor</h4><p>æˆ‘ä»¬çŸ¥é“ThreadPoolExecutoræ˜¯å¯æ‰©å±•çš„,å®ƒæä¾›äº†å‡ ä¸ªå¯ä»¥åœ¨å­ç±»ä¸­æ”¹å†™çš„ç©ºæ–¹æ³•å¦‚ä¸‹ï¼š<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">protected void beforeExecute(Thread t, Runnable r) &#123; &#125;</span><br><span class="line">protected void beforeExecute(Thread t, Runnable r) &#123; &#125;  </span><br><span class="line">protected void terminated() &#123; &#125;</span><br></pre></td></tr></table></figure><p></p><a id="more"></a><h4 id="2ã€ä¸ºä»€ä¹ˆè¦è¿›è¡Œæ‰©å±•ï¼Ÿ"><a href="#2ã€ä¸ºä»€ä¹ˆè¦è¿›è¡Œæ‰©å±•ï¼Ÿ" class="headerlink" title="2ã€ä¸ºä»€ä¹ˆè¦è¿›è¡Œæ‰©å±•ï¼Ÿ"></a>2ã€ä¸ºä»€ä¹ˆè¦è¿›è¡Œæ‰©å±•ï¼Ÿ</h4><p>å› ä¸ºåœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯ä»¥å¯¹çº¿ç¨‹æ± è¿è¡ŒçŠ¶æ€è¿›è¡Œè·Ÿè¸ªï¼Œè¾“å‡ºä¸€äº›æœ‰ç”¨çš„è°ƒè¯•ä¿¡æ¯ï¼Œä»¥å¸®åŠ©æ•…éšœè¯Šæ–­ã€‚</p><h4 id="3ã€ThreadPoolExecutor-Workerçš„runæ–¹æ³•å®ç°"><a href="#3ã€ThreadPoolExecutor-Workerçš„runæ–¹æ³•å®ç°" class="headerlink" title="3ã€ThreadPoolExecutor.Workerçš„runæ–¹æ³•å®ç°"></a>3ã€ThreadPoolExecutor.Workerçš„runæ–¹æ³•å®ç°</h4><p>é€šè¿‡çœ‹æºç æˆ‘ä»¬å‘ç° ThreadPoolExecutorçš„å·¥ä½œçº¿ç¨‹å…¶å®å°±æ˜¯Workerå®ä¾‹ï¼ŒWorker.runTask()ä¼šè¢«çº¿ç¨‹æ± ä»¥å¤šçº¿ç¨‹æ¨¡å¼å¼‚æ­¥è°ƒç”¨ï¼Œåˆ™ä»¥ä¸Šä¸‰ä¸ªæ–¹æ³•ä¹Ÿå°†è¢«å¤šçº¿ç¨‹åŒæ—¶è®¿é—®ã€‚<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">1// åŸºäºjdk1.8.0_161final void runWorker(Worker w) &#123;</span><br><span class="line"> 2         Thread wt = Thread.currentThread();</span><br><span class="line"> 3         Runnable task = w.firstTask;</span><br><span class="line"> 4         w.firstTask = null;</span><br><span class="line"> 5         w.unlock(); // allow interrupts</span><br><span class="line"> 6         boolean completedAbruptly = true;        </span><br><span class="line"> 7             try &#123;            </span><br><span class="line"> 8             while (task != null || (task = getTask()) != null) &#123;</span><br><span class="line"> 9                  w.lock();                </span><br><span class="line">10              if ((runStateAtLeast(ctl.get(), STOP) ||</span><br><span class="line">11                     (Thread.interrupted() &amp;&amp;</span><br><span class="line">12                      runStateAtLeast(ctl.get(), STOP))) &amp;&amp;</span><br><span class="line">13                    !wt.isInterrupted())</span><br><span class="line">14                    wt.interrupt();               </span><br><span class="line">15              try &#123;</span><br><span class="line">16                    beforeExecute(wt, task);</span><br><span class="line">17                    Throwable thrown = null;                   </span><br><span class="line">18              try &#123;</span><br><span class="line">19                        task.run();</span><br><span class="line">20                    &#125; catch (RuntimeException x) &#123;</span><br><span class="line">21                        thrown = x; throw x;</span><br><span class="line">22                    &#125; catch (Error x) &#123;</span><br><span class="line">23                        thrown = x; throw x;</span><br><span class="line">24                    &#125; catch (Throwable x) &#123;</span><br><span class="line">25                        thrown = x; throw new Error(x);</span><br><span class="line">26                    &#125; finally &#123;</span><br><span class="line">27                        afterExecute(task, thrown);</span><br><span class="line">28                    &#125;</span><br><span class="line">29                &#125; finally &#123;</span><br><span class="line">30                    task = null;</span><br><span class="line">31                    w.completedTasks++;</span><br><span class="line">32                    w.unlock();</span><br><span class="line">33                &#125;</span><br><span class="line">34            &#125;</span><br><span class="line">35            completedAbruptly = false;</span><br><span class="line">36        &#125; finally &#123;</span><br><span class="line">37            processWorkerExit(w, completedAbruptly);</span><br><span class="line">38        &#125;</span><br><span class="line">39    &#125;</span><br></pre></td></tr></table></figure><p></p><h4 id="4ã€æ‰©å±•çº¿ç¨‹æ± å®ç°"><a href="#4ã€æ‰©å±•çº¿ç¨‹æ± å®ç°" class="headerlink" title="4ã€æ‰©å±•çº¿ç¨‹æ± å®ç°"></a>4ã€æ‰©å±•çº¿ç¨‹æ± å®ç°</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"> 1public class ExtThreadPool &#123;</span><br><span class="line"> 2    public static class MyTask implements Runnable &#123;</span><br><span class="line"> 3        public String name;        </span><br><span class="line"> 4        public MyTask(String name) &#123;            </span><br><span class="line"> 5          this.name = name;</span><br><span class="line"> 6        &#125;       </span><br><span class="line"> 7        public void run() &#123;</span><br><span class="line"> 8            System.out.println(&quot;æ­£åœ¨æ‰§è¡Œ:Thread ID:&quot; + Thread.currentThread().getId() + &quot;,Task Name:&quot; + name);            try &#123;</span><br><span class="line"> 9                Thread.sleep(100);</span><br><span class="line">10            &#125; catch (InterruptedException e) &#123;</span><br><span class="line">11                e.printStackTrace();</span><br><span class="line">12            &#125;</span><br><span class="line">13        &#125;</span><br><span class="line">14    &#125;    </span><br><span class="line">15public static void main(String args[]) throws InterruptedException &#123;</span><br><span class="line">16ExecutorService executorService = new ThreadPoolExecutor( 5,5,0L,</span><br><span class="line">17TimeUnit.MILLISECONDS,new LinkedBlockingDeque&lt;Runnable&gt;()) &#123;            </span><br><span class="line">18protected void beforeExecute(Thread t, Runnable r) &#123;</span><br><span class="line">19 System.out.println(&quot;å‡†å¤‡æ‰§è¡Œï¼š&quot; + ((MyTask) r).name);</span><br><span class="line">20&#125;            </span><br><span class="line">21protected void afterExecute(Thread t, Runnable r) &#123;</span><br><span class="line">22  System.out.println(&quot;æ‰§è¡Œå®Œæˆ&quot; + ((MyTask) r).name);</span><br><span class="line">23&#125;            </span><br><span class="line">24protected void terminated() &#123;</span><br><span class="line">25  System.out.println(&quot;çº¿ç¨‹æ± é€€å‡ºï¼&quot;);</span><br><span class="line">26&#125;</span><br><span class="line">27&#125;;        </span><br><span class="line">28for (int i = 0; i &lt; 5; i++) &#123;</span><br><span class="line">29 MyTask task = new MyTask(&quot;TASK--&quot; + i);</span><br><span class="line">30            executorService.execute(task);</span><br><span class="line">31            Thread.sleep(10);</span><br><span class="line">32        &#125;</span><br><span class="line">33 executorService.shutdown();</span><br><span class="line">34    &#125;</span><br><span class="line">35&#125;</span><br></pre></td></tr></table></figure><p>è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">å‡†å¤‡æ‰§è¡Œï¼šTASKâ€“0 </span><br><span class="line">æ­£åœ¨æ‰§è¡Œ:Thread ID:10,Task Name:TASKâ€“0 </span><br><span class="line">å‡†å¤‡æ‰§è¡Œï¼šTASKâ€“1 </span><br><span class="line">æ­£åœ¨æ‰§è¡Œ:Thread ID:11,Task Name:TASKâ€“1 </span><br><span class="line">å‡†å¤‡æ‰§è¡Œï¼šTASKâ€“2 </span><br><span class="line">æ­£åœ¨æ‰§è¡Œ:Thread ID:12,Task Name:TASKâ€“2 </span><br><span class="line">å‡†å¤‡æ‰§è¡Œï¼šTASKâ€“3 </span><br><span class="line">æ­£åœ¨æ‰§è¡Œ:Thread ID:13,Task Name:TASKâ€“3 </span><br><span class="line">å‡†å¤‡æ‰§è¡Œï¼šTASKâ€“4 </span><br><span class="line">æ­£åœ¨æ‰§è¡Œ:Thread ID:14,Task Name:TASKâ€“4 </span><br><span class="line">çº¿ç¨‹æ± é€€å‡ºï¼</span><br></pre></td></tr></table></figure><p></p><p>è¿™æ ·å°±å®ç°äº†åœ¨æ‰§è¡Œå‰åè¿›è¡Œçš„ä¸€äº›æ§åˆ¶ï¼Œé™¤æ­¤ä¹‹å¤–æˆ‘ä»¬è¿˜å¯ä»¥è¾“å‡ºæ¯ä¸ªçº¿ç¨‹çš„æ‰§è¡Œæ—¶é—´ï¼Œæˆ–è€…ä¸€äº›å…¶ä»–å¢å¼ºæ“ä½œã€‚</p><h4 id="5ã€æ€è€ƒï¼Ÿ"><a href="#5ã€æ€è€ƒï¼Ÿ" class="headerlink" title="5ã€æ€è€ƒï¼Ÿ"></a>5ã€æ€è€ƒï¼Ÿ</h4><p>è¯·è¯»è€…æ€è€ƒshutdownNowå’Œshutdownæ–¹æ³•çš„åŒºåˆ«ï¼Ÿ<br>å¦‚ä½•ä¼˜é›…çš„å…³é—­çº¿ç¨‹æ± ï¼Ÿ</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed May 15 2019 19:56:23 GMT+0800 (GMT+08:00) --&gt;&lt;h4 id=&quot;1ã€ThreadPoolExecutor&quot;&gt;&lt;a href=&quot;#1ã€ThreadPoolExecutor&quot; class=&quot;headerlink&quot; title=&quot;1ã€ThreadPoolExecutor&quot;&gt;&lt;/a&gt;1ã€ThreadPoolExecutor&lt;/h4&gt;&lt;p&gt;æˆ‘ä»¬çŸ¥é“ThreadPoolExecutoræ˜¯å¯æ‰©å±•çš„,å®ƒæä¾›äº†å‡ ä¸ªå¯ä»¥åœ¨å­ç±»ä¸­æ”¹å†™çš„ç©ºæ–¹æ³•å¦‚ä¸‹ï¼š&lt;br&gt;&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;protected void beforeExecute(Thread t, Runnable r) &amp;#123; &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;protected void beforeExecute(Thread t, Runnable r) &amp;#123; &amp;#125;  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;protected void terminated() &amp;#123; &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://yoursite.com/categories/Java/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Apache Spark æŠ€æœ¯å›¢é˜Ÿå¼€æºæœºå™¨å­¦ä¹ å¹³å° MLflow</title>
    <link href="http://yoursite.com/2018/06/12/Apache%20Spark%20%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E5%BC%80%E6%BA%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B9%B3%E5%8F%B0%20MLflow/"/>
    <id>http://yoursite.com/2018/06/12/Apache Spark æŠ€æœ¯å›¢é˜Ÿå¼€æºæœºå™¨å­¦ä¹ å¹³å° MLflow/</id>
    <published>2018-06-11T16:00:00.000Z</published>
    <updated>2019-05-13T08:56:44.124Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --><p>è¿‘æ—¥ï¼Œæ¥è‡ª Databricks çš„ Matei Zaharia å®£å¸ƒæ¨å‡ºå¼€æºæœºå™¨å­¦ä¹ å¹³å° MLflow ã€‚Matei Zaharia æ˜¯ Apache Spark å’Œ Apache Mesos çš„æ ¸å¿ƒä½œè€…ï¼Œä¹Ÿæ˜¯ Databrick çš„é¦–å¸­æŠ€æœ¯ä¸“å®¶ã€‚Databrick æ˜¯ç”± Apache Spark æŠ€æœ¯å›¢é˜Ÿæ‰€åˆ›ç«‹çš„å•†ä¸šåŒ–å…¬å¸ã€‚MLflow ç›®å‰å·²å¤„äºæ—©æœŸæµ‹è¯•é˜¶æ®µï¼Œå¼€å‘è€…å¯ä¸‹è½½æºç ä½“éªŒã€‚<br><a id="more"></a><br><img src="/assets/blogImg/612_1.png" alt="enter description here"><br>Matei Zaharia è¡¨ç¤ºå½“å‰åœ¨ä½¿ç”¨æœºå™¨å­¦ä¹ çš„å…¬å¸æ™®éå­˜åœ¨å·¥å…·è¿‡å¤šã€éš¾ä»¥è·Ÿè¸ªå®éªŒã€éš¾ä»¥é‡ç°ç»“æœã€éš¾ä»¥éƒ¨ç½²ç­‰é—®é¢˜ã€‚ä¸ºè®©æœºå™¨å­¦ä¹ å¼€å‘å˜å¾—ä¸ä¼ ç»Ÿè½¯ä»¶å¼€å‘ä¸€æ ·å¼ºå¤§ã€å¯é¢„æµ‹å’Œæ™®åŠï¼Œè®¸å¤šä¼ä¸šå·²å¼€å§‹æ„å»ºå†…éƒ¨æœºå™¨å­¦ä¹ å¹³å°æ¥ç®¡ç† MLç”Ÿå‘½å‘¨æœŸã€‚åƒæ˜¯ Facebookã€Google å’Œ Uber å°±å·²åˆ†åˆ«æ„å»ºäº† FBLearner Flowã€TFX å’Œ Michelangelo æ¥ç®¡ç†æ•°æ®ã€æ¨¡å‹åŸ¹è®­å’Œéƒ¨ç½²ã€‚ä¸è¿‡ç”±äºè¿™äº›å†…éƒ¨å¹³å°å­˜åœ¨å±€é™æ€§å’Œç»‘å®šæ€§ï¼Œæ— æ³•å¾ˆå¥½åœ°ä¸ç¤¾åŒºå…±äº«æˆæœï¼Œå…¶ä»–ç”¨æˆ·ä¹Ÿæ— æ³•è½»æ˜“ä½¿ç”¨ã€‚<br>MLflow æ­£æ˜¯å—ç°æœ‰çš„ ML å¹³å°å¯å‘ï¼Œä¸»æ‰“å¼€æ”¾æ€§ï¼š</p><ul><li>å¼€æ”¾æ¥å£ï¼šå¯ä¸ä»»æ„ ML åº“ã€ç®—æ³•ã€éƒ¨ç½²å·¥å…·æˆ–ç¼–ç¨‹è¯­è¨€ä¸€èµ·ä½¿ç”¨ã€‚</li><li>å¼€æºï¼šå¼€å‘è€…å¯è½»æ¾åœ°å¯¹å…¶è¿›è¡Œæ‰©å±•ï¼Œå¹¶è·¨ç»„ç»‡å…±äº«å·¥ä½œæµæ­¥éª¤å’Œæ¨¡å‹ã€‚<br>MLflow ç›®å‰çš„ alpha ç‰ˆæœ¬åŒ…å«ä¸‰ä¸ªç»„ä»¶ï¼š<br><img src="/assets/blogImg/612_2.png" alt="enter description here"><br>å…¶ä¸­ï¼ŒMLflow Trackingï¼ˆè·Ÿè¸ªç»„ä»¶ï¼‰æä¾›äº†ä¸€ç»„ API å’Œç”¨æˆ·ç•Œé¢ï¼Œç”¨äºåœ¨è¿è¡Œæœºå™¨å­¦ä¹ ä»£ç æ—¶è®°å½•å’ŒæŸ¥è¯¢å‚æ•°ã€ä»£ç ç‰ˆæœ¬ã€æŒ‡æ ‡å’Œè¾“å‡ºæ–‡ä»¶ï¼Œä»¥ä¾¿ä»¥åå¯è§†åŒ–å®ƒä»¬ã€‚<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import mlflow</span><br><span class="line"></span><br><span class="line"># Log parameters (key-value pairs)</span><br><span class="line">mlflow.log_param(&quot;num_dimensions&quot;, 8)</span><br><span class="line">mlflow.log_param(&quot;regularization&quot;, 0.1)</span><br><span class="line"></span><br><span class="line"># Log a metric; metrics can be updated throughout the run</span><br><span class="line">mlflow.log_metric(&quot;accuracy&quot;, 0.1)</span><br><span class="line">...</span><br><span class="line">mlflow.log_metric(&quot;accuracy&quot;, 0.45)</span><br><span class="line"></span><br><span class="line"># Log artifacts (output files)</span><br><span class="line">mlflow.log_artifact(&quot;roc.png&quot;)</span><br><span class="line">mlflow.log_artifact(&quot;model.pkl&quot;)</span><br></pre></td></tr></table></figure></li></ul><p>MLflow Projectsï¼ˆé¡¹ç›®ç»„ä»¶ï¼‰æä¾›äº†æ‰“åŒ…å¯é‡ç”¨æ•°æ®ç§‘å­¦ä»£ç çš„æ ‡å‡†æ ¼å¼ã€‚æ¯ä¸ªé¡¹ç›®éƒ½åªæ˜¯ä¸€ä¸ªåŒ…å«ä»£ç æˆ– Git å­˜å‚¨åº“çš„ç›®å½•ï¼Œå¹¶ä½¿ç”¨ä¸€ä¸ªæè¿°ç¬¦æ–‡ä»¶æ¥æŒ‡å®šå®ƒçš„ä¾èµ–å…³ç³»ä»¥åŠå¦‚ä½•è¿è¡Œä»£ç ã€‚æ¯ä¸ª MLflow é¡¹ç›®éƒ½æ˜¯ç”±ä¸€ä¸ªç®€å•çš„åä¸º MLproject çš„ YAML æ–‡ä»¶è¿›è¡Œè‡ªå®šä¹‰ã€‚<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">name: My Project</span><br><span class="line">conda_env: conda.yaml</span><br><span class="line">entry_points:</span><br><span class="line">  main:</span><br><span class="line">    parameters:</span><br><span class="line">      data_file: path</span><br><span class="line">      regularization: &#123;type: float, default: 0.1&#125;</span><br><span class="line">    command: &quot;python train.py -r &#123;regularization&#125; &#123;data_file&#125;&quot;</span><br><span class="line">  validate:</span><br><span class="line">    parameters:</span><br><span class="line">      data_file: path</span><br><span class="line">    command: &quot;python validate.py &#123;data_file&#125;&quot;</span><br></pre></td></tr></table></figure><p></p><p>MLflow Modelsï¼ˆæ¨¡å‹ç»„ä»¶ï¼‰æä¾›äº†ä¸€ç§ç”¨å¤šç§æ ¼å¼æ‰“åŒ…æœºå™¨å­¦ä¹ æ¨¡å‹çš„è§„èŒƒï¼Œè¿™äº›æ ¼å¼è¢«ç§°ä¸º â€œflavorâ€ ã€‚MLflow æä¾›äº†å¤šç§å·¥å…·æ¥éƒ¨ç½²ä¸åŒ flavor çš„æ¨¡å‹ã€‚æ¯ä¸ª MLflow æ¨¡å‹è¢«ä¿å­˜æˆä¸€ä¸ªç›®å½•ï¼Œç›®å½•ä¸­åŒ…å«äº†ä»»æ„æ¨¡å‹æ–‡ä»¶å’Œä¸€ä¸ª MLmodel æè¿°ç¬¦æ–‡ä»¶ï¼Œæ–‡ä»¶ä¸­åˆ—å‡ºäº†ç›¸åº”çš„ flavor ã€‚<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">time_created: 2018-02-21T13:21:34.12</span><br><span class="line">flavors:</span><br><span class="line">  sklearn:</span><br><span class="line">    sklearn_version: 0.19.1</span><br><span class="line">    pickled_model: model.pkl</span><br><span class="line">  python_function:</span><br><span class="line">    loader_module: mlflow.sklearn</span><br><span class="line">    pickled_model: model.pkl</span><br></pre></td></tr></table></figure><p></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon May 13 2019 18:23:39 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;è¿‘æ—¥ï¼Œæ¥è‡ª Databricks çš„ Matei Zaharia å®£å¸ƒæ¨å‡ºå¼€æºæœºå™¨å­¦ä¹ å¹³å° MLflow ã€‚Matei Zaharia æ˜¯ Apache Spark å’Œ Apache Mesos çš„æ ¸å¿ƒä½œè€…ï¼Œä¹Ÿæ˜¯ Databrick çš„é¦–å¸­æŠ€æœ¯ä¸“å®¶ã€‚Databrick æ˜¯ç”± Apache Spark æŠ€æœ¯å›¢é˜Ÿæ‰€åˆ›ç«‹çš„å•†ä¸šåŒ–å…¬å¸ã€‚MLflow ç›®å‰å·²å¤„äºæ—©æœŸæµ‹è¯•é˜¶æ®µï¼Œå¼€å‘è€…å¯ä¸‹è½½æºç ä½“éªŒã€‚&lt;br&gt;
    
    </summary>
    
      <category term="Spark MLlib" scheme="http://yoursite.com/categories/Spark-MLlib/"/>
    
    
      <category term="é«˜çº§" scheme="http://yoursite.com/tags/%E9%AB%98%E7%BA%A7/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
</feed>
